#+title: Numerical methods
#+subtitle: on the Cahn-Hilliard Equation
#+BIBLIOGRAPHY: ~/org/resources/bibliography/refs.bib
#+options: toc:nil
#+BIND: org-latex-title-command ""
#+latex_class: mimosis
 #+latex_header: \include{~/.doom.d/OrgConfig/noteHeader.tex}
 #+HTML_HEAD: <link rel="stylesheet" type="text/css" href="https://gongzhitaao.org/orgcss/org.css"/>
#+PROPERTY: header-args:julia :output-dir images :eval never :noweb no-export
#+PROPERTY: header-args:julia-vterm :output-dir images :exports results :noweb no-export :eval yes :cache yes :session jl
# #+INFOJS_OPT: view:info toc:nil
#+latex_header: \renewcommand{\floatpagefraction}{.9}%
#+latex_header: \usepackage[level]{datetime}

* Title-page :ignore:
#+begin_export latex
\makeatletter
\begin{titlepage}
    \centering
\includegraphics[width=1\textwidth]{logo/logo.png}
\par
	\vspace{1.5cm}
	{\scshape\huge Bachelor's Thesis \par}
	\vspace{1.5cm}
	{\Huge\bfseries  \@title \par}
	\vspace{2cm}
	{\LARGE \@author \par}
	{\Large Matriculation Number: 3545737 \par}
	\vspace{1.5cm}
	{\large Examiner: Prof Rohde i believe \par}
	{\large Advisor: Hasel \par}
	\vspace{1.5cm}
	{\large Institute of Applied Analysis and Numerical Simulation\par}



	\vfill

% Bottom of the page
	{\large Completed 01.01.2022 \par}
\end{titlepage}
\makeatother

#+end_export



#+begin_abstract
This Thesis gives a short overview and derivation for the Cahn-Hilliard Equation. It uses a discretization by the authors [cite:@SHIN20117441] as baseline, and expands upon this dicretisation with an elliptical relaxation approach. It introduces evaluation metrics in terms of time , space and subiteration stability and compares the elliptical approach against the baseline. It shows a qualitative succes of the elliptical solver, however it also highlights challanges in numerical stability.
#+end_abstract

#+TOC: headlines 3

* Introduction
The Cahn Hilliard equation is a well known fourth order PDE used in multiphase flow, to couple fifferent phases. It is used in a diffused interace approach. A diffuse interphase, as compared to a sharp interface has a smooth transition between phases, as shown in Fig.[[fig:sharp-diffuse]]
#+name: fig:sharp-diffuse
#+begin_src julia-vterm :results file output :file diffuse-sharp.svg
<<init>>
<<setup-diverse-testgrids>>
sharp = testgrid(multi_solver,M, 2)
diffuse = testgrid(multi_solver,M, 2)
set_xi_and_psi!(diffuse[1])
SMOOTH!(diffuse[1] , 100, true)
p1 = heatmap(sharp[1].phase , title="sharp" , legend=:none , aspectratio=:equal , showaxis=false , grid=false)
p2 = heatmap( diffuse[1].phase , title="diffuse" , legend=:none , aspectratio=:equal , showaxis=false , grid=false)
p=plot(p1,p2)
savefig(p,"images/diffuse-sharp.svg")
#+end_src

#+caption: Exmaple of a diffuse and a sharp interphase
#+RESULTS[a503b120965966f072aded2fe7f565eaa686891e]: fig:diffuse-sharp
[[file:images/diffuse-sharp.svg]]

 This thesis follows reproducible research philosophy, in that we provide all relevant code in the same file as the writing itself. We then use this file to generate exports to html and PDF, as well as extract the code to be used independently. Further details on execution and reading of the original source provided in org-mode format,
* The Cahn-Hilliard equation
The Cahn-Hilliard(CH) equation is a partial differential equation (PDE) that governs the dynamics of a two-phase fluid[cite:@Wu_2022]. The form of the CH equation used in this thesis in the domain  \( \Omega \times [0, T) \,, \Omega \subset \mathbb{R}^d \,, d \in \mathbb{N}  \,, T>0 \).
#+name: eq:CH
\begin{equation}
\begin{aligned}
\partial_{t}\phi(x,t) &=  \nabla \cdot(M(\phi)\nabla\mu) \\
\mu &= - \varepsilon^2 \Delta\phi  + W'(\phi)
\end{aligned}
\end{equation}
where the variables \( \phi , \mu \) are phase-field variable and chemical potential,
\begin{equation}
\begin{aligned}
\phi: \Omega \times [0, T) &\to \mathbb{R}^d \\
\mu: \Omega \times [0, T) &\to \mathbb{R}^d
\end{aligned}
\end{equation}
\(\varepsilon\) is a positive constant correlated with interface thickness, \( W(\phi) \) is a double well potential and \(M(\phi) > 0\) is a mobility coefficient [cite:@Wu_2022].
 \( \phi\) is defined in an interval \(I=[-1,1] \) and  represent the different phases.
\begin{align*}
\phi &=
\begin{cases}
1 &\,, \phi \in \text{phase 1} \\
-1 &\,, \phi \in\text{phase 2}
\end{cases}
\end{align*}

 In this thesis we assume \(M(\phi) \equiv 1 \), simplifying the CH equation.

The advantages of the CH approach, as compared to traditional boundary coupling, are for example: "explicit tracking of the interface" [cite:@Wu_2022], as well as "evolution of complex geometries and topological changes [...] in a natural way" [cite:@Wu_2022].
In practice it enables linear interpolation between different formulas on different phases.
** Physical derivation of the CH equation [[eq:CH]]
*** The free energy
The authors in [cite:@Wu_2022] define the CH equation using the *Ginzburg-Landau* free energy equation:
#+name: eq:energy
\begin{align}
E^{\text{bulk}}[\phi] &= \int_{\Omega} \frac{\varepsilon^2}{2} |\nabla \phi |^2 + W(\phi) \, dx ,
\end{align}
where \(W(\phi) \) denotes the Helmholtz free energy density of mixing [cite:@Wu_2022] that we approximate it in further calculations with \(W(\phi) = \frac{(1-\phi ^2)^2}{4}\) as in [cite:@SHIN20117441] shown in Fig. [[fig:double-well]].
#+name: fig:double-well
#+begin_src julia-vterm :results file graphics :file double-well.svg
using Plots
using LaTeXStrings
W(x) = 1/4 * (1- x^ 2)^2

p = plot(W , xlims=(-2,2) , label=:none)
savefig(p, "images/double-well.svg")
#+end_src

#+caption: Double well potential \( W(\phi) \)
#+RESULTS[978b0588e2d59be5e973459583ee383508f68433]: fig:double-well
[[file:images/double-well.svg]]




The chemical potential, \( \mu \), then follows as the variational derivation of the free energy [[eq:energy]].
\begin{align*}
 \mu &= \frac{\delta E_{bulk}(\phi)}{\delta \phi} = -\varepsilon^2 \Delta \phi + W'(\phi)
\end{align*}

*** Derivation of the CH equation from mass balance
The paper [cite:@Wu_2022]  motivates us to derive the CH equation as follows:
#+name: eq:massbal
\begin{equation}
    \partial_t \phi + \nabla \cdot J = 0
\end{equation}
where \( J \) is mass flux. The equation [[eq:massbal]] then ensures continuity of mass
Using the no-flux boundary conditions:
#+name: eq:boundary-conditions
\begin{equation}
\begin{aligned}
J \cdot n &= 0 & \partial\Omega &\times (0,T)\\
\partial_n\phi &= 0 & \partial\Omega &\times (0,T)
\end{aligned}
\end{equation}
where \( n \) is the outward normal on \( \partial \Omega \).
conservation of mass follows see[cite:@Wu_2022].
#+name: eq:mass-conservation
\begin{equation}
\begin{aligned}
\frac{d}{dt}\int_{\Omega}\phi&=\int_{\Omega}\frac{\partial \phi}{\partial t} dV \\
&= - \int_{\Omega} \nabla \cdot J \ dV\\
&=  \int_{\partial\Omega}  J \cdot n  \ dA \\
&= 0
\end{aligned}
\end{equation}
Therefore mass is conserved over time, as shown in [[eq:mass-conservation]].
We define the mass flux, \( J \), as the gradient in chemical potential as follows
\begin{align}
J &= - \nabla \mu
\end{align}
This results in the CH equation as stated in [[eq:CH]].
#+name: eq:boundary-conditions
\begin{equation}
\begin{aligned}
 - \nabla \mu &= 0 \\
\partial_n \phi &= 0
\end{aligned}
\end{equation}
i.e. no flow leaves and potential on the border doesn't change.
In order to show the CH equation's consistency with thermodynamics we take the time derivation of the free energy [[eq:energy]] and we show that it decreases in time.
\begin{align*}
\frac{d}{dt}E^{bulk}(\phi(t)) &= \int_{\Omega} ( \varepsilon^2 \nabla \phi \cdot \nabla \partial_t \phi + W'(\phi) \partial_t \phi) \ d x \\
&=\int_{\Omega} (\varepsilon^2\nabla\phi + W'(\phi))\partial_t\phi \ dx\\
&=\int_{\Omega} \mu \partial_t \phi \ dx\\
&= \int_{\Omega} \mu \cdot \Delta\mu \ dx \\
&= -\int_{\Omega} \nabla\mu \cdot \nabla\mu \ dx + \int_{\partial\Omega} \mu \nabla\phi_t \cdot n \ dS \\
&\stackrel{\partial_n\phi = 0}{=} - \int_{ \Omega } |\nabla \mu|^2 \ d x, & \forall t \in [0,T)
\end{align*}
* Baseline multi-grid solver
** The discretization of the CH equation:
As baseline for numerical experiments we use a two-grid method based on the finite difference method defined in [cite:@SHIN20117441].
Our discretization follows the one taken by the authors in [cite:@SHIN20117441].
We discretize our domain \( \Omega \) to be a Cartesian-grid \( \Omega_d \) on a square with side-length \( N\cdot h \), where N is the number of grid-points in one direction, and \( h \) is the distance between grid-points. In all our initial data \( h \) is \( 3\cdot10^{-3}\) and \( N=64 \) . However for stability tests we change \( h \) and \( N \).
\begin{equation}
\Omega_d = \left\{ i,j \mid i,j \in \mathbb{N} \,, i,j \in [2,N+1] \right\}
\end{equation}
where \( \Omega_{d} \) is the discrete version or our domain as shown in [[fig:discrete-domain]].
#+name: fig:discrete-domain
#+begin_src julia-vterm :results file graphics :file domain.svg
using Plots
using LaTeXStrings
pgfplotsx()
Idx = CartesianIndex(1,1)
M = zeros(66,66)
M[2:end-1 , 2:end-1] = ones(64,64)
p= heatmap(M, title=L"\Omega_d" , clim=(-1,1),
            gridlinewidth=2 , axis_equal_image=true , extra_kwargs=:subplot , xlims=(1 ,66) , ylims=(1,66))

savefig(p,"images/domain.svg")
#+end_src

#+caption: Discrete Domain used for most of the experiments in this Thesis
#+RESULTS[46038739234db0a64b145e68000e9b1ea9d30425]: fig:discrete-domain
[[file:images/domain.svg]]


We discretize the phase-field ,\( \phi \), and chemical potential ,\( \mu \), into grid-wise functions \(\phi_{ij}, \mu_{ij} \)
\begin{equation}
\begin{aligned}
\phi_{ij}^n: \Omega_d \times \left\{ 0, \dots  \right\} &\to \mathbb{R}\\
\mu_{ij}^n: \Omega_d \times \left\{ 0, \dots \right\} &\to \mathbb{R}
\end{aligned}
\end{equation}
Here \( n \) denotes the nth time-step , and \( (i,j) \) are cartesian indicies on the discrete domain \( \Omega_d \).
The authors in [cite:@SHIN20117441] then use the characteristic function \( G \) of the  domain \( \Omega \) to enforce no-flux boundary conditions [[eq:boundary-conditions]].

\begin{align*}
G(x,y) &=
\begin{cases}
1, & (x,y) \in  \Omega \\
0, & (x,y) \not\in  \Omega
\end{cases}
\end{align*}
We implement the discrete version of \( G \) on \( \Omega_d \) as follows:
\begin{align*}
G_{ij} &=
\begin{cases}
1, & (i,j) \in  \Omega_{d} \\
0, & \text{else}
\end{cases}
\end{align*}

#+begin_src julia :tangle src/utils.jl :eval never :exports none
"""
Boundry indicator function

Returns
---------------
1 if index i,j is in bounds(without padding) and 0 else
"""
#+end_src
#+begin_src julia :tangle src/utils.jl :eval never
function G(i, j, len, width)
    if 2 <= i <= len + 1 && 2 <= j <= width + 1
        return 1.0
    else
        return 0.0
    end
end
#+end_src

We then define the discrete derivatives \( D_x\phi_{ij}, \ D_y\phi_{ij} \) using centred differences:
\begin{align}
D_x\phi^{n+1,m}_{i+\frac{1}{2} j} &= \frac{\phi^{n+1,m}_{i+1j} - \phi^{n+1,m}_{ij}}{h} & D_y\phi^{n+1,m}_{ij+\frac{1}{2}} &= \frac{\phi^{n+1,m}_{ij+1} - \phi^{n+1,m}_{ij}}{h}
\end{align}
We define \( D_x\mu_{ij}^{n+\frac{1}{2},m} , D_y\mu_{ij}^{n+\frac{1}{2},m} \) in the same way.
Next we define the discrete gradient \( \nabla_d \phi^{n+1,m}_{ij}\), as well as a modified Laplacian \( \nabla_d \cdot (G_{ij} \nabla_d \phi^{n+1,m}_{ij} )\):


#+name: eq:discretization
\begin{align}
\nabla_d \phi^{n+1,m}_{ij} &= \left(D_x \phi^{n+1,m}_{i+1j} , \ D_y \phi^{n+1,m}_{ij+1}\right) \\
 \nabla_d \cdot (G_{ij} \nabla_d \phi^{n+1,m}_{ij}) &= \frac{G_{i+\frac{1}{2}j}D_x \phi^{n+1,m}_{i+\frac{1}{2}j} -  G_{i-172}D_x \phi^{n+1,m}_{i-\frac{1}{2}j} + D_y \phi^{n+1,m}_{ij+\frac{1}{2}} - D_y \phi^{n+1,m}_{ij-\frac{1}{2}}}{h} \\
  &= \frac{ G_{i+\frac{1}{2}j} \phi^{n + 1,m}_{i+1j} +  G_{i-\frac{1}{2}j} \phi^{n +,m}_{i-1j} + G_{ij+\frac{1}{2}}  \phi^{n +,m}_{ij+1} + G_{ij-\frac{1}{2}} \phi^{n +,m}_{ij-1}    }{h^2}\\
& \, - \frac{\left(   G_{i+\frac{1}{2}j} + G_{i-\frac{1}{2}j} + G_{ij+\frac{1}{2}} + G_{ij-\frac{1}{2}}  \cdot \phi_{ij} \right)}{h^2}
\end{align}
 We define \(   \nabla_d \cdot (G_{ij} \nabla_d \phi_{ij} )\) instead of a discrete laplacian \( \Delta_d \) to ensure a discrete version of boundary conditions [[eq:boundary-conditions]].
the discretizations for \(  \nabla_d\mu_{ij}^{n+\frac{1}{2},m} ,  \nabla_d \cdot (G_{ij} \nabla_d \mu^{n+\frac{1}{2},m}_{ij}) \) are done the same as for \( \phi_{ij}^{n+1} \)

 The authors in [cite:@SHIN20117441] show this to be the case by expanding \( \nabla_d \cdot (G_{ij} \nabla_d\phi_{ij}) \).

notably, when one point lies outside the domain, then \( G_{i \pm \frac{1}{2}} = 0 \)  and therefore the corresponding discrete gradient \( \frac{\phi_{i\pm1} - \phi_i}{h}  \) is weighted by 0. This corresponds the discrete version of \( \partial_n\phi = 0 \).
The authors in [cite:@SHIN20117441]

To simplify the notation for discretized derivatives we use the following abbreviations:
- \(  \Sigma_G \phi_{ij} = G_{i+\frac{1}{2}j} \phi^{n + 1,m}_{i+1j} +  G_{i-\frac{1}{2}j} \phi^{n +1,m}_{i-1j} + G_{ij+\frac{1}{2}}  \phi^{n +1,m}_{ij+1} + G_{ij-\frac{1}{2}} \phi^{n +1,m}_{ij-1}  \)
- \(  \Sigma_{Gij} = G_{i+\frac{1}{2}j} + G_{i-\frac{1}{2}j} + G_{ij+\frac{1}{2}} + G_{ij-\frac{1}{2}}  \)
Code:
#+begin_src julia :tangle src/utils.jl :eval never
function neighbours_in_domain(i, j, G, len, width)
    (
        G(i + 0.5, j, len, width)
        + G(i - 0.5, j, len, width)
        + G(i, j + 0.5, len, width)
        + G(i, j - 0.5, len, width)
    )

end
function discrete_G_weigted_neigbour_sum(i, j, arr, G, len, width)
    (
        G(i + 0.5, j, len, width) * arr[i+1, j]
        + G(i - 0.5, j, len, width) * arr[i-1, j]
        + G(i, j + 0.5, len, width) * arr[i, j+1]
        + G(i, j - 0.5, len, width) * arr[i, j-1]
    )
end
#+end_src

We can then write the modified Laplacian \( \nabla_d (G \nabla_d\phi_{ij}) \) as:
\begin{align*}
\nabla_{d} \cdot(G \nabla_d\phi_{ij}) &= \frac{\Sigma_G\phi_{ij} - \Sigma_G\cdot \phi_{ij}}{h^2}
\end{align*}
We use this modified Laplacian to deal with boundary conditions. Our abbreviations simplify separating implicit and explicit terms in the discretization.
** Initial data
For testing we use initial phase-fields defined by the following equations:

\begin{equation}
\begin{aligned}
\phi_{ij} &=
\begin{cases}
1 &\,, \|(i,j) - (\frac{N}{2} , \frac{N}{2})\|_p < \frac{N}{3}\\
-1 &\,,else
\end{cases}
&
\text{where    }  p \in \{2,\infty\}
\\
\phi_{ij} &=
\begin{cases}
1 &\,,  i < \frac{N}{2} \\
-1 &\,,else
\end{cases}
\\
\phi_{ij} &=
\begin{cases}
1 &\,, \|(i,j) - (\frac{N}{2} , 2)\|_2 < \frac{N}{3} \\
-1 &\,,else
\end{cases}
\\
\phi_{ij} &=
\begin{cases}
1 &\,, \| (i,j) - q_k \|_p < \frac{N}{5}  \\
-1 &\,,else
\end{cases}
& p \in \{1,2, \infty\} , q_k \in Q
\end{aligned}
\end{equation}
where \( q_k \) are random points inside my domain. Those we generate those using the following rng setup in julia


#+name: fig:testinput
#+begin_src julia-vterm :results file graphics  :file testdata.svg
<<init>>
<<setup-diverse-testgrids>>
plots =[  heatmap(t[1].phase ,  legend=:none , aspectratio=:equal , grid=false , showaxis=false , size=(600,600))
for t in tests[1:2:end]]
#plots = [heatmap(t[1].phase , size=(600,600), axis=:none , aspect_ratio=:equal) for t in tests]
p = plot(plots... , layout=(1,4) , size=(2400,600))
savefig(p,"images/testdata.svg")
#+end_src

#+caption: Examples of different phase-fields used as the initial condition in this work.
#+RESULTS[022c521f7b12b7f61d32b1d70b05629b2f49e747]: fig:testinput
[[file:images/testdata.svg]]

** Numerical ansatz
The authors in [cite:@SHIN20117441] then define the discrete CH equation adapted for the domain as:
#+name: eq:discrete-cahn-hilliard
\begin{equation}
\begin{aligned}
\frac{\phi_{ij}^{n+1} - \phi_{ij}^n}{\Delta t}  &=  \nabla _d \cdot (G_{ij} \nabla_d \mu_{ij}^{n+\frac{1}{2}} )  \\
 \mu_{ij}^{n+\frac{1}{2}} &= 2\phi_{ij}^{n+1} - \varepsilon^2  \nabla_d \cdot  (G_{ij} \nabla _d \phi_{ij}^{n+1} ) + W'(\phi_{ij}^n) - 2\phi _{ij}^n
\end{aligned}
\end{equation}
and derive a numerical scheme from this implicit equation.
** The discrete scheme
The authors in [cite:@SHIN20117441] derive their method by separating [[eq:discrete-cahn-hilliard]] into implicit and linear terms, and explicit non-linear terms. We write the implicit terms in form of a function \( L: \RR^2 \to \RR^2  \) and the explicit terms in \( (\zeta^n_{ij} , \psi^n_{ij})^T \).
\begin{align*}
L
\begin{pmatrix}
\phi^{n+1}_{ij} \\
\mu^{n+\frac{1}{2}}_{ij}
\end{pmatrix}
&=
\begin{pmatrix}
\frac{\phi^{n+1}_{ij}}{\Delta t} - \nabla _d \cdot  ( G_{ij} \nabla _d \mu^{n+\frac{1}{2}}_{ij} ) \\
\varepsilon^2 \nabla _d \cdot  (G \nabla_d \phi_{ij}^{n+1}) - 2\phi_{ij}^{n+1} + \mu_{ij}^{n+\frac{1}{2}}
\end{pmatrix}
\end{align*}
This operator follows from [[eq:discrete-cahn-hilliard]] by separating implicit and explicit terms \( L \) and   \( (\zeta^n_{ij} , \psi^n_{ij})^T \), respectively.
\begin{align*}
\begin{pmatrix}
\zeta^n_{ij}
 \\
\psi^n_{ij}
\end{pmatrix}
&=
\begin{pmatrix}
\frac{\phi_{ij}^{n}}{\Delta t}\\
W'(\phi_{ij}^n) - 2\phi_{ij}^n
\end{pmatrix}
\end{align*}
Due to being explicit, we know everything needed to calculate \( (\zeta^n_{ij} , \psi^n_{ij})^T \) at the beginning of each time step. We compute those values  once and store them in the solver.

Furthermore, as it is needed later on, we derive its Jacobian with respect to the current grid point \( (\phi^{n+1}_{ij} , \mu^{n+\frac{1}{2}}_{ij})^{T} \):

\begin{align*}
DL\begin{pmatrix}
\phi_{ij} \\
\mu_{ij}
\end{pmatrix} &= \begin{pmatrix}
\frac{1}{\Delta t} & \frac{1}{h^2}\Sigma_{Gij}  \\
-\frac{\varepsilon^2}{h^2}\Sigma_{Gij} - 2 & 1
\end{pmatrix}
\end{align*}
Implementation details can be found in the Apendix under  [[*baseline][baseline]].
** SMOOTH operator
The authors [cite:@SHIN20117441]derived Gauss-Seidel Smoothing from:
#+name: eq:smooth
\begin{align}
L
\begin{pmatrix}
\phi^{n+1}_{ij} \\
\mu^{n+\frac{1}{2}}_{ij}
\end{pmatrix}
&=
\begin{pmatrix}
\zeta^n_{ij} \\
\psi^n_{ij}
\end{pmatrix}
\end{align}
 SMOOTH consists of point-wise Gauss-Seidel relaxation, by solving Eq.[[eq:smooth]] for all \( i,j \) with the initial guess for \( \zeta^n_{ij} , \psi^n_{ij} \). Since \( L \) is linear we can write Eq.[[eq:smooth]] as
 #+name: eq:explicit-smooth
 \begin{equation}
\begin{aligned}
\begin{pmatrix}
  \zeta_{ij}^n\\
\psi_{ij}^n
\end{pmatrix}
&=
DL\begin{pmatrix}
\phi_{ij}^{n+1} \\
\mu_{ij}^{n+\frac{1}{2}}
\end{pmatrix}
\cdot
\begin{pmatrix}
\phi^{n+1}_{ij} \\
\mu^{n+\frac{1}{2}}_{ij}
\end{pmatrix}
+
\begin{pmatrix}
 - \frac{1}{h^2} \Sigma_{Gij}\mu_{ij}^{n+\frac{1}{2}} \\
+ \frac{\varepsilon^2}{h^2} \Sigma_{Gij}\phi_{ij}^{n+1} \\
\end{pmatrix}
\\
\begin{pmatrix}
  \zeta_{ij}^n\\
\psi_{ij}^n
\end{pmatrix}
-
\begin{pmatrix}
 - \frac{1}{h^2} \Sigma_{Gij}\mu_{ij}^{n+\frac{1}{2}} \\
+ \frac{\varepsilon^2}{h^2} \Sigma_{Gij}\phi_{ij}^{n+1} \\
\end{pmatrix}
&=
DL\begin{pmatrix}
\phi_{ij}^{n+1} \\
\mu_{ij}^{n+\frac{1}{2}}
\end{pmatrix}
\cdot
\begin{pmatrix}
\phi^{n+1}_{ij} \\
\mu^{n+\frac{1}{2}}_{ij}
\end{pmatrix}
\end{aligned}
\end{equation}
where
- \(  \Sigma_G \phi_{ij}^{n+1} = G_{i+\frac{1}{2}j} \phi^{n + 1,m}_{i+1j} +  G_{i-\frac{1}{2}j} \phi^{n + 1,m}_{i-1j} + G_{ij+\frac{1}{2}}  \phi^{n + 1,m}_{ij+1} + G_{ij-\frac{1}{2}} \phi^{n + 1,m}_{ij-1}  \),
- \(  \Sigma_G \mu_{ij} = G_{i+\frac{1}{2}j} \mu^{n + \frac{1}{2},m}_{i+1j} +  G_{i-\frac{1}{2}j} \mu^{n + \frac{1}{2},m}_{i-1j} + G_{ij+\frac{1}{2}}  \mu^{n + \frac{1}{2},m}_{ij+1} + G_{ij-\frac{1}{2}} \mu^{n + \frac{1}{2},m}_{ij-1}  \),
In order to compute \( \left(   \phi_{ij}^{n+1} , \mu^{n+\frac{1}{2}}_{ij}  \right) \) we have to evaluate those grid-wise functions on at neighbouring indicies \( k,l \) eg. \( k=i+1 , l=j-1 \).
since values for \( \phi_{kl}^{n+1,m} , \mu_{kl}^{n+\frac{1}{2},m} \) are unknown,if \( k > i , l > j \), the authors in [cite:@SHIN20117441] and we use initial approximations,   and the values of the current smooth iteration else. As initial approximation we use the values of \(  \phi_{kl}^{n+1,m} , \mu_{kl}^{n+\frac{1}{2},m}  \) from the last smoothing iteration.
The equation Eq.[[eq:explicit-smooth]] is of form \(b = Ax\)
We then and solve Eq.[[eq:explicit-smooth]] for \( \left( \phi_{ij}^{n+1} , \mu^{n+\frac{1}{2}}_{ij}  \right)  \).
#+name: calculate-left-hand-side-b
#+begin_src julia :eval never :exports none
bordernumber = neighbours_in_domain(i, j, G, solver.len, solver.width)

b = [(
            solver.xi[i, j]
            +
            discrete_G_weigted_neigbour_sum(
                i, j, solver.potential, G, solver.len, solver.width
            ) / solver.h^2
        ), (
            solver.psi[i, j]
            -
            (solver.epsilon^2 / solver.h^2) * discrete_G_weigted_neigbour_sum(
                i, j, solver.phase, G, solver.len, solver.width
            ))]


#+end_src
#+name:SMOOTH
#+begin_src julia :tangle src/multisolver.jl :eval never :noweb no-export
function SMOOTH!(
    solver::T,
    iterations,
    adaptive
) where T <: Union{multi_solver, adapted_multi_solver , gradient_boundary_solver}
    for k = 1:iterations
        # old_phase = copy(solver.phase)
        for I in CartesianIndices(solver.phase)[2:end-1, 2:end-1]
            i, j = I.I

            <<calculate-left-hand-side-b>>

            res = dL(solver, i,j ) \ b
            solver.phase[i, j] = res[1]
            solver.potential[i, j] = res[2]
        end
    end
end
#+end_src
In Fig.[[fig:smoothing-examples]] we show 4 of the 7 initial data after one 200 iterations of smoothing. It is apparent that the sharp interface from the initial Data has diffused.
#+name: fig:smoothing-examples
#+begin_src julia-vterm :results file graphics  :file smooth.svg
<<input>>
<<setup-diverse-testgrids>>
plots= []
for t in tests
set_xi_and_psi!(t[1])
SMOOTH!(t[1], 200, true);
end
plots =[  heatmap(t[1].phase ,  legend=:none , aspectratio=:equal , grid=false , showaxis=false , size=(600,600))
          for t in tests[1:2:end]]
p = plot(plots... , layout=(1,4) , size=(2400,600))
savefig(p,"images/smooth.svg")

#+end_src

#+caption: inputs from [[Initial data]] after SMOOTH.
#+RESULTS[fdb9207550b6615253fa672f5417f153b861be3b]: fig:smoothing-examples
[[file:images/smooth.svg]]

** Multigrid method
The numerical method proposed in [cite:@SHIN20117441] consists of a V-cycle multi-grid method derived from previously stated operators. Specificly we use a two-grid implementation consisting of.
1. a Gauss-Seidel relaxation for smoothing Chapter [[SMOOTH operator]].
2. calculate the residual error in phase and potential \( d_{ij,H}^{n+1,m} , r_{ij,H}^{n+1,m} \).
3. restriction and prolongation methods between grids \(  h \leftrightarrow H  \).
4. a Newton iteration to solve \( L(\phi_{ij,H}^{n+1,m}, \mu_{ij,H}^{n+\frac{1}{2},m})_H = L(\bar{\phi}_{ij,H}^{n+1,m} , \bar{\mu}_{ij,H}^{n+\frac{1}{2},m}) + (d_{ij,H}^{n+1,m} , r_{ij,H}^{n+1,m}) \).
   we solve using the same iteration as in Chapter [[SMOOTH operator]] however we replace \( (\zeta_{ij}^{n} , \psi_{ij}^n) \) with  \(  L(\bar{\phi}_{ij,H}^{n+1,m} , \bar{\mu}_{ij,H}^{n+\frac{1}{2},m}) + (d_{ij,H}^{n+1,m} , r_{ij,H}^{n+1,m}) \).  in the iteration, where \( \bar{\phi}_{ij,H}^{n+1,m} , \bar{\mu}_{ij,H}^{n+\frac{1}{2},m} \) are the values after the smooth restricted to the coarser grid and \( d_{ij,H}^{n+1,m} , r_{ij,H}^{n+1,m} \) is the residual from the smooth  iteration on the fine grid restricted onto the coarse grid.
5. post smoothing

#+name: restrict-to-coarse-grid
#+begin_src julia :eval never :exports none
restrict_solver!(grid[level], grid[level+1])
solver = grid[level+1]
solution = deepcopy(solver)

d_large = restrict(d, G)
r_large = restrict(r, G)


u_large = zeros(size(d_large))
v_large = zeros(size(d_large))

#+end_src
#+name: prolong-to-fine-grid
#+begin_src julia :eval never :exports none
u_large = solver.phase .- solution.phase
v_large = solver.potential .- solution.potential

solver = grid[level]

solver.phase .+= prolong(u_large , G)
solver.potential .+= prolong(v_large, G)

#+end_src
The V-cycle of a two-grid method using pre and post smoothing is then stated by:
#+begin_src julia :tangle src/multisolver.jl :eval never :noweb no-export
function v_cycle!(grid::Array{T}, level) where T <: solver
    solver = grid[level]
    #pre SMOOTHing:
    SMOOTH!(solver, 400, false)

    d = zeros(size(solver.phase))
    r = zeros(size(solver.phase))

    # calculate error between L and expected values
    for I in CartesianIndices(solver.phase)[2:end-1, 2:end-1]
        d[I], r[I] = [solver.xi[I], solver.psi[I]] .- L(solver, I.I..., solver.phase[I], solver.potential[I])
    end

    <<restrict-to-coarse-grid>>

    #Newton Iteration for solving smallgrid
    for i = 1:300
        for I in CartesianIndices(solver.phase)[2:end-1, 2:end-1]

            diffrence = L(solution, I.I..., solution.phase[I], solution.potential[I])
                        .- [d_large[I], r_large[I]]
                        .- L(solver, I.I..., solver.phase[I], solver.potential[I])

            local ret = dL(solution, I.I...) \ diffrence

            u_large[I] = ret[1]
            v_large[I] = ret[2]
        end
        solution.phase .-= u_large
        solution.potential .-= v_large
    end

    <<prolong-to-fine-grid>>

    SMOOTH!(solver, 800, false)
end
#+end_src


The iteration of the solver is then done as follows
#+begin_src julia :eval never :exports code
for j in 1:timesteps

    set_xi_and_psi!(solvers[1])

    for i = 1:subiterations

        v_cycle!(solvers, 1)
    end
end
#+end_src
After a few iterations, V-cycle exhibits the following behavior:

#+name: fig:solver-iteration
#+begin_src julia-vterm :results file graphics  :file iteration.gif :noweb no-export :async t :exports results :output-dir images  :tangle src/plot.jl :session jl :eval never-export
<<init>>
using JLD2
using DataFrames
results = jldopen("experiments/iteration.jld2")["result"]
anim = @animate for res in eachrow(results)
    heatmap(res.solver.phase , title="phase field" , legend=:none , aspectratio=:equal , showaxis=false , grid=false , size=(400 ,400))
end
gif(anim , "images/iteration.gif" , fps = 10)
#+end_src

#+caption: a fex timesteps of the solver for different initial contitions as shown in [[Initial data]]
#+RESULTS: fig:solver-iteration
[[file:images/iteration.gif]]

* Numerical experiments
The analytical CH equation conserves mass Eq.[[eq:massbal]] and the free energy ,\( E_{bulk} \), Eq.[[eq:energy]]  decreases in time, i.e. consistence with the second law of thermodynamics. Therefore, we use discrete variants of those concepts as necessary conditions for a "good" solution. Furthermore, since \( E_{bulk} \) is closely correlated with chemical potential, \( \mu \), we evaluate this difference as quality of convergence.
** Energy evaluations
As discrete energy measure we use:
#+name: eq:discrete-energy
\begin{equation}
\begin{aligned}
E^{\text{bulk}}_d(\phi_{ij}) &= \sum_{i,j \in \Omega} \frac{\varepsilon^2}{2} |G\nabla_d \phi_{ij} |^2 + W\left(\phi_{ij}\right)  \\
&= \sum_{i,j \in \Omega} \frac{\varepsilon^2}{2} G_{i+\frac{1}{2}j}(D_x\phi_{i+\frac{1}{2}j}) ^2 + G_{ij+\frac{1}{2}}(D_y\phi_{ij+\frac{1}{2}})^2  + W\left(\phi_{ij}\right)  \\
\end{aligned}
\end{equation}
Since the continous Helmholtz energy Eq.[[eq:energy]].
#+begin_src julia :tangle src/utils.jl :eval never
function bulk_energy(solver::T) where T <: Union{multi_solver , relaxed_multi_solver}
    energy = 0
    dx = CartesianIndex(1,0)
    dy = CartesianIndex(0,1)
    W(x) = 1/4 * (1-x^2)^2
    for I in CartesianIndices(solver.phase)[2:end-1,2:end-1]
        i,j = I.I
        energy += solver.epsilon^2 / 2 * G(i+ 0.5,j ,solver.len, solver.width) * (solver.phase[I+dx] - solver.phase[I])^2 + G(i,j+0.5,solver.len ,solver.width) * (solver.phase[I+dy] - solver.phase[I])^2 + W(solver.phase[I])
        end
   return energy
end
#+end_src


#+name: fig:energy-balance
#+begin_src julia-vterm :results file graphics :file energy_balance.svg
<<init>>
using JLD2
using DataFrames
i0 = 1*64 +1
results = jldopen("experiments/iteration.jld2")["result"]
energy = bulk_energy.(results[i0:i0+63,:].solver)
p1 = plot(1:64 , energy , title=L"Discrete Helmholtz Energy $E_d^{bulk}$", xlabel="timesteps" , ylabel="energy"  , label=false)
p2 = heatmap(results.solver[i0].phase , title="initial condition" , legend=:none , aspectratio=:equal , showaxis=false , grid=false)
p3 = heatmap(results.solver[i0+63].phase , title="after 64 time-steps" , aspectratio=:equal , legend=:none , showaxis=false , grid=false)
p = plot(p2,p3,p1 , layout=layout3x1 , size=size3x1  )

savefig(p , "images/energy_balance.svg")
#+end_src

#+caption: behaviour of energy \( E_{bulk} \) over time for one initial condition \( \phi_0 \).
#+RESULTS: fig:energy-balance
[[file:images/energy_balance.svg]]

here we observe the discrete Helmholtz energy going down with increasing number of timesteps, as we expect from a cahn hilliard based solver.
** Numerical mass conservation
Instead of a physical mass we use the average of \(\phi\) over the domain \(\Omega\).
This yields a balance between both phases. Since the analytical CH equation Eq.[[eq:CH]] is mass conserving we require a good numerical implementation to exhibit as few loss in mass as possible. Since our implementation uses no-flow boundary conditions the balance between /phase 1/ and /phase 2/ stays the same. We therefore calculate a balanace
\begin{align*}
b &= \frac{\sum_{i,j \in \Omega} \phi_{ij}}{N^2}
\end{align*}
such that \( b = 1 \) means there is only phase 1, \( \phi \equiv 1 \), and \( b = -1 \) means there is only phase 2, \( \phi \equiv -1 \).
Ideally this value stays constant over time.
In practice we observe slight fluctuations in Figure [[fig:mass-balance]]. Those however are close to machine precision and can therefore be ignored.
#+begin_src julia :tangle src/utils.jl
function massbal(arr)
    num_cells= *((size(arr).-2)...)
    return sum(arr[2:end-1, 2:end-1])/num_cells
    end
#+end_src

#+name: fig:mass-balance
#+begin_src julia-vterm :results file graphics :file mass_balance.svg :output-dir images :noweb no-export :session jl
<<init>>
using JLD2
using DataFrames
using Measures
pgfplotsx()
i0 = 64 * 1 + 1
results = jldopen("experiments/iteration.jld2")["result"]
energy = [ massbal(s.phase) for s in results[i0:i0+63,:].solver]
p1 = plot(1:64 ,
          energy .- energy[1],
          xlabel= "time-steps" ,
          ylabel = "error" ,
          title = "phase change",
          label=false)
p2 = heatmap(results.solver[i0].phase ,
             title="initial condition" ,
             legend=:none ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false)
p3 = heatmap(results.solver[i0+63].phase ,
             title="after 64 time-steps" ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false ,
             legend=:none)

p = plot(p2,
         p3 ,
         p1 ,
         layout= layout3x1 ,
         size=size3x1)

savefig(p , "images/mass_balance.svg")
#+end_src

        #+caption: behaviour of phase change over time for one initial condition \( \phi_0 \).
#+RESULTS: fig:mass-balance
[[file:images/mass_balance.svg]]

** Stability of a multigrid sub iteration
We expect our solver to stay stable when increasing the number of multigrid sub-iterations. To validate this assumption we compare the phase-field of the current sub-iteration \( \phi^{n+1,m}_{ij} \) with the phse-field of the previous sub-iteration \( \phi_{ij}^{n+1,m-1} \).
\begin{equation}
\| \phi^{n+1,m-1} - \phi^{n+1,m} \|_{Fr}= \sqrt{ \sum_{i,j \in \Omega_d} \left|   \phi^{n+1,m-1}_{ij} - \phi^{n+1,m}_{ij} \right| }
\end{equation}
 As sub-iterations increase , \( m\to\infty \),  we expect the difference between both phase-fields to go to zero \( \|\phi^{n+1,m} - \phi^{n+1,m-1}\|_{Fr} \to 0 \). We observe this behaviour in Figure [[fig:convergence]]
#+name: fig:convergence
#+begin_src julia-vterm :results file graphics :file convergence.svg
<<init>>
<<setup-diverse-testgrids>>
using DataFrames
using JLD2
using LaTeXStrings
i0 = 4
df = jldopen("experiments/subiteration.jld2")["result"]
gd = groupby(df , :iteration)
res = combine(gd  , :cycle => ((x)-> [norm(x[i].phase - x[i-1].phase) for i in 2:size(x,1)]))

gres =  groupby(res , :iteration)[1]
p1= res.cycle_function[i0*64:(i0+1)*64-2] |>
    (x)-> plot(x ,
               yscale=:log10 ,
               title="Behaviour" ,
               xlabel="sub-iterations" ,
               ylabel= "diffrence" ,
               label= L" \|\phi^{n+1,m} - \phi^{n+1,m-1}\|_{Fr} ")
p2 = heatmap(df.cycle[i0].phase ,
             title="initial condition" ,
             legend=:none ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false)
p3 = heatmap(df.cycle[i0].phase .-df.cycle[i0+62].phase ,
             title="after 64 subiteration" ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false )

p = plot(p2,
         p3 ,
         p1 ,
         layout= layout3x1 ,
         size=(1600 , 1600))
savefig(p , "images/convergence.svg")
#+end_src

#+caption: stability of the original CH solver for increasing sub-iterations
#+RESULTS: fig:convergence
[[file:images/convergence.svg]]

in practise we observe the behaviour we expect, where an increasing number of sub-iterations leads to decreasing change compared to the previous sub-iteration.

#+begin_src julia-vterm :results file graphics :file subiteration.svg :output-dir images :noweb no-export :session jl :exports none
<<init>>
using DataFrames
using JLD2
using LaTeXStrings
df = jldopen("experiments/subiteration.jld2")["result"]
gd = groupby(df , :iteration)
p1 = heatmap(gd[1].cycle[1].phase , aspectratio=:equal , title= "one subiteration" , showaxis=false  )
p2 = heatmap(gd[1].cycle[64].phase , aspectratio=:equal , title = "64 sub-iterations" , showaxis=false)
p = plot(p1,p2)
savefig(p , "images/subiteration.svg")
#+end_src

#+RESULTS:
[[file:images/subiteration.svg]]

** Stability in time
We expect our numerical error to decrease when calculating with smaller time steps. To test this, we  succesivly subdivide the original time interval \( [0,T] \) in finer parts. We fix \( \Delta t \cdot n = T \) for \( T=10^{-2} \) and test different values of \( n \). In Figure [[fig:stability-in-time]] we compare the phase-field \( \phi^{n}_{ij} \) and \( \phi^{n-1}_{ij}  \) at \( T=10^{-2} \). and observe the decrease we expect.
#+name: fig:stability-in-time
#+begin_src julia-vterm :results file graphics :file time-stability.svg
<<init>>
using DataFrames
using JLD2
using LaTeXStrings

df = jldopen("experiments/time.jld2")["result"]
gd = groupby(df , :iteration)

sd =  combine(x->(;phase=x[end,:].phase) , gd)
change = [norm(sd[!, "phase"][i] .- sd[! , "phase"][i-1]) for i=2:size(sd , 1)]

p1 = plot(change ,
         ylabel = "difference to previous number time-steps" ,
         xlabel = L"number of time-steps to $t = 10^{-2}s$" ,
         label=L"\|\phi_{ij}^{n+1} - \phi_{ij}^n \|_{Fr}" ,
         title= L"behavior of the original CH solver at $t=10^{-2}s$")
p2 = heatmap(gd[32].phase[end],
             title=L"$t=10^{-2} \,, n=32$" ,
             legend=:none ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false)
p3 = heatmap(gd[end].phase[end],
             title=L"$t=10^{-2} \,, n=64$" ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false ,
             legend=:none)

p = plot(p2,
         p3 ,
         p1 ,
         layout= layout3x1 ,
         size=size3x1)
savefig(p , "images/time-stability.svg")
#+end_src

#+Caption: behavior of the baseline solver while solving the time interval \( T = \left[ 0 , 10^{-2} \right] \) with increasing number of time-steps.
#+RESULTS[c9dd717190350aef1329f2cbdb26859677756133]: fig:stability-in-time
[[file:images/time-stability.svg]]

** Stability in space
We expect our methods to be stable under different grid-sizes \( h \) and gridpoints \( N \). Therefore we expect the difference after one time-step between eg. a \( 512 \times 512 \) grid and a \( 1024 \times 1024 \) grid to be smaller than the difference between a \( 64 \times 64 \) grid and a \( 128 \times 128 \) grid. In order to keep the problem the same , we fix \( Nh = 10^{-3} \cdot 1024 \) and test for \( N \in \left\{ 1024 , 512 , 256 , 128 , 64 , 32 \right\} \)
#+name: fig:stability-in-space
#+begin_src julia-vterm :results file graphics :file space-stability.svg
<<init>>
using DataFrames
using JLD2
using LaTeXStrings
df = jldopen("experiments/space_refinement.jld2")["result"]
gd = groupby(df , :iteration)
change = [norm(df[!, "phase"][i] .- restrict(df[! , "phase"][i-16] , G))/*(size(df[!,"phase"][i])...) for i=17:16:size(df , 1)]
p1 = plot([L"1024^2 \to 512^2" , L"512^2 \to 256^2" , L"256^2\to128^2" , L"128^2\to64^2" , L"64^2 \to32^2"],
         change ,
         ylabel = "difference" ,
         yscale=:log10,
         xlabel = "change in number of gridpoints" ,
         label=L"\Delta \phi" ,
         xscale=:log2 ,
         seriestype=:scatter ,
         xaxis=:flip ,
         legend=:topright)

p2 = heatmap(gd[16].phase[begin],
             title=L"1024 \times 1024" ,
             legend=:none ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false)
p3 = heatmap(gd[16].phase[4],
             title=L"128 \times 128" ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false ,
             legend=:none)

p = plot(p2,
         p3 ,
         p1 ,
         layout= layout3x1 ,
         size=size3x1)
savefig(p , "images/space-stability.svg")
#+end_src

#+Caption: behavior of the baseline solver while solving on successively finer grids
#+RESULTS[d65d9dfebf929c604fd273a9c1ffcfd955bb13e0]: fig:stability-in-space
[[file:images/space-stability.svg]]

* Relaxed problem
In effort to decrease the order of complexity, from fourth order derivative to second order, we propose an elliptical relaxation approach, where the relaxation variable \( c \) is the solution of the following elliptical PDE:
#+name: eq:elliptical-equation
\begin{align}
- \Delta c^\alpha  + \alpha c^a &= \alpha \phi ^\alpha,
\end{align}
where \( \alpha \) is a relaxation parameter. We expect to approach the original solution of the CH equation Eq.[[eq:CH]] as  \( \alpha \to \infty \).
This results in the following relaxation for the classical CH equation Eq.[[eq:CH]]:
#+name: eq:relaxed-cahn-hilliard
\begin{equation}
\begin{aligned}
\partial_t \phi^\alpha  &= \Delta \mu \\
\mu &= \varepsilon ^2 \alpha(c^\alpha - \phi^\alpha) + W'(\phi)
\end{aligned}
\end{equation}
It requires solving the elliptical PDE each time-step to calculate \(c\).

As ansatz for the numerical solver we propose:
#+name: eq:discrete-relaxed-cahn-hilliard
\begin{equation}
\begin{aligned}
\frac{\phi_{ij}^{n+1,\alpha} - \phi_{ij}^{n,\alpha}}{\Delta t}  &=  \nabla _d \cdot (G_{ij} \nabla_d \mu_{ij}^{n+\frac{1}{2},\alpha} )  \\
 \mu_{ij}^{n+\frac{1}{2},\alpha} &= 2\phi_{ij}^{n+1,\alpha} - \varepsilon^2 a(c_{ij}^{n+1,\alpha} - \phi_{ij}^{n+1,\alpha})  + W'(\phi_{ij}^{n,\alpha}) - 2\phi _{ij}^{n,\alpha}
\end{aligned}
\end{equation}
This approach is inspired by Eq.[[eq:discrete-cahn-hilliard]] adapted to the relaxed CH equation Eq.[[eq:discrete-relaxed-cahn-hilliard]].
We then adapt the multi-grid solver proposed in [[Baseline multi-grid solver]] to the relaxed problem by replacing the differential operators by their discrete counterparts as defined in Eq.[[eq:discretization]],
and expand them.
** Elliptical PDE
In order to solve the relaxed CH equation we solve the following PDE in each  time step:
\begin{align*}
- \nabla \cdot  (G \nabla c^\alpha) + \alpha c^\alpha  = \alpha \phi ^\alpha
\end{align*}

Similarly to the first solver we solve this PDE  with a finite difference scheme using the same discretization as before.
*** Discretization
The discretization of the PDE expands the differential operators in the same way and proposes an equivalent scheme for solving the elliptical equation Eq.[[eq:elliptical-equation]].
\begin{align*}
- \nabla_d \cdot  (G_{ij} \nabla_d c_{ij}^\alpha) + \alpha  c_{ij}^\alpha &= \alpha \phi_{ij}^\alpha
\end{align*}
\( \implies \)
\begin{align*}
- (\frac{1}{h}(G_{i+\frac{1}{2}j} \nabla c^\alpha_{i+\frac{1}{2}j} + G_{ij+\frac{1}{2}} \nabla c^\alpha_{ij+\frac{1}{2}}) &  \\
- (G_{i-\frac{1}{2}j} \nabla c^\alpha_{i-\frac{1}{2}j} + G_{ij-\frac{1}{2}} \nabla c^\alpha_{ij-\frac{1}{2}})) + \alpha  c_{ij}^\alpha   &= \alpha  \phi_{ij}^\alpha
\end{align*}
\( \implies \)
\begin{align*}
- \frac{1}{h^2} ( G_{i+\frac{1}{2}j}(c_{i+1j}^\alpha - c_{ij}^\alpha) & \\
+G_{ij+\frac{1}{2}}(c_{ij+1}^\alpha - c_{ij}^\alpha) & \\
+G_{i-\frac{1}{2}j}(c_{i-1j}^\alpha - c_{ij}^\alpha)& \\
+G_{ij-\frac{1}{2}}(c_{ij-1}^\alpha - c_{ij}^\alpha)) + \alpha  c_{ij}^\alpha &=\alpha  \phi_{ij}^\alpha
\end{align*}


As before we abbreviate \(  \Sigma_G c^\alpha_{ij} = G_{i+\frac{1}{2}j} c^\alpha_{i+1j} +  G_{i-\frac{1}{2}j} c^\alpha_{i-1j} + G_{ij+\frac{1}{2}}  c^\alpha_{ij+1} + G_{ij-\frac{1}{2}} c^\alpha_{ij-1}  \) and \(  \Sigma_{Gij} = G_{i+\frac{1}{2}j} + G_{i-\frac{1}{2}j} + G_{ij+\frac{1}{2}} + G_{ij-\frac{1}{2}}  \). Then the discrete elliptical PDE can be stated as:
#+name: eq:discrete_elyps
\begin{align}
-\frac{ \Sigma_G c^\alpha_{ij}}{h^2} + \frac{\Sigma_G}{h^2} c^\alpha_{ij} + \alpha c^\alpha_{ij} &= \alpha\phi^\alpha_{ij}
\end{align}

solving Eq.[[eq:discrete_elyps]] for \(c_{ij}^\alpha \) then results in.
\begin{align*}
\left( \frac{\Sigma_{Gij}}{h^2} + \alpha \right)c_{ij}^{\alpha} = \alpha\phi^{\alpha}_{ij} + \frac{\Sigma_G c_{ij}^{\alpha}}{h^2}\\
c_{ij}^{\alpha} = \frac{\alpha\phi^{\alpha}_{ij} + \frac{\Sigma_G c_{ij}^{\alpha}}{h^2}}{\frac{\Sigma_{G}}{h^2} + \alpha}\\
c_{ij}^{\alpha} = \frac{\alpha h^2 \phi^{\alpha}_{ij}}{\Sigma_{Gij} + \alpha h^2} + \frac{\Sigma_G c_{ij}^{\alpha}}{\Sigma_{Gij} + \alpha h^{2}}
\end{align*}
and can be translated to code as follows
#+begin_src julia :eval never :tangle src/elypssolver.jl :exports none
using ProgressBars

"""
    elyps_solver(c,
    phase,
    len,
        width,
    alpha,
    h,
    n
)

TBW
"""
#+end_src
#+name: elyps_solver
#+begin_src julia :eval never :tangle src/elypssolver.jl
function elyps_solver!(solver::T, n) where T  <: Union{relaxed_multi_solver , adapted_relaxed_multi_solver}
    for k in 1:n
        for i = 2:(solver.len+1)
            for j = 2:(solver.width+1)
                bordernumber = neighbours_in_domain(i, j,G, solver.len, solver.width)
                solver.c[i, j] =
                    (
                        solver.alpha * solver.phase[i, j] +
                        discrete_G_weigted_neigbour_sum(i, j, solver.c, G, solver.len, solver.width) / solver.h^2
                    ) / (bordernumber / solver.h^2 + solver.alpha)

            end
        end
    end
end
#+end_src
** Relaxed PDE as operator L
We reformulate the discretization Eq.[[eq:discrete-relaxed-cahn-hilliard]] in terms of the relaxed operator \(L\) as follows:
\begin{align*}
L_r
\begin{pmatrix}
\phi ^{n+1,\alpha} \\
\mu^{n+\frac{1}{2},\alpha}
\end{pmatrix}
&=
\begin{pmatrix}
\frac{\phi^{n+1,m,\alpha}_{ij}}{\Delta t} - \nabla _d \cdot (G_{ji} \nabla _d \mu^{n + \frac{1}{2},m,\alpha}_{ji}) \\
\varepsilon ^2 \alpha (c^\alpha - \phi^{n+1,m,\alpha}_{ij}) - 2\phi ^{n+1,m,\alpha}_{ij} -\mu^{n + \frac{1}{2},m,\alpha}_{ji}
\end{pmatrix}
\end{align*}

and its Jacobian:
\begin{align*}
DL_r\begin{pmatrix}
\phi \\
\mu
\end{pmatrix} &= \begin{pmatrix}
\frac{1}{\Delta t} & \frac{1}{h^2}\Sigma_{G}  \\
- \varepsilon^2 \alpha  - 2 & 1
\end{pmatrix}
\end{align*}

** The relaxed multigrid method
As the difference between both methods is abstracted away in the operators, the relaxed V-cycle the replaces the original operators with their relaxed counterparts. Due to julias multiple dispatch features this changes nothing in the implementation Therefore we reuse the original V-cycle in the [[Multigrid method]].
In the executions for each time step, we add the elliptic solver in the subiteration.
#+begin_src julia :eval never :exports code
for j in 1:timesteps

    set_xi_and_psi!(solvers[1])

    for i = 1:subiterations

        elyps_solver!(solvers[1] , 1000)
        v_cycle!(solvers, 1)
    end
end
#+end_src

#+name: fig:relaxed-anim
#+begin_src julia-vterm :results file graphics :file relaxed-anim.gif
<<init>>
using JLD2
using DataFrames
using Measures

gr()

results = jldopen("experiments/relaxed-iteration4.jld2")["result"]
anim = @animate for s in results.solver
    heatmap(s.phase)
    end
gif(anim , "images/relaxed-anim.gif", fps=10)
#+end_src

#+RESULTS: fig:relaxed-anim
[[file:images/relaxed-anim.gif]]

** SMOOTH operator
The relaxed solver uses the same approach as the original solver, where we solve \( L_r(\phi^{n+1,m,\alpha}_{ij}, \mu^{n+\frac{1}{2},m,\alpha}_{ij}) = (\zeta_{ij}^n , \psi_{ij}^n)^T \) for each grid-point \( \phi_{ij}^{n+1,m,\alpha} \). Notably \((\zeta_{ij}^n , \psi_{ij}^n)^T  \) is the same as in the original part. As in the original smoothing, evalations of \( \mu^{n+\frac{1}{2},m,\alpha}_{kl} \) for \( k,l > i,j \) are replaced with their values from the previous SMOOTH iteration.

Correspondingly the SMOOTH operation expands to:
#+name: eq:discrete-relaxed-smooth
\begin{equation}
\begin{aligned}
  -\frac{\Sigma_{Gij}}{h^2}\overline{\mu^{n + \frac{1}{2},m,\alpha}_{ji}} &= \frac{\phi ^{n+1,m,\alpha}_{ij}}{\Delta t} - \zeta^{n,\alpha}_{ij} - \frac{\Sigma_G\mu_{ij}}{h^2} \\
 \varepsilon ^2 \alpha \overline{\phi ^{n+1,m,\alpha}_{ij}} + 2 \phi ^{n+1,m,\alpha}_{ij} &= \varepsilon ^2 \alpha c^{n,\alpha}_{ij}  -\overline{\mu^{n + \frac{1}{2},m,\alpha}_{ji}}  - \psi_{ij}^{n,\alpha}
\end{aligned}
\end{equation}
where
- \(  \Sigma_G \mu_{ij} = G_{i+\frac{1}{2}j} \mu^{n + \frac{1}{2},m}_{i+1j} +  G_{i-\frac{1}{2}j} \mu^{n + \frac{1}{2},m}_{i-1j} + G_{ij+\frac{1}{2}}  \mu^{n + \frac{1}{2},m}_{ij+1} + G_{ij-\frac{1}{2}} \mu^{n + \frac{1}{2},m}_{ij-1}  \),
We then solve directly for the smoothed variables, \( \overline{\mu_{ij}^{n+1,m,\alpha}} \) and \( \overline{\phi_{ij}^{n+1,m,\alpha}} \). This was not done in the original paper [cite:@SHIN20117441] because the required system of linear equations in the paper [cite:@SHIN20117441]  was solved numerically.
\begin{align*}
\varepsilon^2 \alpha(\phi_{ij}^{n+1,m,\alpha}) + 2\phi_{ij}^{n+1,m,\alpha} &= \varepsilon^2 \alpha c^\alpha - \frac{h^2}{\Sigma_G} (\frac{\phi_{ij}^{n+1,m,\alpha}}{\Delta t} - \zeta^n_{ij} - \frac{1}{h^2} \Sigma_G \mu_{ij}) - \psi_{ij}
\end{align*}
\( \implies \)
\begin{align*}
\varepsilon^2\alpha (\phi_{ij}^{n+1,m,\alpha}) + 2\phi_{ij}^{n+1,m,\alpha} + \frac{h^2}{\Sigma_{Gij}}\frac{\phi_{ij}^{n+1,m,\alpha}}{\Delta t} &= \varepsilon^2 \alpha c^\alpha - \frac{h^2}{\Sigma_G} (- \zeta^n_{ij} - \frac{1}{h^2} \Sigma_G \mu_{ij}) - \psi_{ij}
\end{align*}
\( \implies \)
\begin{align*}
(\varepsilon^2 \alpha + 2 + \frac{h^2}{\Sigma_G \Delta t}) \phi_{ij}^{n+1,m,\alpha} &= \varepsilon^2 \alpha c^\alpha - \frac{h^2}{\Sigma_G}(- \zeta^n_{ij} - \frac{\Sigma_G \mu_{ij}}{h^2} ) -\psi_{ij}
\end{align*}
\( \implies \)
\begin{align*}
 \phi_{ij}^{n+1,m,\alpha} &= \left(\varepsilon^2 \alpha c^\alpha - \frac{h^2}{\Sigma_G}(- \zeta^n_{ij} - \frac{\Sigma_G \mu_{ij}}{h^2} ) -\psi_{ij}\right)\left(\varepsilon^2 \alpha + 2 + \frac{h^2}{\Sigma_G \Delta t}\right)^{-1}
\end{align*}
#+name: solve-for-phi
#+begin_src julia :eval never :exports none
bordernumber = neighbours_in_domain(i, j, G, solver.len, solver.width)

solver.phase[I] = (solver.epsilon^2 * solver.alpha * solver.c[I] - solver.h^2 / bordernumber * ( -solver.xi[I]  - discrete_G_weigted_neigbour_sum(i,j,solver.potential , G , solver.len , solver.width) / solver.h^2 ) - solver.psi[I]) / (solver.epsilon^2 * solver.alpha  + 2 + solver.h^2 / (bordernumber*solver.dt))
#+end_src
#+name: update-the-potential
#+begin_src julia :eval never :exports none
            solver.potential[I] = (solver.phase[I]/solver.dt - solver.xi[I] - discrete_G_weigted_neigbour_sum(i,j, solver.potential , G , solver.len , solver.width)/solver.h^2) * (-solver.h^2/bordernumber)
#+end_src
#+name: SMOOTH_relaxed
#+begin_src julia :eval never :tangle src/multi_relaxed.jl :noweb no-export
function SMOOTH!(
    solver::T,
    iterations,
    adaptive
) where T <: Union{relaxed_multi_solver , adapted_relaxed_multi_solver}
    for k = 1:iterations
        # old_phase = copy(solver.phase)
        for I in CartesianIndices(solver.phase)[2:end-1, 2:end-1]
            i, j = I.I
            <<solve-for-phi>>
            <<update-potential>>
        end

        #if adaptive && LinearAlgebra.norm(old_phase - solver.phase) < 1e-10
            ##println("SMOOTH terminated at $(k) succesfully")
            #break
        #end
    end
end
#+end_src

#+name: fig:relaxed-smooth-eval
#+begin_src julia-vterm :results file graphics :file smooth_relaxed.svg
<<init>>
plots = []
eps = 0.13
#M = testdata(64, div(64,3), 64/5 , 2)
for alpha in [1e3 , 1e4 , 1e5 , 1e6 , 32500]
local testgrd = testgrid(relaxed_multi_solver,M, 2 ; alpha=alpha , epsilon=eps)
set_xi_and_psi!(testgrd[1])
elyps_solver!(testgrd[1] , 2000)
SMOOTH!(testgrd[1], 1000, false);
push!(plots , heatmap(testgrd[1].phase, aspect_ratio=:equal, title=L"$\alpha = %$alpha$" , xlim=(2,testgrd[1].len) , ylim=(2,testgrd[1].width) , showaxis=false , legend=false));
    end

original = testgrid(multi_solver,M, 2)
set_xi_and_psi!(original[1])
SMOOTH!(original[1], 1000, false);
push!(plots , heatmap(original[1].phase, aspect_ratio=:equal, title="original" , xlim=(2,original[1].len) , ylim=(2,original[1].width) , showaxis=false , legend=false));
p = plot(plots...)
savefig(p,"images/smooth_relaxed.svg")
#+end_src

#+caption: effect of the relaxed SMOOTH operator, and additional solving of the elliptical problem, for different values of alpha
#+RESULTS: fig:relaxed-smooth-eval
[[file:images/smooth_relaxed.svg]]

Furthermore, experimentation shows that alpha alone is insufficient to get a relaxed method consistent with the original solver, since alpha had an effect similar to epsilon, where it changed the boundary thickness in the phase-field \( \phi \). Therefore epsilon and alpha cannot be chosen independently. Hence we use a simple MCMC optimizer for \( \alpha,\varepsilon \) in order to give the relaxed solver the best chance we can.
Monte Carlo Optimizer For \( \varepsilon , \alpha \).
* Relaxed Experiments
We expect the relaxed solver to behave the same as the baseline method for all test cases that we have introduced in Chapter [[Numerical experiments]]. Therefore we run the same experiments for our relaxed solver.
** Relaxed energy evaluations
we do evaluate our relaxed method using the discrete Helmoltz energy defined in Eq.[[eq:discrete-energy]]. On the same initial data, and with the same values for \( \varepsilon , h , dt \) as in the Chapter.[[Energy evaluations]]. In Figure.[[fig:relaxed-energy-balance]] we then observe the energy decay we expected. Our relaxed approach closely follows the baseline, although it consistently decayed slightly faster. This is within our expectations.
#+name: fig:relaxed-energy-balance
#+begin_src julia-vterm :results file graphics :file relaxed-energy-balance.svg
<<init>>
using JLD2
using DataFrames
i0 = 1*64 +1
original_results = jldopen("experiments/iteration.jld2")["result"]
relaxed_results = jldopen("experiments/relaxed-iteration.jld2")["result"]
original_energy = bulk_energy.(original_results[i0:i0+63,:].solver)
relaxed_energy = bulk_energy.(relaxed_results[i0:i0+63,:].solver)
p1 = plot(1:64 , original_energy , title=L"Discrete Helmholtz Energy $E_d^{bulk}$", xlabel="timesteps" , ylabel="energy"  , label="original")
p1 = plot!(p1,1:64 , relaxed_energy , title=L"Discrete Helmholtz Energy $E_d^{bulk}$", xlabel="timesteps" , ylabel="energy"  , label="relaxed")
p2 = heatmap(relaxed_results.solver[i0].phase , title="initial condition" , legend=:none , aspectratio=:equal , showaxis=false , grid=false)
p3 = heatmap(relaxed_results.solver[i0+63].phase , title="after 64 time-steps" , aspectratio=:equal , legend=:none , showaxis=false , grid=false)
p = plot(p2,p3,p1 , layout=layout3x1 , size=(1600 ,1600))
savefig(p , "images/relaxed-energy-balance.svg")
#+end_src

#+caption: energy decay of the relaxed solver compared to the original solver.
#+RESULTS[06f7ce276ee26e0f3adfda9d2fb591ad7786b44f]: fig:relaxed-energy-balance
[[file:images/relaxed-energy-balance.svg]]


We observe the discrete Helmoltz energy decrease is the same manner as with the original solver.
** Relaxed numerical mass balance
since both the CH equation Eq.[[eq:CH]] and the baseline solver from Fig.[[fig:mass-balance]] are mass conservative, the relaxed solver should be as well, to be competitive with the baseline approach. Our relaxed solver shows  mass loss around 2% as seen in Fig.[[fig:relaxed-mass-balance]]. This is nowhere near the machine precision, we reached in Fig.[[fig:mass-balance]]. However it is still tolerable.
#+name: fig:relaxed-mass-balance
#+begin_src julia-vterm :results file graphics :file relaxed-mass-balance.svg
<<init>>
using JLD2
using DataFrames
using Measures
i0 = 64 * 0+1
results = jldopen("experiments/relaxed-iteration.jld2")["result"]
energy = [ massbal(s.phase) .- massbal(results.solver[i0].phase) for s in results[i0:i0+63,:].solver]
p1 = plot(1:64 , energy, xlabel= "time-steps" , ylabel = "error"  , label =false)
p2 = heatmap(results.solver[i0].phase , title="initial condition" , legend=:none , aspectratio=:equal , grid=false , showaxis=false)
p3 = heatmap(results.solver[i0+63].phase , title="after 64 time-steps" , legend=:none , aspectratio=:equal , grid=false , showaxis=false)
p = plot(p2,p3 , p1 , layout=layout3x1 , size=(1600 ,1600))
savefig(p , "images/relaxed-mass-balance.svg")
#+end_src

#+caption: Mass los in the relaxed solver
#+RESULTS[178f08c5de1dc17908fc5f5b85bbb77b27d17b9f]: fig:relaxed-mass-balance
[[file:images/relaxed-mass-balance.svg]]

** Stability of a relaxed multigrid sub-iteration
We also compare the subiteration behaviour of the relaxed solver to the original we therefore plot \( \|\phi_{ij}^{n+1,m} - \phi_{ij}^{n+2,m-1} \|_{Fr} \) against \( \| \phi_{ij}^{n+1,m,\alpha} - \phi_{ij}^{n+1,m-1,\alpha} \| \) for \( m \in \{2, \dots , 64\} \). Here we observe instablility at about 60 sub-iterations in Fig.[[fig:relaxed-convergence]]. We are uncertain, as to why.
#+name: fig:relaxed-convergence
#+begin_src julia-vterm :results file graphics :file relaxed-convergence.svg
<<init>>
using DataFrames
using JLD2
using LaTeXStrings
n=1024

i0 = 1
df = jldopen("experiments/subiteration.jld2")["result"]
df = groupby(df , :experiment)[i0]
gd = groupby(df , :iteration)
original_res = combine(gd  , :cycle => ((x)-> [norm(x[i].phase - x[i-1].phase) for i in 2:size(x,1)]))

original_res =  groupby(original_res , :iteration)[1].cycle_function


df = jldopen("experiments/relaxed-subiteration.jld2")["result"]
df = groupby(df , :experiment)[i0]
gd = groupby(df , :iteration)
relaxed_res = combine(gd  , :cycle => ((x)-> [norm(x[i].phase - x[i-1].phase) for i in 2:size(x,1)]))

relaxed_res =  groupby(relaxed_res , :iteration)[1].cycle_function
p=plot([original_res, relaxed_res],label= ["original"  "relaxed"])
savefig(p , "images/relaxed-convergence.svg")
#+end_src

#+RESULTS: fig:relaxed-convergence
[[file:images/relaxed-convergence.svg]]

** Relaxed stability in time
we test the behaviour under refinement in time by succesivly subdividing the original time interval \( [0,T] \) in finer parts. We use the same meassure as in Chaper.[[Stability in time]] and directly compare. We observe simmilar behaviour to the original solver in Fig.[[fig:relaxed-stability-in-time]]. The relaxed solver has consisten lower difference than the original solver. This might suggest a more consistent method over time. However since the sub-iteration showed problematic behaviour, this micht also be a side-effect of this.
#+name: fig:relaxed-stability-in-time
#+begin_src julia-vterm :results file graphics :file relaxed-time-stability.svg
<<init>>
using DataFrames
using JLD2
using LaTeXStrings
df = jldopen("experiments/relaxed-time.jld2")["result"]
dfo = jldopen("experiments/time.jld2")["result"]
gdo = groupby(dfo,:iteration)
dfo = DataFrame([ last(x) for x in gdo])
change = [norm(df[!, "phase"][i] .- df[! , "phase"][i-1]) for i=2:size(df , 1)]
change0 = [norm(dfo[!, "phase"][i] .- dfo[! , "phase"][i-1]) for i=2:size(dfo , 1)]
p = plot(change , ylabel = "difference" , xlabel = "number of timesteps" , label="relaxed" )
p = plot(p , change0 , ylabel = "difference" , xlabel = "number of timesteps" , label="original")
savefig(p , "images/relaxed-time-stability.svg")
#+end_src

#+Caption: behavior of the relaxed and baseline solvers while solving the time interval \( T = \left[ 0 , 10^{-2} \right] \) with increasing number of time-steps.
#+RESULTS: fig:relaxed-stability-in-time
[[file:images/relaxed-time-stability.svg]]

** Relaxed stability in space
we test convergence in space by succesivly subdividing our grid into finer meshes


#+name: fig:relaxed-stability-in-space
#+begin_src julia-vterm :results file graphics :file relaxed-space-stability.svg
<<init>>
using DataFrames
using JLD2
using LaTeXStrings
df = jldopen("experiments/relaxed_space_refinement.jld2")["result"]
change = [norm(df[!, "phase"][i] .- restrict(df[! , "phase"][i-16] , G))/*(size(df[!,"phase"][i])...) for i=17:16:size(df , 1)]
p = plot([L"1024^2 \to 512^2" , L"512^2 \to 256^2" , L"256^2\to128^2" , L"128^2\to64^2" , L"64^2 \to32^2"],change , ylabel = "difference" , yscale=:log10, xlabel = "change in number of gridpoints" , label=L"\Delta \phi" , xscale=:log2 , seriestype=:scatter , xaxis=:flip , legend=:topright)
savefig(p , "images/relaxed-space-stability.svg")
#+end_src

#+RESULTS: fig:relaxed-stability-in-space
[[file:images/relaxed-space-stability.svg]]

* Comparison
In the previous chapter we have shown stability compared to the original solver. However we have not yet show a direct comparison between both methods. Since the relaxed solver is dependant on the relaxation variable \( \alpha \) We are interested in finding an optimal value for it.
Furthemore to see the effect \( \alpha \) has on our solver, we evaluate both solvers after one time-step , and then calculate the difference between \( \phi_{ij}^{n+1} \) and \( \phi_{ij}^{n+1,\alpha} \), for various values of \( \alpha \).
Should the relaxed solver approach the original, we would expect
\begin{equation}
||\phi_{ij}^{n+1} - \phi_{ij}^{n+1,\alpha}||_{Fr} \to 0
\end{equation}
In Fig.[[fig:alpha-error]] we observe the following behaviour where in all cases the difference to the original solver is apparent. Furthermore we observe a optimal value of \( \alpha \) at approximately \( 7.5 * 10^5 \) we explain this with our observations done for the Smoothing operator, where for small and large values of \( \alpha \) the relaxed approach ironically results in restricted behaviour. Empirical this is to be expected as. for large values of alpha the elliptical equation approaches \( \phi \)  and for small values the elliptical solver from chapter [[Elliptical PDE]] does not converge.
#+begin_src julia :noweb no-export :eval never :tangle experiments/src/alpha.jl :exports results
<<init>>
using JLD2
using Distributed
using ProgressBars
using DataFrames

original_grid = testgrid(multi_solver, M, 2)
alphas = 0:1e4:2e6

function alpha_error(alpha::Number , solution::Array )
    test_solver  = testgrid(relaxed_multi_solver, M, 2, alpha=alpha)
    set_xi_and_psi!(test_solver[1])
    for j in 1:64
        elyps_solver!(test_solver[1], 1000)
        v_cycle!(test_solver , 1)
    end
return [(;alpha=alpha , error=norm(test_solver[1].phase - solution))]
end
set_xi_and_psi!(original_grid[1])
for j in 1:64
    v_cycle!(original_grid, 1)
end
print("finished original v_cycle")
tasks = []
for alpha in alphas
    t = Threads.@spawn alpha_error(alpha , original_grid[1].phase)
    push!(tasks , (alpha=alpha , task = t))
end
result = DataFrame()
for task in ProgressBar(tasks)
    append!(result , fetch(task.task) )
    end
jldsave("experiments/alpha.jld2"; result)
#+end_src
#+name: fig:alpha-error
#+begin_src julia-vterm :results graphics file :file alpha-error.svg
using JLD2
using DataFrames
using Measures
<<init>>

pgfplotsx()
results = jldopen("experiments/alpha.jld2")["result"]
p=plot(results.alpha  , results.error ./64^2, label=false , xlabel=L"alpha $\alpha$" , ylabel="difference" )
savefig(p, "images/alpha-error.svg")
#+end_src

#+caption: Difference between the original solver \( \phi^1_{ij} \) and the relaxed solver \( \phi^{1,\alpha}_{ij} \)
#+RESULTS[cd5058dea24342ec78fa89393da40207fc1a5fab]: fig:alpha-error
[[file:images/alpha-error.svg]]
#+begin_src julia-vterm :results file graphics :file relaxed-comp.gif
<<init>>
using JLD2
using DataFrames
using Measures
using LaTeXStrings

gr()

results = jldopen("experiments/iteration.jld2")["result"]
results1 = jldopen("experiments/relaxed-iteration.jld2")["result"]
results2 = jldopen("experiments/relaxed-iteration-nophi.jld2")["result"]
results3 = jldopen("experiments/relaxed-iteration-nosubiter.jld2")["result"]
titles =  ["original" , "subiter elliptical" , L"without $2\phi$" , L"without $2\phi$ and subiter"]

anim = @animate for iter in zip(results.solver,results1.solver ,results2.solver , results3.solver)
    plots = []
    for (phase , title) in zip(iter ,titles)
        push!(plots , heatmap(phase.phase , title=title , legend=:none , aspectratio=:equal , grid=false , showaxis=false))
        plot(plots...)
        end
    end
gif(anim , "images/relaxed-comp.gif", fps=10)
#+end_src
although we can observe slight differences between the original solver and the relaxed approach they are barely noticeable by eye. Therefore we run our solver for a fixed value of \( \alpha=7700 \) , as this was one of the best values from Fig.[[fig:alpha-error]], We then  show the numerical difference between \( \phi_{ij}^n \) and \( \phi_{ij}^{n,\alpha} \) in Fig.[[fig:relaxed-original-comparison]]. We observe a a small difference between both methods, especially in areas with high curvature and inclusions of small segments of one phase in the other.
#+name: relaxed-comparison
#+begin_src julia-vterm :results file graphics :file relaxed-comparison.gif
<<init>>
using JLD2
using DataFrames
using Measures
using LaTeXStrings

i = 1*64 +1
gr()

original_results = jldopen("experiments/iteration.jld2")["result"]
relaxed_results = jldopen("experiments/relaxed-iteration.jld2")["result"]

difference = [norm(original.phase./2 .- relaxed.phase./2) /64^2 for (original, relaxed) in zip(original_results.solver[i:i+63],relaxed_results.solver[i:i+63])
]
anim = @animate for (original, relaxed) in zip(original_results.solver[i:i+63],relaxed_results.solver[i:i+63])
        p1 = plot(1:size(difference,1) , difference , xlabel= "time-steps" , ylabel = "error"  , title="diffrence" , label=false)
        p2 = heatmap(original.phase , title="original" , legend=:none , aspectratio=:equal , grid=false , showaxis=false)
        p3 = heatmap(relaxed.phase , title="relaxed" , aspectratio=:equal , grid=false , showaxis=false , legend=:none)
        plot(p1,p2,p3 , layout=(1,3) , size=(2000 ,700) , bottom_margin=20Plots.mm , left_margin=20Plots.mm)
        end
gif(anim , "images/relaxed-comparison.gif", fps=10)
#+end_src

#+RESULTS:
[[file:images/relaxed-comparison.gif]]
#+name: fig:relaxed-original-comparison
#+begin_src julia-vterm :results file graphics :file relaxed-comparison.svg
<<init>>
using JLD2
using DataFrames
using Measures
using LaTeXStrings

i = 0*64 +1
pgfplotsx()
original_results = jldopen("experiments/iteration.jld2")["result"]
relaxed_results = jldopen("experiments/relaxed-iteration.jld2")["result"]

difference = [norm(original.phase .- relaxed.phase) /64^2 for (original, relaxed) in zip(original_results.solver[i:i+63],relaxed_results.solver[i:i+63])
]
original, relaxed =   original_results.solver[i+63],relaxed_results.solver[i+63]

p1 = plot(1:size(difference,
                 1) ,
          difference ,
          xlabel= "time-steps" ,
          ylabel = "error"  ,
          title="diffrence" ,
          label=false)

p2 = heatmap(original.phase ,
             title=L"original at $n=64$" ,
             legend=:none ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false)
p3 = heatmap(relaxed.phase ,
             title=L"relaxed at $n=64$" ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false ,
             legend=:none)
p=plot(p1,
       p2,
       p3 ,
       layout=Layout3x1 ,
       size=size3x1 )
savefig(p , "images/relaxed-comparison.svg")
#+end_src

#+caption: comparison between the original and the relaxed CH solvers.

In addition to the experiments in Fig.[[fig:alpha-error]] we have experimented with a Monte Carlo Optimizer to opmimize \( \alpha \) in conjuvtion with \( \varepsilon \) to best approximate the baseline solver after one time-step. This resulted in a optimal \( \varepsilon \) found that was very close to the actual \( \varepsilon \) used. (9e-3 compared to 8e-3).

#+begin_src julia :tangle src/optim.jl :noweb yes
using Distributions
using DataFrames
using JLD2
<<init>>

function test_values(alpha_distribution::Distribution , epsilon_distribution::Distribution , M)
    alpha = rand(alpha_distribution)
    eps = max(rand(epsilon_distribution)  ,1e-10)
    relaxed_solver = testgrid(relaxed_multi_solver, M, 2; alpha=alpha, epsilon=eps)
    set_xi_and_psi!(relaxed_solver[1])
    #SMOOTH!(relaxed_solver[1], 100, false)
    for j=1:64
    elyps_solver!(relaxed_solver[1], 2000)
    v_cycle!(relaxed_solver , 1)
    end
    error = norm(relaxed_solver[1].phase .- original_solver[1].phase) / *(size(relaxed_solver[1].phase)...)
    return (;alpha=alpha , epsilon=eps , error=error)
end

original_solver = testgrid(multi_solver, M, 2)
set_xi_and_psi!(original_solver[1])
for j=1:64
v_cycle!(original_solver , 1)
end
#SMOOTH!(original_solver[1], 100, false);
eps = 3e-3
#M = testdata(64, div(64,3), 64/5 , 2)
alpha0 = 10000
epsilon0 = 1e-2
best_alpha = alpha0 / 10
best_epsilon = epsilon0 / 10
best_error  = Inf
results = DataFrame()
for n=1:1000
    searchradius = 1
    alpha_distribution = Normal(best_alpha , searchradius * alpha0)
    epsilon_distribution = Normal(best_epsilon , searchradius * epsilon0)
    result = test_values(alpha_distribution , epsilon_distribution , M)
    if result.error < best_error
        global best_error = result.error
        global best_alpha = result.alpha
        global best_epsilon = result.epsilon
        println(result)
    end
push!(results , result)
end
jldsave("experiments/alpha-epsilon.jld2"; result=results)
println("Best alpha: $best_alpha , Best epsilon: $best_epsilon")
#+end_src
* Apendix
** Operator implementation
#+begin_src julia :tangle src/utils.jl :eval never
function set_xi_and_psi!(solver::T) where T <: Union{multi_solver , relaxed_multi_solver}
    xi_init(x) = x / solver.dt
    psi_init(x) = solver.W_prime(x) - 2 * x
    solver.xi[2:end-1, 2:end-1] = xi_init.(solver.phase[2:end-1,2:end-1])
    solver.psi[2:end-1, 2:end-1] = psi_init.(solver.phase[2:end-1,2:end-1])
    return nothing
end
#+end_src
*** baseline
#+begin_src julia :tangle src/multisolver.jl :eval never
function L(solver::multi_solver,i,j , phi , mu)
    xi = solver.phase[i, j] / solver.dt -
         (discrete_G_weigted_neigbour_sum(i, j, solver.potential, G, solver.len, solver.width)
          -
          neighbours_in_domain(i, j, G, solver.len, solver.width) * mu )/solver.h^2
    psi = solver.epsilon^2/solver.h^2 *
          (discrete_G_weigted_neigbour_sum(i, j, solver.phase, G, solver.len, solver.width)
           -
           neighbours_in_domain(i, j, G, solver.len, solver.width) * phi) - 2 * phi + mu
    return [xi, psi]
end
#+end_src
#+begin_src julia :tangle src/multisolver.jl :eval never
function dL(solver::multi_solver , i , j)
    return [ (1/solver.dt) (1/solver.h^2*neighbours_in_domain(i,j,G,solver.len , solver.width));
             (-1*solver.epsilon^2/solver.h^2 * neighbours_in_domain(i,j,G,solver.len , solver.width) - 2) 1]
    end
#+end_src
*** relaxed
#+begin_src julia :tangle src/multi_relaxed.jl :eval never
function L(solver::relaxed_multi_solver,i,j , phi , mu)
    xi = solver.phase[i, j] / solver.dt -
         (discrete_G_weigted_neigbour_sum(i, j, solver.potential, G, solver.len, solver.width)
          -
          neighbours_in_domain(i, j, G, solver.len, solver.width) * mu )/solver.h^2
    psi = solver.epsilon^2 * solver.alpha*(solver.c[i,j] - phi) - solver.potential[i,j] - 2 * solver.phase[i,j]
    return [xi, psi]
end
#+end_src
#+begin_src julia :tangle src/multi_relaxed.jl :eval never
function dL(solver::relaxed_multi_solver , i , j)
    return [ (1/solver.dt) (1/solver.h^2*neighbours_in_domain(i,j,G,solver.len , solver.width));
             (-1*solver.epsilon^2 * solver.alpha  - 2) 1]
    end
#+end_src
** rng generation
for random point generation we use the folowing Function and seed.
#+begin_src julia-vterm :session jl :results table :exports both
using Random
rng = MersenneTwister(42)
gridsize = 64
radius = gridsize /5
blobs = gridsize ÷ 5
rngpoints = rand(rng,1:gridsize, 2, blobs)
#+end_src

#+RESULTS:
: 2×12 Matrix{Int64}:
:  48  40  20   1  63  49   8  60  26  58  26  11
:  17  13  56  52  15   9  30  14  40   9  40  25


the random testdata is then generated as follows
#+name: testdata
#+begin_src julia :eval never :tangle src/utils.jl :exports none
using Random
function testdata(gridsize , blobs , radius ,norm;rng=MersenneTwister(42))
rngpoints = rand(rng,1:gridsize, 2, blobs)
M = zeros(gridsize,gridsize) .- 1
for p in axes(rngpoints , 2)
    point = rngpoints[:, p]
    for I in CartesianIndices(M)
        if (LinearAlgebra.norm(point .- I.I  , norm) < radius)
            M[I] = 1
        end
    end
end
M
end
#+end_src
** Experiments :noexport:
*** iteration
#+begin_src julia :results output  :noweb yes :eval never :tangle experiments/src/iteration.jl
using JLD2
using DataFrames
using Random
<<init>>
<<setup-diverse-testgrids>>
function iter(g::Vector{T} , n) where T<: solver
    out = []
    for j in 1:64
    set_xi_and_psi!(g[1])
    for i = 1:64
        v_cycle!(g, 1)
    end
    push!(out, (solver=deepcopy(g[1]), iteration=j , experiment=n))
    end
    return out
end


tasks = []
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i], i)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/iteration.jld2"; result)
#+end_src

#+RESULTS:

#+name: fig:behaviour
#+begin_src julia-vterm :results graphics file :file behaviour.gif :chache :session jl :noweb no-export :output-dir images :exports none :noweb no-export
<<init>>
using JLD2
using DataFrames
results = jldopen("experiments/iteration.jld2")["result"]
n  = size(results.solver , 1)
pbar = ProgressBar(total = 10 * n)
energy = zeros(0)
massbalance = zeros(0)

anim = @animate for res in eachrow(results)
    push!(energy , bulk_energy(res.solver))
    push!(massbalance , massbal(res.solver.phase))

    p0 = heatmap(res.solver.phase , clim =(-1,1) , framestyle=:none , legend=true, lims=(1, size(res.solver.phase , 1)) , aspect_ratio=:equal, title  = "phasefield" )
   p1 = heatmap(res.solver.potential , framestyle=:none , legend=true, lims=(1,size(res.solver.phase , 1)), aspect_ratio=:equal, title  = "potential" )

    current_range = (res.experiment -1)*64 +1

    p3 = plot( 1:res.iteration, (massbalance .-massbalance[current_range])[current_range:current_range+res.iteration-1] , xlim=(1,64),  title = "Mass change")
    p2 = plot(1:res.iteration , energy[current_range:current_range+res.iteration-1], xlim=(1,64),  title = "Bulk energy")
    plot(p0,p1,p2,p3)
end
gif(anim , "images/behaviour.gif" , fps = 10)
#+end_src

#+caption: behaviour of bulk energy \( E_{bulk} \) and amount of fluid changing phase, for different initial conditions
#+RESULTS: fig:behaviour
[[file:images/behaviour.gif]]

*** subiteration
#+begin_src julia :results output :noweb yes :tangle experiments/src/subiteration.jl
using DataFrames
using JLD2
using ProgressMeter
<<init>>
<<setup-diverse-testgrids>>
n = 4
m = 64

function iter(g::Vector{T} , n , k , prg::Progress) where T<: solver
    out = []
    for j in 1:n
    set_xi_and_psi!(g[1])
    for i = 1:m
        v_cycle!(g, 1)
        push!(out, (cycle=deepcopy(g[1]), iteration=j , subiteration=i , experiment=k))
        next!(prg)
    end
    end
    return out
end


tasks = []
prg=Progress(size(tests ,1)*n*m , showspeed=true , )
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i] , n , i , prg)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/subiteration.jld2"; result)
#+end_src
*** time
#+begin_src julia :results output :noweb yes :exports none :tangle experiments/src/time.jl
using DataFrames
using JLD2
<<init>>
SIZE  =64
M = testdata(SIZE, SIZE ÷ 5, SIZE /5 , 2)
tests = [testgrid(multi_solver , M , 2 , dt = t ) for t in 1e-2./(1:64)]

function iter(g::Vector{T} , n) where T<: solver
    out = []
    for i = 1:n
    set_xi_and_psi!(g[1])
    for i = 1:64
        v_cycle!(g, 1)
    end
    push!(out, (phase=copy(g[1].phase), iteration=n))
    end
    return out
end


tasks = []
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i], i)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/time.jld2"; result)
#+end_src
*** space
#+begin_src julia :results output :noweb yes :exports none :tangle experiments/src/space.jl
using DataFrames
using JLD2
<<init>>

M = testdata(2^10 , 2^5 , 2^7 , 2 )
grids = testgrid(multi_solver  , M , 7)
# inits
for i=2:size(grids,1)
    restrict_solver!(grids[i-1] , grids[i])
end
tests = [[grids[i-1] , grids[i]] for i=2:size(grids,1)]


function iter(g::Vector{T} , n) where T<: solver
    out = []
    for j in 1:n
    set_xi_and_psi!(g[1])
    for i = 1:64
        v_cycle!(g, 1)
    end
    push!(out, (phase=copy(g[1].phase), iteration=j))
    end
    return out
end


tasks = []
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i], 16)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/space_refinement.jld2"; result)
#+end_src
** Relaxed experiments :noexport:
*** Iteration
#+begin_src julia    :noweb no-export :tangle experiments/src/relaxed-iteration.jl :async
using JLD2
using DataFrames
using ProgressMeter
using Random
<<init>>
<<setup-diverse-testgrids>>

#tests = [testgrid(relaxed_multi_solver, M , 2;alpha=82000 , epsilon=0.009) for M in initial_data]
tests = [testgrid(relaxed_multi_solver, M , 2) for M in initial_data]

n = 64
m = 64


function iter(g::Vector{relaxed_multi_solver} , n , prg::Progress)
    out = []
    for j in 1:n
    set_xi_and_psi!(g[1])
    for i = 1:m
        elyps_solver!(g[1] , 1000)
        v_cycle!(g, 1)
        next!(prg)
    end
    push!(out, (solver=deepcopy(g[1]), iteration=j , experiment=n))
    end
    return out
end

prg=Progress(size(tests ,1)*n*m , showspeed=true , )
tasks = []
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i], i , prg)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/relaxed-iteration.jld2"; result)
#+end_src

*** Subiteration
#+begin_src julia :tangle experiments/src/relaxed-subiteration.jl :noweb yes
using DataFrames
using JLD2
using ProgressMeter
<<init>>
<<setup-diverse-testgrids>>
#tests = [testgrid(relaxed_multi_solver, M , 2;alpha=32428.2 , epsilon=0.163398) for M in initial_data]
tests = [testgrid(relaxed_multi_solver, M , 2) for M in initial_data]
n = 4
m = 1024

function iter(g::Vector{T} , n ,k , prg::Progress) where T<: solver
    out = []
    for j in 1:n
    set_xi_and_psi!(g[1])
    for i = 1:m
        elyps_solver!(g[1] , 1000)
        v_cycle!(g, 1)
        push!(out, (cycle=deepcopy(g[1]), iteration=j , subiteration=i , experiment=k))
        next!(prg)
    end
    end
    return out
end


tasks = []
prg=Progress(size(tests ,1)*n*m , showspeed=true , )
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i] , n , i , prg)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/relaxed-subiteration.jld2"; result)
#+end_src

*** Time
#+begin_src julia :results output :noweb yes :exports none :tangle experiments/src/relaxed-tiem.jl
using DataFrames
using JLD2
<<init>>
tests = [testgrid(relaxed_multi_solver , M , 2 , dt = t ) for t in 1e-2./(1:64)]

function iter(g::Vector{T} , n) where T<: solver
    out = []
    for j in 1:n
    set_xi_and_psi!(g[1])
    for i = 1:64
        elyps_solver!(g[1] , 1000)
        v_cycle!(g, 1)
    end
    end
    push!(out, (phase=copy(g[1].phase), iteration=n))
    return out
end


tasks = []
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i], i)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/relaxed-time.jld2"; result)
#+end_src
*** Space
#+begin_src julia :results output :noweb yes :exports none :tangle experiments/src/space.jl
using DataFrames
using JLD2
<<init>>

M = testdata(2^10 , 2^5 , 2^7 , 2 )
grids = testgrid(relaxed_multi_solver  , M , 7)
# inits
for i=2:size(grids,1)
    restrict_solver!(grids[i-1] , grids[i])
end
tests = [[grids[i-1] , grids[i]] for i=2:size(grids,1)]


function iter(g::Vector{T} , n) where T<: solver
    out = []
    for j in 1:n
    set_xi_and_psi!(g[1])
    elyps_solver!(solver , 1000)
    for i = 1:64
        v_cycle!(g, 1)
    end
    push!(out, (phase=copy(g[1].phase), iteration=j))
    end
    return out
end


tasks = []
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i], 16)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/relaxed_space_refinement.jld2"; result)
#+end_src
* Utility functions :noexport:
#+name: imports
#+begin_src julia :session jl :results silent :exports none
using Plots
using LinearAlgebra
#+end_src


#+begin_src julia :tangle src/utils.jl :eval never
###############################################################################
#                  Common Utility Functions For Multi Solvers                 #
###############################################################################
"""
restricts an array on the small grid to an array in the large grid asserts size arr=2^n + 2 and returns ret=2^(n-1) + 2

Returns
---------------------------
large grid array + padding
"""
function restrict(arr, G)
    shape = (size(arr) .- 2) .÷ 2
    ret = zeros(shape .+ 2)
    for I in CartesianIndices(ret)[2:end-1, 2:end-1]
        i, j = I.I
        g = [
            G(2 * i - 1, 2 * j - 1, (size(arr) .- 2)...),
            G(2 * i - 1, 2 * j, (size(arr) .- 2)...),
            G(2 * i, 2 * j - 1, (size(arr) .- 2)...),
            G(2 * i, 2 * j, (size(arr) .- 2)...)
        ]
        if sum(g) == 0
            ret[I] = 0
        else
            ret[I] = (
                1 / sum(g)
                ,*
                dot(g,
                    [
                        arr[2*i-1, 2*j-1],
                        arr[2*i-1, 2*j],
                        arr[2*i, 2*j-1],
                        arr[2*i, 2*j]
                    ]
                )
            )
        end
    end
    return ret
end

"""
    prolong(arr , G)

interpolates int a smaller grid by a factor of 2

"""
function prolong(arr, G)
    inner_shape = (size(arr) .- 2) .* 2
    ret = zeros(inner_shape .+ 2)
    ONE = oneunit(CartesianIndices(arr)[1])
    for I in CartesianIndices(arr)[2:end-1, 2:end-1]
        Ind = 2 * (I - ONE) + ONE
        for J in (Ind-ONE):Ind
            ret[J] = G(J.I..., inner_shape...) * arr[I]
        end
    end
    return ret
end
"""
    restrict!(smallgrid_solver::multi_solver , largegrid_solver::multi_solver)::multi_solver

------------
Requires
----------
smallgrid solver and largegid solvers to be multiple of 2 from each other bar padding eg. (66x66)->(34x34)

------------
Returns
------------
    nothing. mutatest largegid in place to represent the smallgrid

"""
function restrict_solver!(smallgrid_solver::T, largegrid_solver::T) where {T<:solver}
    copy!(largegrid_solver.phase, restrict(smallgrid_solver.phase, G))
    copy!(largegrid_solver.potential, restrict(smallgrid_solver.potential, G))
    return nothing
end
#+end_src
#+begin_src julia :tangle src/solvers.jl :eval never
abstract type solver end
struct multi_solver <: solver
    phase::Matrix{Float64}
    potential::Matrix{Float64}
    xi::Matrix{Float64}
    psi::Matrix{Float64}
    epsilon::Float64
    h::Float64
    dt::Float64
    W_prime::Function
    len::Int
    width::Int

end
struct relaxed_multi_solver <: solver
    phase::Matrix{Float64}
    potential::Matrix{Float64}
    xi::Matrix{Float64}
    psi::Matrix{Float64}
    c::Matrix{Float64}
    epsilon::Float64
    h::Float64
    dt::Float64
    W_prime::Function
    len::Int
    width::Int
    alpha::Float64

end
#+end_src
#+begin_src julia :tangle src/testgrids.jl :eval never
function W_prime(x)
    return -x * (1 - x^2)
end
function testgrid(::Type{multi_solver},M, len; dt = 1e-3 ,  epsilon=8e-3 , h0=3e-3)
    grid = Array{multi_solver}(undef, len)
    phase = zeros(size(M) .+ 2)
    phase[2:end-1, 2:end-1] = M


    for i = 1:len
        dims = size(M) .÷ 2^(i-1) .+ 2
        grid[i] = multi_solver(zeros(dims),
            zeros(dims),
            zeros(dims),
            zeros(dims),
            epsilon, h0 * 2^i, dt,
            W_prime,
            (dims .- 2)...)

    end
    copyto!(grid[1].phase, phase)
    return grid

end

function testgrid(::Type{relaxed_multi_solver},M, len ; alpha=1e6 , dt=1e-3, epsilon=8e-3 , h0=3e-3)
    grid = Array{relaxed_multi_solver}(undef, len)
    phase = zeros(size(M) .+ 2)
    phase[2:end-1, 2:end-1] = M

    for i = 1:len
        dims = size(M) .÷ 2^(i-1) .+ 2
        grid[i] = relaxed_multi_solver(zeros(dims),
            zeros(dims),
            zeros(dims),
            zeros(dims),
            zeros(dims),
            epsilon, h0 * 2^i, dt,
            W_prime,
            (dims .- 2)... ,
            alpha)

    end
    copyto!(grid[1].phase, phase)
    return grid
end


#+end_src

#+name: init
#+begin_src julia :eval never
include(pwd() * "/src/solvers.jl")
include(pwd() * "/src/adapted_solvers.jl")
include(pwd() * "/src/utils.jl")
include(pwd() * "/src/multisolver.jl")
include(pwd() * "/src/multi_relaxed.jl")
include(pwd() * "/src/testgrids.jl")
include(pwd() * "/src/elypssolver.jl")
using Plots
using LaTeXStrings
using LinearAlgebra
using Printf
using ProgressBars
default(fontfamily="computer modern" , titlefontsize=32 , guidefontsize=32 , tickfontsize = 22 )
pgfplotsx()
layout2x2 = grid(2,2)
layout3x1 = @layout [ b  c ; a]
size3x1 = (1600,1600)
SIZE = 64
M = testdata(SIZE, SIZE ÷ 5, SIZE /5 , 2)

#+end_src
#+name: setup-grid
#+begin_src julia :eval never :noweb yes
<<init>>
testgrd = testgrid(multi_solver,M, 2)
test_solver = testgrd[1]
#+end_src


#+name: setup-relaxed-grid
#+begin_src julia :eval never :noweb yes
<<init>>
testgrd = testgrid(relaxed_multi_solver,M, 2)
println("Hi")
solver = testgrd[1]
#+end_src

#+name: setup-comparison
#+begin_src julia :noweb yes
<<init>>
using Plots
using LinearAlgebra
using ProgressBars
using JLD2
M = jldopen("data/test-phasefield.jld2")["M"]

relaxed_grid1 = testgrid(relaxed_multi_solver, M, 2 ,alpha=1e3)
relaxed_grid2 = testgrid(relaxed_multi_solver, M, 2 , alpha=1e4)
relaxed_grid3 = testgrid(relaxed_multi_solver, M, 2 , alpha=1e5)
original_grid = testgrid(multi_solver, M, 2)

#+end_src

#+name: setup-diverse-testgrids
#+begin_src julia :noweb yes
incirc(M) = filter(x -> norm(x.I .- (size(M, 1) / 2, size(M, 2) / 2)) < min(size(M)...) / 3, CartesianIndices(M))
insquare(M) = filter(x -> norm(x.I .- (size(M, 1) / 2, size(M, 2) / 2), Inf) < min(size(M)...) / 4, CartesianIndices(M))
side(M) = filter(x -> x.I[2] < size(M, 2) ÷ 2, CartesianIndices(M))
halfcirc(M) = filter(x -> norm(x.I .- (1, size(M, 2) / 2), 2) < min(size(M)...) / 3, CartesianIndices(M))

function get_special_input(fn, size)
    M = fill(-1, size , size )
    M[fn(M)] .= 1
    return M
end
SIZE  =64
t1= [testdata(SIZE, SIZE ÷ 5, SIZE /5 , j) for j in [1,2, Inf]]
t2 = [get_special_input(fn,SIZE) for  fn in [halfcirc , incirc, side , insquare]]
initial_data = [t1 ; t2]
tests = [testgrid(multi_solver, M , 2) for M in initial_data]

#+end_src











* Conclusion
In this thesis we have presented a simple introduction to the CH equation and have shown 2 numerical solvers for it. We have presented a baseline method implemented from the authors [cite:@SHIN20117441], and have Shown how to derive it from their initial approach. We have done the derivations in a way, that enables a simple adaptation to a modified version of the discrete CH equation Eq.[[eq:discrete-cahn-hilliard]], as introduced in [cite:@SHIN20117441]. We have introduced messures to evaluate both solvers in space , time and mass conservation as well as their sub-iteration behaviour. We have shown the baseline to be mass conservative, in a numerical sense, and we have shown it to be stable in all tested measures. We have shown our relaxed solver to approach the baseline, however we have also highlighted instability with subiterations, and massloss. We intentionally didn't evaluate runtime since numerical experiments have shown both solvers to be dependant on the amount of sub-iterations, hyperparameters such as \( \varepsilon \) as well as the number off smoothing iterations. It would therefore be unfair to evaluate one solver on a set of parameters tweaked for the other. As example for this dilemma we recall runs where the relaxed solver was around 10x faster than the baseline with the same parameters. The baseline solver was able to run with 10x less smoothing iterations than the relaxed one. A fair comparison would hence require to find the optimal number of smoothing for each solver.


For the sake of compleetness we include runtime benchmarks Of both methods. Those should be taken with a pinch of salt because of the reasons above. Both examples are run with the same parameters.
#+begin_src julia-vterm :results value :sync
using BenchmarkTools
<<init>>
<<setup-diverse-testgrids>>

relaxed_grid= testgrid(relaxed_multi_solver, M , 2)
baseline_grid = testgrid(multi_solver, M , 2)
function test(s::Array{multi_solver})
    set_xi_and_psi!(s[1])
    for i=1:1
        v_cycle!(s , 1)
    end
    end

function test(s::Array{relaxed_multi_solver})
    set_xi_and_psi!(s[1])
    for i=1:1
        elyps_solver!(s[1] , 1000)
        v_cycle!(s , 1)
    end
    end
# b1 = @benchmark test(baseline_grid)
#b2 = @benchmark test(relaxed_grid)
#b2
#+end_src

#+RESULTS[8eeb500671b68950e0d0d2ce8c4d70a92b0b2b9b]:
: Executing... 1a392143


#+begin_example
BenchmarkTools.Trial: 1 sample with 1 evaluation.
 Single result which took 8.938 s (3.95% GC) to evaluate,
 with a memory estimate of 3.36 GiB, over 63995963 allocations.
#+end_example

#+begin_example
BenchmarkTools.Trial: 5 samples with 1 evaluation.
 Range (min … max):  1.030 s …    1.304 s  ┊ GC (min … max): 3.26% … 2.74%
 Time  (median):     1.068 s               ┊ GC (median):    3.14%
 Time  (mean ± σ):   1.128 s ± 111.612 ms  ┊ GC (mean ± σ):  2.87% ± 0.34%

  █      ██                    █                           █
  █▁▁▁▁▁▁██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█ ▁
  1.03 s         Histogram: frequency by time          1.3 s <

 Memory estimate: 293.88 MiB, allocs estimate: 5013565.
#+end_example
* References :ignore:
#+PRINT_BIBLIOGRAPHY:
#  LocalWords:  Discretization
# Local Variables:
# mode: org
# org-export-allow-bind-keywords: t
# End:
