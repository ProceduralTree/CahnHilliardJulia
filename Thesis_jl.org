#+title: Numerical methods
#+subtitle: on the Cahn-Hilliard Equation
#+BIBLIOGRAPHY: ~/org/resources/bibliography/refs.bib
#+options: toc:nil
#+BIND: org-latex-title-command ""
#+latex_class: mimosis
 #+latex_header: \include{~/.doom.d/OrgConfig/noteHeader.tex}
 #+HTML_HEAD: <link rel="stylesheet" type="text/css" href="https://gongzhitaao.org/orgcss/org.css"/>
#+PROPERTY: header-args:julia :output-dir images :eval never :noweb no-export
#+PROPERTY: header-args:julia-vterm :output-dir images :exports results  :noweb no-export :session jl :eval yes :cache yes
#+latex_header: \renewcommand{\floatpagefraction}{.7}%
#+latex_header: \usepackage[level]{datetime}

* Titlepage :ignore:
#+begin_export latex
\makeatletter
\begin{titlepage}
    \centering
\includegraphics[width=1\textwidth]{logo/logo.png}
\par
	\vspace{1.5cm}
	{\scshape\huge Bachelor's Thesis \par}
	\vspace{1.5cm}
	{\Huge\bfseries  \@title \par}
	\vspace{2cm}
	{\LARGE \@author \par}
	{\Large Matriculation Number: 3545737 \par}
	\vspace{1.5cm}
	{\large Examiner: Prof Rohde i believe \par}
	{\large Advisor: Hasel \par}
	\vspace{1.5cm}
	{\large Institute of Applied Analysis and Numerical Simulation\par}



	\vfill

% Bottom of the page
	{\large Completed 01.01.2022 \par}
\end{titlepage}
\makeatother

#+end_export



#+begin_abstract
This Thesis gives a short overview and derivation for the Cahn-Hilliard Equation. It uses a discretization by the authors [cite:@SHIN20117441] as baseline, and expands upon this dicretisation with an elliptical relaxation approach. It introduces evaluation metrics in terms of time , space and subiteration stability and compares the elliptical approach against the baseline. It shows a qualitative succes of the elliptical solver, however it also highlights challanges in numerical stability.
#+end_abstract

#+TOC: headlines 3

* Introduction
 This thesis follows reproducible research philosophy, in that we provide all relevant code in the same file as the writing itself. We then use this file to generate exports to html and PDF, as well as extract the code to be used independently. Further details on execution and reading of the original source provided in org-mode format,
* The Cahn-Hilliard equation
The Cahn-Hilliard(CH) equation is a partial differential equation (PDE) that governs the dynamics of a two-phase fluid[cite:@Wu_2022]. The form of the CH equation used in this thesis is
#+name: eq:CH
\begin{equation}
\begin{aligned}
\partial_{t}\phi(x,t) &=  \nabla \cdot(M(\phi)\nabla\mu) \\
\mu &= - \varepsilon^2 \Delta\phi  + W'(\phi)
\end{aligned}
\end{equation}
where, \( \phi\) is a phase-field variable representing the different states of the fluids through an interval \(I=[-1,1] \)
\begin{align*}
\phi &=
\begin{cases}
1 &\,, \phi = \text{phase 1} \\
-1 &\,, \phi =\text{ phase 2}
\end{cases}
\end{align*}

 \(\varepsilon\) is a positive constant correlated with boundary thickness and \(\mu\) is the chemical potential[cite:@Wu_2022].

 In this thesis we assume \(M(\phi) \equiv 1 \), simplifying the CH equation used in [cite:@Wu_2022] [cite:@SHIN20117441].

The advantages of the CH approach, as compared to traditional boundary coupling, are for example: "explicit tracking of the interface" [cite:@Wu_2022], as well as "evolution of complex geometries and topological changes [...] in a natural way" [cite:@Wu_2022].
In practice it enables linear interpolation between different formulas on different phases.
** Derivation from paper
*** The free energy
The authors in [cite:@Wu_2022] define the CH equation using the *Ginzburg-Landau* free energy equation:
#+name: eq:energy
\begin{align}
E^{\text{bulk}}(\phi) &= \int_{\Omega} \frac{\varepsilon^2}{2} |\nabla \phi |^2 + W(\phi) \, dx
\end{align}
where \(W(\phi) \) denotes the Helmholtz free energy density of mixing [cite:@Wu_2022] that we approximate it in further calculations with \(W(\phi) = \frac{(1-\phi ^2)^2}{4}\) as in [cite:@SHIN20117441]. \( W(\phi) \) is a double well potential with minima at \( \phi \in {-1,1} \).
#+name: double-well
#+begin_src julia-vterm :results file graphics :file double-well.svg
using Plots
using LaTeXStrings
W(x) = 1/4 * (1- x^ 2)^2

p = plot(W , xlims=(-2,2) , label=:none)
savefig(p, "images/double-well.svg")
#+end_src

#+caption: Double well potential \( W(\phi) \)
#+RESULTS[978b0588e2d59be5e973459583ee383508f68433]: double-well
[[file:images/double-well.svg]]



The chemical potential, \( \mu \), then follows as the variational derivation of the free energy [[eq:energy]].
\begin{align*}
 \mu &= \frac{\delta E_{bulk}(\phi)}{\delta \phi} = -\varepsilon^2 \Delta \phi + W'(\phi)
\end{align*}

*** Derivation of the CH equation from mass balance
The paper [cite:@Wu_2022]  motivates us to derive the CH equation as follows:
#+name: eq:massbal
\begin{equation}
    \partial_t \phi + \nabla \cdot J = 0
\end{equation}
where \( J \) is mass flux. The equation [[eq:massbal]] then ensures continuity of mass
Using the no-flux boundary conditions:
#+name: eq:boundary-conditions
\begin{equation}
\begin{aligned}
J \cdot n &= 0 & \partial\Omega &\times (0,T)\\
\partial_n\phi &= 0 & \partial\Omega &\times (0,T)
\end{aligned}
\end{equation}
where \( n \) is the outward normal on \( \partial \Omega \).
conservation of mass follows see[cite:@Wu_2022].
#+name: eq:mass-conservation
\begin{equation}
\begin{aligned}
\frac{d}{dt}\int_{\Omega}\phi&=\int_{\Omega}\frac{\partial \phi}{\partial t} dV \\
&= - \int_{\Omega} \nabla \cdot J \ dV\\
&=  \int_{\partial\Omega}  J \cdot n  \ dA \\
&= 0
\end{aligned}
\end{equation}
Therefore mass is conserved over time, as shown in [[eq:mass-conservation]].
We define the mass flux, \( J \), as the gradient in chemical potential as follows
\begin{align}
J &= - \nabla \mu
\end{align}
This results in the CH equation as stated in [[eq:CH]].
#+name: eq:boundary-conditions
\begin{equation}
\begin{aligned}
 - \nabla \mu &= 0 \\
\partial_n \phi &= 0
\end{aligned}
\end{equation}
i.e. no flow leaves and potential on the border doesn't change.
In order to show the CH equation's consistency with thermodynamics we take the time derivation of the free energy [[eq:energy]] and we show that it decreases in time.
\begin{align*}
\frac{d}{dt}E^{bulk}(\phi(t)) &= \int_{\Omega} ( \varepsilon^2 \nabla \phi \cdot \nabla \partial_t \phi + W'(\phi) \partial_t \phi) \ d x \\
&=\int_{\Omega} (\varepsilon^2\nabla\phi + W'(\phi))\partial_t\phi \ dx\\
&=\int_{\Omega} \mu \partial_t \phi \ dx\\
&= \int_{\Omega} \mu \cdot \Delta\mu \ dx \\
&= -\int_{\Omega} \nabla\mu \cdot \nabla\mu \ dx + \int_{\partial\Omega} \mu \nabla\phi_t \cdot n \ dS \\
&\stackrel{\partial_n\phi = 0}{=} - \int_{ \Omega } |\nabla \mu|^2 \ d x, & \forall t \in [0,T)
\end{align*}
* Baseline multi-grid solver
** The discretization of the CH equation:
As baseline for numerical experiments we use a two-grid method based on the finite difference method defined in [cite:@SHIN20117441].
Our discretization follows the one taken by the authors in [cite:@SHIN20117441].
We discretize our domain \( \Omega \) to be a Cartesian-grid \( \Omega_d \) on a square with side-length \( N\cdot h \), where N is the number of grid-points in one direction, and \( h \) is the distance between grid-points. In all our initial data \( h \) is \( 3\cdot10^{-3}\) and \( N=64 \) . However for stability tests we change \( h \) and \( N \).
\begin{equation}
\Omega_d = \left\{ i,j \mid i,j \in \mathbb{N} \,, i,j \in [2,N+1] \right\}
\end{equation}
where \( \Omega_{d} \) is the discrete version or our domain as shown in [[fig:discrete-domain]].
#+name: fig:discrete-domain
#+begin_src julia-vterm :results file graphics :file domain.svg
using Plots
using LaTeXStrings
pgfplotsx()
Idx = CartesianIndex(1,1)
M = zeros(66,66)
M[2:end-1 , 2:end-1] = ones(64,64)
p= heatmap(M, title=L"\Omega_d" , clim=(-1,1),
            gridlinewidth=2 , axis_equal_image=true , extra_kwargs=:subplot , xlims=(1 ,66) , ylims=(1,66))

savefig(p,"images/domain.svg")
#+end_src

#+caption: Discrete Domain used for most of the experiments in this Thesis
#+RESULTS[46038739234db0a64b145e68000e9b1ea9d30425]: fig:discrete-domain
[[file:images/domain.svg]]


We discretize the phase-field ,\( \phi \), and chemical potential ,\( \mu \), into grid-wise functions \(\phi_{ij}, \mu_{ij} \)
\begin{equation}
\begin{aligned}
\phi_{ij}^n: \Omega_d \times \left\{ 0, \dots  \right\} &\to \mathbb{R}\\
\mu_{ij}^n: \Omega_d \times \left\{ 0, \dots \right\} &\to \mathbb{R}
\end{aligned}
\end{equation}
Here \( n \) denotes the nth time-step , and \( (i,j) \) are cartesian indicies on the discrete domain \( \Omega_d \).
The authors in [cite:@SHIN20117441] then use the characteristic function \( G \) of the  domain \( \Omega \) to enforce no-flux boundary conditions [[eq:boundary-conditions]].

\begin{align*}
G(x,y) &=
\begin{cases}
1, & (x,y) \in  \Omega \\
0, & (x,y) \not\in  \Omega
\end{cases}
\end{align*}
We implement the discrete version of \( G \) on \( \Omega_d \) as follows:
\begin{align*}
G_{ij} &=
\begin{cases}
1, & (i,j) \in  \Omega_{d} \\
0, & \text{else}
\end{cases}
\end{align*}

#+begin_src julia :tangle src/utils.jl :eval never :exports none
"""
Boundry indicator function

Returns
---------------
1 if index i,j is in bounds(without padding) and 0 else
"""
#+end_src
#+begin_src julia :tangle src/utils.jl :eval never
function G(i, j, len, width)
    if 2 <= i <= len + 1 && 2 <= j <= width + 1
        return 1.0
    else
        return 0.0
    end
end
#+end_src

We then define the discrete derivatives \( D_x\phi_{ij}, \ D_y\phi_{ij} \) using centred differences:
\begin{align}
D_x\phi_{i+\frac{1}{2} j} &= \frac{\phi_{i+1j} - \phi_{ij}}{h} & D_y\phi_{ij+\frac{1}{2}} &= \frac{\phi_{ij+1} - \phi_{ij}}{h}
\end{align}
We then define the discrete gradient \( \nabla_d \phi_{ij}\)  as well as a modified laplacian \( \nabla_d \cdot (G_{ij} \nabla_d \phi_{ij} )\):
#+name: eq:discretization
\begin{align}
\nabla_d \phi_{ij} &= (D_x \phi_{i+1j} , \ D_y \phi_{ij+1}) \\
 \nabla_d \cdot (G_{ij} \nabla_d \phi_{ij}) &= \frac{G_{i+\frac{1}{2}j}D_x \phi_{i+\frac{1}{2}j} -  G_{i-172}D_x \phi_{i-\frac{1}{2}j} + D_y \phi_{ij+\frac{1}{2}} - D_y \phi_{ij-\frac{1}{2}}}{h},
\end{align}
 We define \(   \nabla_d \cdot (G_{ij} \nabla_d \phi_{ij} )\) instead of a discrete laplacian \( \Delta_d \) to ensure a discrete version of boundary conditions [[eq:boundary-conditions]]. The authors in [cite:@SHIN20117441] show this to be the case by expanding \( \nabla_d \cdot (G_{ij} \nabla_d\phi_{ij}) \).

notably, when one point lies outside the domain, then \( G_{i \pm \frac{1}{2}} = 0 \)  and therefore the corresponding discrete gradient \( \frac{\phi_{i\pm1} - \phi_i}{h}  \) is weighted by 0. This corresponds the discrete version of \( \partial_n\phi = 0 \).
The authors in [cite:@SHIN20117441]

To simplify the notation for discretized derivatives we use the following abbreviations:
Math:
- \(  \Sigma_G \phi_{ij} = G_{i+\frac{1}{2}j} \phi^{n + \frac{1}{2},m}_{i+1j} +  G_{i-\frac{1}{2}j} \phi^{n + \frac{1}{2},m}_{i-1j} + G_{ij+\frac{1}{2}}  \phi^{n + \frac{1}{2},m}_{ij+1} + G_{ij-\frac{1}{2}} \phi^{n + \frac{1}{2},m}_{ij-1}  \)
- \(  \Sigma_{Gij} = G_{i+\frac{1}{2}j} + G_{i-\frac{1}{2}j} + G_{ij+\frac{1}{2}} + G_{ij-\frac{1}{2}}  \)
Code:
#+begin_src julia :tangle src/utils.jl :eval never
function neighbours_in_domain(i, j, G, len, width)
    (
        G(i + 0.5, j, len, width)
        + G(i - 0.5, j, len, width)
        + G(i, j + 0.5, len, width)
        + G(i, j - 0.5, len, width)
    )

end
function discrete_G_weigted_neigbour_sum(i, j, arr, G, len, width)
    (
        G(i + 0.5, j, len, width) * arr[i+1, j]
        + G(i - 0.5, j, len, width) * arr[i-1, j]
        + G(i, j + 0.5, len, width) * arr[i, j+1]
        + G(i, j - 0.5, len, width) * arr[i, j-1]
    )
end
#+end_src

We can then write the modified Laplacian \( \nabla_d (G \nabla_df_{ij}) \) as:
\begin{align*}
\nabla_{d} \cdot(G \nabla_df_{ij}) &= \frac{\Sigma_Gf_{ij} - \Sigma_G\cdot f_{ij}}{h^2}
\end{align*}
We use this modified Laplacian to deal with boundary conditions. Our abbreviations simplify separating implicit and explicit terms in the discretization.
** Initial data
For testing we use initial phase-fields defined by the following equations:

\begin{equation}
\begin{aligned}
\phi_{ij} &=
\begin{cases}
1 &\,, \|(i,j) - (\frac{N}{2} , \frac{N}{2})\|_p < \frac{N}{3}\\
-1 &\,,else
\end{cases}
&
\text{where    }  p \in \{2,\infty\}
\\
\phi_{ij} &=
\begin{cases}
1 &\,,  i < \frac{N}{2} \\
-1 &\,,else
\end{cases}
\\
\phi_{ij} &=
\begin{cases}
1 &\,, \|(i,j) - (\frac{N}{2} , 2)\|_2 < \frac{N}{3} \\
-1 &\,,else
\end{cases}
\\
\phi_{ij} &=
\begin{cases}
1 &\,, \| (i,j) - q_k \|_p < \frac{N}{5}  \\
-1 &\,,else
\end{cases}
& p \in \{1,2, \infty\} , q_k \in Q
\end{aligned}
\end{equation}
where \( q_k \) are random points inside my domain. Those we generate those using the following rng setup in julia


#+name: fig:testinput
#+begin_src julia-vterm :results file graphics  :file testdata.svg
<<init>>
<<setup-diverse-testgrids>>
plots =[  heatmap(t[1].phase ,  legend=:none , aspectratio=:equal , grid=false , showaxis=false , size=(600,600))
for t in tests[1:2:end]]
#plots = [heatmap(t[1].phase , size=(600,600), axis=:none , aspect_ratio=:equal) for t in tests]
p = plot(plots... , layout=(1,4) , size=(2400,600))
savefig(p,"images/testdata.svg")
#+end_src

#+caption: Examples of different phase-fields used as the initial condition in this work.
#+RESULTS[022c521f7b12b7f61d32b1d70b05629b2f49e747]: fig:testinput
[[file:images/testdata.svg]]

** Numerical ansatz
The authors in [cite:@SHIN20117441] then define the discrete CH equation adapted for the domain as:
#+name: eq:discrete-cahn-hilliard
\begin{equation}
\begin{aligned}
\frac{\phi_{ij}^{n+1} - \phi_{ij}^n}{\Delta t}  &=  \nabla _d \cdot (G_{ij} \nabla_d \mu_{ij}^{n+\frac{1}{2}} )  \\
 \mu_{ij}^{n+\frac{1}{2}} &= 2\phi_{ij}^{n+1} - \varepsilon^2  \nabla_d \cdot  (G_{ij} \nabla _d \phi_{ij}^{n+1} ) + W'(\phi_{ij}^n) - 2\phi _{ij}^n
\end{aligned}
\end{equation}
and derive a numerical scheme from this implicit equation.
** The discrete scheme
The authors in [cite:@SHIN20117441] derive their method by separating [[eq:discrete-cahn-hilliard]] into implicit and linear terms, and explicit non-linear terms. We write the implicit terms in form of a function \( L: \RR^2 \to \RR^2  \) and the explicit terms in \( (\zeta^n_{ij} , \psi^n_{ij})^T \).
\begin{align*}
L
\begin{pmatrix}
\phi^{n+1}_{ij} \\
\mu^{n+\frac{1}{2}}_{ij}
\end{pmatrix}
&=
\begin{pmatrix}
\frac{\phi^{n+1}_{ij}}{\Delta t} - \nabla _d \cdot  ( G_{ij} \nabla _d \mu^{n+\frac{1}{2}}_{ij} ) \\
\varepsilon^2 \nabla _d \cdot  (G \nabla_d \phi_{ij}^{n+1}) - 2\phi_{ij}^{n+1} + \mu_{ij}^{n+\frac{1}{2}}
\end{pmatrix}
\end{align*}
This operator follows from [[eq:discrete-cahn-hilliard]] by separating implicit and explicit terms \( L \) and   \( (\zeta^n_{ij} , \psi^n_{ij})^T \), respectively.
\begin{align*}
\begin{pmatrix}
\zeta^n_{ij}
 \\
\psi^n_{ij}
\end{pmatrix}
&=
\begin{pmatrix}
\frac{\phi_{ij}^{n}}{\Delta t}\\
W'(\phi_{ij}^n) - 2\phi_{ij}^n
\end{pmatrix}
\end{align*}
Due to being explicit, we know everything needed to calculate \( (\zeta^n_{ij} , \psi^n_{ij})^T \) at the beginning of each time step. We compute those values  once and store them in the solver.

Furthermore, as it is needed later on, we derive its Jacobian with respect to the current grid point \( (\phi^{n+1}_{ij} , \mu^{n+\frac{1}{2}}_{ij})^{T} \):

\begin{align*}
DL\begin{pmatrix}
\phi_{ij} \\
\mu_{ij}
\end{pmatrix} &= \begin{pmatrix}
\frac{1}{\Delta t} & \frac{1}{h^2}\Sigma_{Gij}  \\
-\frac{\varepsilon^2}{h^2}\Sigma_{Gij} - 2 & 1
\end{pmatrix}
\end{align*}
Implementation details can be found in the Apendix under  [[*baseline][baseline]].
** SMOOTH operator
The authors [cite:@SHIN20117441]derived Gauss-Seidel Smoothing from:
#+name: eq:smooth
\begin{align}
L
\begin{pmatrix}
\phi^{n+1}_{ij} \\
\mu^{n+\frac{1}{2}}_{ij}
\end{pmatrix}
&=
\begin{pmatrix}
\zeta^n_{ij} \\
\psi^n_{ij}
\end{pmatrix}
\end{align}
 SMOOTH consists of point-wise Gauss-Seidel relaxation, by solving [[eq:smooth]] for all \( i,j \) with the initial guess for \( \zeta^n_{ij} , \psi^n_{ij} \). Since \( L \) is linear we can write [[eq:smooth]] as
 #+name: eq:explicit-smooth
 \begin{equation}
\begin{aligned}
\begin{pmatrix}
  \zeta_{ij}^n\\
\psi_{ij}^n
\end{pmatrix}
&=
DL\begin{pmatrix}
\phi_{ij}^{n+1} \\
\mu_{ij}^{n+\frac{1}{2}}
\end{pmatrix}
\cdot
\begin{pmatrix}
\phi^{n+1}_{ij} \\
\mu^{n+\frac{1}{2}}_{ij}
\end{pmatrix}
+
\begin{pmatrix}
 - \frac{1}{h^2} \Sigma_{Gij}\mu_{ij}^{n+\frac{1}{2}} \\
+ \frac{\varepsilon^2}{h^2} \Sigma_{Gij}\phi_{ij}^{n+1} \\
\end{pmatrix}
\\
\begin{pmatrix}
  \zeta_{ij}^n\\
\psi_{ij}^n
\end{pmatrix}
-
\begin{pmatrix}
 - \frac{1}{h^2} \Sigma_{Gij}\mu_{ij}^{n+\frac{1}{2}} \\
+ \frac{\varepsilon^2}{h^2} \Sigma_{Gij}\phi_{ij}^{n+1} \\
\end{pmatrix}
&=
DL\begin{pmatrix}
\phi_{ij}^{n+1} \\
\mu_{ij}^{n+\frac{1}{2}}
\end{pmatrix}
\cdot
\begin{pmatrix}
\phi^{n+1}_{ij} \\
\mu^{n+\frac{1}{2}}_{ij}
\end{pmatrix}
\end{aligned}
\end{equation}
where
- \(  \Sigma_G \phi_{ij}^{n+1} = G_{i+\frac{1}{2}j} \phi^{n + 1,m}_{i+1j} +  G_{i-\frac{1}{2}j} \phi^{n + 1,m}_{i-1j} + G_{ij+\frac{1}{2}}  \phi^{n + 1,m}_{ij+1} + G_{ij-\frac{1}{2}} \phi^{n + 1,m}_{ij-1}  \),
- \(  \Sigma_G \mu_{ij} = G_{i+\frac{1}{2}j} \mu^{n + \frac{1}{2},m}_{i+1j} +  G_{i-\frac{1}{2}j} \mu^{n + \frac{1}{2},m}_{i-1j} + G_{ij+\frac{1}{2}}  \mu^{n + \frac{1}{2},m}_{ij+1} + G_{ij-\frac{1}{2}} \mu^{n + \frac{1}{2},m}_{ij-1}  \),
In order to compute \( \left(   \phi_{ij}^{n+1} , \mu^{n+\frac{1}{2}}_{ij}  \right) \) we have to evaluate those grid-wise functions on at neighbouring indicies \( k,l \) eg. \( k=i+1 , l=j-1 \).
since values for \( \phi_{kl}^{n+1,m} , \mu_{kl}^{n+\frac{1}{2},m} \) are unknown,if \( k > i , l > j \), the authors in [cite:@SHIN20117441] and we use initial approximations,   and the values of the current smooth iteration else. As initial approximation we use the values of \(  \phi_{kl}^{n+1,m} , \mu_{kl}^{n+\frac{1}{2},m}  \) from the last smoothing iteration.
The equation [[eq:explicit-smooth]] is of form \(b = Ax\)
We then and solve [[eq:explicit-smooth]] for \( \left( \phi_{ij}^{n+1} , \mu^{n+\frac{1}{2}}_{ij}  \right)  \).
#+name: calculate-left-hand-side-b
#+begin_src julia :eval never :exports none
bordernumber = neighbours_in_domain(i, j, G, solver.len, solver.width)

b = [(
            solver.xi[i, j]
            +
            discrete_G_weigted_neigbour_sum(
                i, j, solver.potential, G, solver.len, solver.width
            ) / solver.h^2
        ), (
            solver.psi[i, j]
            -
            (solver.epsilon^2 / solver.h^2) * discrete_G_weigted_neigbour_sum(
                i, j, solver.phase, G, solver.len, solver.width
            ))]


#+end_src
#+name:SMOOTH
#+begin_src julia :tangle src/multisolver.jl :eval never :noweb no-export
function SMOOTH!(
    solver::T,
    iterations,
    adaptive
) where T <: Union{multi_solver, adapted_multi_solver , gradient_boundary_solver}
    for k = 1:iterations
        old_phase = copy(solver.phase)
        for I in CartesianIndices(solver.phase)[2:end-1, 2:end-1]
            i, j = I.I

            <<calculate-left-hand-side-b>>

            res = dL(solver, i,j ) \ b
            solver.phase[i, j] = res[1]
            solver.potential[i, j] = res[2]
        end
    end
end
#+end_src

#+name: fig:smoothing-examples
#+begin_src julia-vterm :results file graphics  :file smooth.svg
<<input>>
<<setup-diverse-testgrids>>
plots= []
for t in tests
set_xi_and_psi!(t[1])
SMOOTH!(t[1], 2, true);
end
plots =[  heatmap(t[1].phase ,  legend=:none , aspectratio=:equal , grid=false , showaxis=false , size=(600,600))
          for t in tests[1:2:end]]
p = plot(plots... , layout=(1,4) , size=(2400,600))
savefig(p,"images/smooth.svg")

#+end_src

#+caption: inputs from [[Initial data]] after SMOOTH.
#+RESULTS: fig:smoothing-examples
[[file:images/smooth.svg]]

** Multigrid method
Notably the sharp interphase of the  initial phase-fields has been smoothed, and the values are between \( -1,1 \).
The numerical method proposed in [cite:@SHIN20117441] consists of a V-cycle multi-grid method derived from previously stated operators. Specificly we use a two-grid implementation consisting of.
1. a Gauss-Seidel relaxation for smoothing Chapter [[SMOOTH operator]].
2. restriction and prolongation methods between grids \(  h \leftrightarrow H  \).
3. a Newton iteration to solve \( L(\phi_{ij,H}^{n+1,m}, \mu_{ij,H}^{n+\frac{1}{2},m})_H = L(\bar{\phi}_{ij,H}^{n+1,m} , \bar{\mu}_{ij,H}^{n+\frac{1}{2},m}) + (d_{ij,H}^{n+1,m} , r_{ij,H}^{n+1,m}) \).
   we solve using the same iteration as in Chapter [[SMOOTH operator]] however we replace \( (\zeta_{ij}^{n} , \psi_{ij}^n) \) with  \(  L(\bar{\phi}_{ij,H}^{n+1,m} , \bar{\mu}_{ij,H}^{n+\frac{1}{2},m}) + (d_{ij,H}^{n+1,m} , r_{ij,H}^{n+1,m}) \).  in the iteration, where \( \bar{\phi}_{ij,H}^{n+1,m} , \bar{\mu}_{ij,H}^{n+\frac{1}{2},m} \) are the values after the smooth restricted to the coarser grid and \( d_{ij,H}^{n+1,m} , r_{ij,H}^{n+1,m} \) is the residual from the smooth  iteration on the fine grid restricted onto the coarse grid.

#+name: restrict-to-coarse-grid
#+begin_src julia :eval never :exports none
restrict_solver!(grid[level], grid[level+1])
solver = grid[level+1]
solution = deepcopy(solver)

d_large = restrict(d, G)
r_large = restrict(r, G)


u_large = zeros(size(d_large))
v_large = zeros(size(d_large))

#+end_src

#+name: prolong-to-fine-grid
#+begin_src julia :eval never :exports none
u_large = solver.phase .- solution.phase
v_large = solver.potential .- solution.potential

solver = grid[level]

solver.phase .+= prolong(u_large , G)
solver.potential .+= prolong(v_large, G)

#+end_src

The V-cycle of a two-grid method using pre and post smoothing is then stated by:
#+begin_src julia :tangle src/multisolver.jl :eval never :noweb no-export
function v_cycle!(grid::Array{T}, level) where T <: solver
    solver = grid[level]
    #pre SMOOTHing:
    SMOOTH!(solver, 400, false)

    d = zeros(size(solver.phase))
    r = zeros(size(solver.phase))

    # calculate error between L and expected values
    for I in CartesianIndices(solver.phase)[2:end-1, 2:end-1]
        d[I], r[I] = [solver.xi[I], solver.psi[I]] .- L(solver, I.I..., solver.phase[I], solver.potential[I])
    end

    <<restrict-to-coarse-grid>>

    #Newton Iteration for solving smallgrid
    for i = 1:300
        for I in CartesianIndices(solver.phase)[2:end-1, 2:end-1]

            diffrence = L(solution, I.I..., solution.phase[I], solution.potential[I])
                        .- [d_large[I], r_large[I]]
                        .- L(solver, I.I..., solver.phase[I], solver.potential[I])

            local ret = dL(solution, I.I...) \ diffrence

            u_large[I] = ret[1]
            v_large[I] = ret[2]
        end
        solution.phase .-= u_large
        solution.potential .-= v_large
    end

    <<prolong-to-fine-grid>>

    SMOOTH!(solver, 800, false)
end
#+end_src


The iteration of the solver is then done as follows
#+begin_src julia :eval never :exports code
for j in 1:timesteps

    set_xi_and_psi!(solvers[1])

    for i = 1:subiterations

        v_cycle!(solvers, 1)
    end
end
#+end_src
After a few iterations, V-cycle exhibits the following behavior:

#+name: fig:solver-iteration
#+begin_src julia-vterm :results file graphics  :file iteration.gif :noweb no-export :async t :exports results :output-dir images  :tangle src/plot.jl :session jl :eval never-export
<<init>>
using JLD2
using DataFrames
results = jldopen("experiments/iteration.jld2")["result"]
anim = @animate for res in eachrow(results)
    heatmap(res.solver.phase , title="phase field" , legend=:none , aspectratio=:equal , showaxis=false , grid=false , size=(400 ,400))
end
gif(anim , "images/iteration.gif" , fps = 10)
#+end_src

#+caption: a fex timesteps of the solver for different initial contitions as shown in [[Initial data]]
#+RESULTS: fig:solver-iteration
[[file:images/iteration.gif]]

* Numerical evaluation
The analytical CH equation conserves mass [[eq:massbal]] and the free energy ,\( E_{bulk} \), [[eq:energy]]  decreases in time, i.e. consistence with the second law of thermodynamics. Therefore, we use discrete variants of those concepts as necessary conditions for a "good" solution. Furthermore, since \( E_{bulk} \) is closely correlated with chemical potential, \( \mu \), we evaluate this difference as quality of convergence.
** Energy evaluations
As discrete energy measure we use:
\begin{align*}
E^{\text{bulk}}_d(\phi_{ij}) &= \sum_{i,j \in \Omega} \frac{\varepsilon^2}{2} |G\nabla_d \phi_{ij} |^2 + W\left(\phi_{ij}\right)  \\
&= \sum_{i,j \in \Omega} \frac{\varepsilon^2}{2} G_{i+\frac{1}{2}j}(D_x\phi_{i+\frac{1}{2}j}) ^2 + G_{ij+\frac{1}{2}}(D_y\phi_{ij+\frac{1}{2}})^2  + W\left(\phi_{ij}\right)  \\
\end{align*}
#+begin_src julia :tangle src/utils.jl :eval never
function bulk_energy(solver::T) where T <: Union{multi_solver , relaxed_multi_solver}
    energy = 0
    dx = CartesianIndex(1,0)
    dy = CartesianIndex(0,1)
    W(x) = 1/4 * (1-x^2)^2
    for I in CartesianIndices(solver.phase)[2:end-1,2:end-1]
        i,j = I.I
        energy += solver.epsilon^2 / 2 * G(i+ 0.5,j ,solver.len, solver.width) * (solver.phase[I+dx] - solver.phase[I])^2 + G(i,j+0.5,solver.len ,solver.width) * (solver.phase[I+dy] - solver.phase[I])^2 + W(solver.phase[I])
        end
   return energy
end
#+end_src


#+name: fig:energy-balance
#+begin_src julia-vterm :results file graphics :file energy_balance.svg
<<init>>
using JLD2
using DataFrames
i0 = 1*64 +1
results = jldopen("experiments/iteration.jld2")["result"]
energy = bulk_energy.(results[i0:i0+63,:].solver)
p1 = plot(1:64 , energy , title=L"Discrete Helmholtz Energy $E_d^{bulk}$", xlabel="timesteps" , ylabel="energy"  , label=false)
p2 = heatmap(results.solver[i0].phase , title="initial condition" , legend=:none , aspectratio=:equal , showaxis=false , grid=false)
p3 = heatmap(results.solver[i0+63].phase , title="after 64 time-steps" , aspectratio=:equal , legend=:none , showaxis=false , grid=false)
p = plot(p2,p3,p1 , layout=layout3x1 , size=size3x1  )

savefig(p , "images/energy_balance.svg")
#+end_src

#+caption: behaviour of energy \( E_{bulk} \) over time for one initial condition \( \phi_0 \).
#+RESULTS: fig:energy-balance
[[file:images/energy_balance.svg]]

here we observe the discrete Helmholtz energy going down with increasing number of timesteps, as we expect from a cahn hilliard based solver.
** Numerical mass balance
Instead of a physical mass we use the average of \(\phi\) over the domain \(\Omega\).
We calculate this balance between /phase 1/ and /phase 2/ as follows:
\begin{align*}
b &= \frac{\sum_{i,j \in \Omega} \phi_{ij}}{N^2}
\end{align*}
such that \( b = 1 \) means there is only phase 1, \( \phi \equiv 1 \), and \( b = -1 \) means there is only phase 2, \( \phi \equiv -1 \).
#+begin_src julia :tangle src/utils.jl
function massbal(arr)
    num_cells= *((size(arr).-2)...)
    return sum(arr[2:end-1, 2:end-1])/num_cells
    end
#+end_src

#+name: fig:mass-balance
#+begin_src julia-vterm :results file graphics :file mass_balance.svg :output-dir images :noweb no-export :session jl
<<init>>
using JLD2
using DataFrames
using Measures
pgfplotsx()
i0 = 64 * 1 + 1
results = jldopen("experiments/iteration.jld2")["result"]
energy = [ massbal(s.phase) for s in results[i0:i0+63,:].solver]
p1 = plot(1:64 ,
          energy .- energy[1],
          xlabel= "time-steps" ,
          ylabel = "error" ,
          title = "phase change",
          label=false)
p2 = heatmap(results.solver[i0].phase ,
             title="initial condition" ,
             legend=:none ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false)
p3 = heatmap(results.solver[i0+63].phase ,
             title="after 64 time-steps" ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false ,
             legend=:none)

p = plot(p2,
         p3 ,
         p1 ,
         layout= layout3x1 ,
         size=size3x1)

savefig(p , "images/mass_balance.svg")
#+end_src

        #+caption: behaviour of phase change over time for one initial condition \( \phi_0 \).
#+RESULTS: fig:mass-balance
[[file:images/mass_balance.svg]]

The baseline solver manages a massbalance close to machine precision for our test cases. Mass loss and phase change is therefore negligible.
** stability of a multigrid sub iteration
in order to evaluate convergence we observe the change in phase
\begin{equation}
\| \phi^n - \phi^{n+1,m} \|_{Fr}
\end{equation}
where \( \|\cdot\|_{Fr} \) is the Frobenious norm defined by
\begin{equation}
\| f \| = \sqrt{ \sum_{i,j \in \Omega_d} f_{ij}^2}
\end{equation}
over the tensors representing \( \phi.^n,\phi^{n+1,m} \).
we expect our solver to converge if we do more sub-iterations. To test this we compare the phase-field \( \phi_{ij}^{n+1,m-1} \) after \( m-1 \) sub-iterations with the phase-field \( \phi_{ij}^{n+1,m} \) after m sub-iterations. As sub-iterations increase , \( m\to\infty \) we expect the difference between both phase-fields to go to zero \( \|\phi^{n+1,m} - \phi^{n+1,m-1}\|_{Fr} \to 0 \)
#+name: fig:convergence
#+begin_src julia-vterm :results file graphics :file convergence.svg
<<init>>
<<setup-diverse-testgrids>>
using DataFrames
using JLD2
using LaTeXStrings
i0 = 4
df = jldopen("experiments/subiteration.jld2")["result"]
gd = groupby(df , :iteration)
res = combine(gd  , :cycle => ((x)-> [norm(x[i].phase - x[i-1].phase) for i in 2:size(x,1)]))

gres =  groupby(res , :iteration)[1]
p1= res.cycle_function[i0*64:(i0+1)*64-2] |>
    (x)-> plot(x ,
               yscale=:log10 ,
               title="Behaviour" ,
               xlabel="sub-iterations" ,
               ylabel= "diffrence" ,
               label= L" \|\phi^{n+1,m} - \phi^{n+1,m-1}\|_{Fr} ")
p2 = heatmap(df.cycle[i0].phase ,
             title="initial condition" ,
             legend=:none ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false)
p3 = heatmap(df.cycle[i0].phase .-df.cycle[i0+62].phase ,
             title="after 64 subiteration" ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false )

p = plot(p2,
         p3 ,
         p1 ,
         layout= layout3x1 ,
         size=(1600 , 1600))
savefig(p , "images/convergence.svg")
#+end_src

#+caption: stability of the original CH solver for increasing sub-iterations
#+RESULTS: fig:convergence
[[file:images/convergence.svg]]

in practise we observe the behaviour we expect, where an increasing number of sub-iterations leads to decreasing change compared to the previous sub-iteration.

#+begin_src julia-vterm :results file graphics :file subiteration.svg :output-dir images :noweb no-export :session jl :exports none
<<init>>
using DataFrames
using JLD2
using LaTeXStrings
df = jldopen("experiments/subiteration.jld2")["result"]
gd = groupby(df , :iteration)
p1 = heatmap(gd[1].cycle[1].phase , aspectratio=:equal , title= "one subiteration" , showaxis=false  )
p2 = heatmap(gd[1].cycle[64].phase , aspectratio=:equal , title = "64 sub-iterations" , showaxis=false)
p = plot(p1,p2)
savefig(p , "images/subiteration.svg")
#+end_src

#+RESULTS:
[[file:images/subiteration.svg]]

** stability under refinment in time
we test the bahaviour unter refinement in time by succesivly subdeviding the original time interval \( [0,T] \) in finer parts


#+name: fig:stability-in-time
#+begin_src julia-vterm :results file graphics :file time-stability.svg
<<init>>
using DataFrames
using JLD2
using LaTeXStrings

df = jldopen("experiments/time.jld2")["result"]
gd = groupby(df , :iteration)

sd =  combine(x->(;phase=x[end,:].phase) , gd)
change = [norm(sd[!, "phase"][i] .- sd[! , "phase"][i-1]) for i=2:size(sd , 1)]

p1 = plot(change ,
         ylabel = "difference to previous number time-steps" ,
         xlabel = L"number of time-steps to $t = 10^{-2}s$" ,
         label=L"\|\phi_{ij}^{n+1} - \phi_{ij}^n \|_{Fr}" ,
         title= L"behavior of the original CH solver at $t=10^{-2}s$")
p2 = heatmap(gd[5].phase[end],
             title=L"$t=10^{-2} \,, n=5$" ,
             legend=:none ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false)
p3 = heatmap(gd[end].phase[end],
             title=L"$t=10^{-2} \,, n=64$" ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false ,
             legend=:none)

p = plot(p2,
         p3 ,
         p1 ,
         layout= layout3x1 ,
         size=size3x1)
savefig(p , "images/time-stability.svg")
#+end_src

#+Caption: behavior of the baseline solver while solving the time interval \( T = \left[ 0 , 10^{-2} \right] \) with increasing number of time-steps.
#+RESULTS[d744c21eb7ad91d50d16e0c23cb2d64680ead8c8]: fig:stability-in-time
[[file:images/time-stability.svg]]


In this experiment we ran our solver on a fixed length time intervall ie. we ran our solver for one time.step with \( \Delta t = 10^{-2}  \) , for two time-steps with \( \Delta t = \frac{10^{-2}}{2}  \) and so on until 64 time-steps with \( \Delta t = \frac{10^{-2}}{64}  \).
** stability under refinement in space
We expect our methods to be stable in space. Therefore we expect
#+RESULTS:
#+name: fig:stability-in-space
#+begin_src julia-vterm :results file graphics :file space-stability.svg
<<init>>
using DataFrames
using JLD2
using LaTeXStrings
df = jldopen("experiments/space_refinement.jld2")["result"]
gd = groupby(df , :iteration)
change = [norm(df[!, "phase"][i] .- restrict(df[! , "phase"][i-16] , G))/*(size(df[!,"phase"][i])...) for i=17:16:size(df , 1)]
p1 = plot([L"1024^2 \to 512^2" , L"512^2 \to 256^2" , L"256^2\to128^2" , L"128^2\to64^2" , L"64^2 \to32^2"],
         change ,
         ylabel = "difference" ,
         yscale=:log10,
         xlabel = "change in number of gridpoints" ,
         label=L"\Delta \phi" ,
         xscale=:log2 ,
         seriestype=:scatter ,
         xaxis=:flip ,
         legend=:topright)

p2 = heatmap(gd[16].phase[begin],
             title=L"1024 \times 1024" ,
             legend=:none ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false)
p3 = heatmap(gd[16].phase[4],
             title=L"128 \times 128" ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false ,
             legend=:none)

p = plot(p2,
         p3 ,
         p1 ,
         layout= layout3x1 ,
         size=size3x1)
savefig(p , "images/space-stability.svg")
#+end_src

#+Caption: behavior of the baseline solver while solving on successively finer grids
#+RESULTS[d65d9dfebf929c604fd273a9c1ffcfd955bb13e0]: fig:stability-in-space
[[file:images/space-stability.svg]]

* Relaxed problem
In effort to decrease the order of complexity, from fourth order derivative to second order, we propose an elliptical relaxation approach, where the relaxation variable \( c \) is the solution of the following elliptical PDE:
#+name: eq:elliptical-equation
\begin{align}
- \Delta c^\alpha  + \alpha c^a &= \alpha \phi ^\alpha,
\end{align}
where \( \alpha \) is a relaxation parameter. We expect to approach the original solution of the CH equation [[eq:CH]] as  \( \alpha \to \infty \).
This results in the following relaxation for the classical CH equation [[eq:CH]]:
#+name: eq:relaxed-cahn-hilliard
\begin{equation}
\begin{aligned}
\partial_t \phi^\alpha  &= \Delta \mu \\
\mu &= \varepsilon ^2 \alpha(c^\alpha - \phi^\alpha) + W'(\phi)
\end{aligned}
\end{equation}
It requires solving the elliptical PDE each time-step to calculate \(c\).

As ansatz for the numerical solver we propose:
#+name: eq:discrete-relaxed-cahn-hilliard
\begin{equation}
\begin{aligned}
\frac{\phi_{ij}^{n+1,\alpha} - \phi_{ij}^{n,\alpha}}{\Delta t}  &=  \nabla _d \cdot (G_{ij} \nabla_d \mu_{ij}^{n+\frac{1}{2},\alpha} )  \\
 \mu_{ij}^{n+\frac{1}{2},\alpha} &= 2\phi_{ij}^{n+1,\alpha} - \varepsilon^2 a(c_{ij}^{n+1,\alpha} - \phi_{ij}^{n+1,\alpha})  + W'(\phi_{ij}^{n,\alpha}) - 2\phi _{ij}^{n,\alpha}
\end{aligned}
\end{equation}
This approach is inspired by [[eq:discrete-cahn-hilliard]] adapted to the relaxed CH equation [[eq:discrete-relaxed-cahn-hilliard]].
We then adapt the multi-grid solver proposed in [[Baseline multi-grid solver]] to the relaxed problem by replacing the differential operators by their discrete counterparts as defined in [[eq:discretization]],
and expand them.
** Elliptical PDE:
In order to solve the relaxed CH equation we solve the following PDE in each  time step:
\begin{align*}
- \nabla \cdot  (G \nabla c^\alpha) + \alpha c^\alpha  = \alpha \phi ^\alpha
\end{align*}

Similarly to the first solver we solve this PDE  with a finite difference scheme using the same discretization as before.
*** Discretization
The discretization of the PDE expands the differential operators in the same way and proposes an equivalent scheme for solving the elliptical equation [[eq:elliptical-equation]].
\begin{align*}
- \nabla_d \cdot  (G_{ij} \nabla_d c_{ij}^\alpha) + \alpha  c_{ij}^\alpha &= \alpha \phi_{ij}^\alpha
\end{align*}
\( \implies \)
\begin{align*}
- (\frac{1}{h}(G_{i+\frac{1}{2}j} \nabla c^\alpha_{i+\frac{1}{2}j} + G_{ij+\frac{1}{2}} \nabla c^\alpha_{ij+\frac{1}{2}}) &  \\
- (G_{i-\frac{1}{2}j} \nabla c^\alpha_{i-\frac{1}{2}j} + G_{ij-\frac{1}{2}} \nabla c^\alpha_{ij-\frac{1}{2}})) + \alpha  c_{ij}^\alpha   &= \alpha  \phi_{ij}^\alpha
\end{align*}
\( \implies \)
\begin{align*}
- \frac{1}{h^2} ( G_{i+\frac{1}{2}j}(c_{i+1j}^\alpha - c_{ij}^\alpha) & \\
+G_{ij+\frac{1}{2}}(c_{ij+1}^\alpha - c_{ij}^\alpha) & \\
+G_{i-\frac{1}{2}j}(c_{i-1j}^\alpha - c_{ij}^\alpha)& \\
+G_{ij-\frac{1}{2}}(c_{ij-1}^\alpha - c_{ij}^\alpha)) + \alpha  c_{ij}^\alpha &=\alpha  \phi_{ij}^\alpha
\end{align*}


As before we abbreviate \(  \Sigma_G c^\alpha_{ij} = G_{i+\frac{1}{2}j} c^\alpha_{i+1j} +  G_{i-\frac{1}{2}j} c^\alpha_{i-1j} + G_{ij+\frac{1}{2}}  c^\alpha_{ij+1} + G_{ij-\frac{1}{2}} c^\alpha_{ij-1}  \) and \(  \Sigma_{Gij} = G_{i+\frac{1}{2}j} + G_{i-\frac{1}{2}j} + G_{ij+\frac{1}{2}} + G_{ij-\frac{1}{2}}  \). Then the discrete elliptical PDE can be stated as:
#+name: eq:discrete_elyps
\begin{align}
-\frac{ \Sigma_G c^\alpha_{ij}}{h^2} + \frac{\Sigma_G}{h^2} c^\alpha_{ij} + \alpha c^\alpha_{ij} &= \alpha\phi^\alpha_{ij}
\end{align}

solving [[eq:discrete_elyps]] for \(c_{ij}^\alpha \) then results in.
\begin{align*}
\left( \frac{\Sigma_{Gij}}{h^2} + \alpha \right)c_{ij}^{\alpha} = \alpha\phi^{\alpha}_{ij} + \frac{\Sigma_G c_{ij}^{\alpha}}{h^2}\\
c_{ij}^{\alpha} = \frac{\alpha\phi^{\alpha}_{ij} + \frac{\Sigma_G c_{ij}^{\alpha}}{h^2}}{\frac{\Sigma_{G}}{h^2} + \alpha}\\
c_{ij}^{\alpha} = \frac{\alpha h^2 \phi^{\alpha}_{ij}}{\Sigma_{Gij} + \alpha h^2} + \frac{\Sigma_G c_{ij}^{\alpha}}{\Sigma_{Gij} + \alpha h^{2}}
\end{align*}
and can be translated to code as follows
#+begin_src julia :eval never :tangle src/elypssolver.jl :exports none
using ProgressBars

"""
    elyps_solver(c,
    phase,
    len,
        width,
    alpha,
    h,
    n
)

TBW
"""
#+end_src
#+name: elyps_solver
#+begin_src julia :eval never :tangle src/elypssolver.jl
function elyps_solver!(solver::T, n) where T  <: Union{relaxed_multi_solver , adapted_relaxed_multi_solver}
    for k in 1:n
        for i = 2:(solver.len+1)
            for j = 2:(solver.width+1)
                bordernumber = neighbours_in_domain(i, j,G, solver.len, solver.width)
                solver.c[i, j] =
                    (
                        solver.alpha * solver.phase[i, j] +
                        discrete_G_weigted_neigbour_sum(i, j, solver.c, G, solver.len, solver.width) / solver.h^2
                    ) / (bordernumber / solver.h^2 + solver.alpha)

            end
        end
    end
end
#+end_src
** Relaxed PDE as operator L
We reformulate the discretization [[eq:discrete-relaxed-cahn-hilliard]] in terms of the relaxed operator \(L\) as follows:
\begin{align*}
L_r
\begin{pmatrix}
\phi ^{n+1,\alpha} \\
\mu^{n+\frac{1}{2},\alpha}
\end{pmatrix}
&=
\begin{pmatrix}
\frac{\phi^{n+1,m,\alpha}_{ij}}{\Delta t} - \nabla _d \cdot (G_{ji} \nabla _d \mu^{n + \frac{1}{2},m,\alpha}_{ji}) \\
\varepsilon ^2 \alpha (c^\alpha - \phi^{n+1,m,\alpha}_{ij}) - 2\phi ^{n+1,m,\alpha}_{ij} -\mu^{n + \frac{1}{2},m,\alpha}_{ji}
\end{pmatrix}
\end{align*}

and its Jacobian:
\begin{align*}
DL_r\begin{pmatrix}
\phi \\
\mu
\end{pmatrix} &= \begin{pmatrix}
\frac{1}{\Delta t} & \frac{1}{h^2}\Sigma_{G}  \\
- \varepsilon^2 \alpha  - 2 & 1
\end{pmatrix}
\end{align*}

** The relaxed multigrid method
As the difference between both methods is abstracted away in the operators, the relaxed V-cycle the replaces the original operators with their relaxed counterparts. Due to julias multiple dispatch features this changes nothing in the implementation Therefore we reuse the original V-cycle in the [[Multigrid method]].
In the executions for each time step, we add the elliptic solver in the subiteration.
#+begin_src julia :eval never :exports code
for j in 1:timesteps

    set_xi_and_psi!(solvers[1])

    for i = 1:subiterations

        elyps_solver!(solvers[1] , 1000)
        v_cycle!(solvers, 1)
    end
end
#+end_src

#+name: fig:relaxed-anim
#+begin_src julia-vterm :results file graphics :file relaxed-anim.gif
<<init>>
using JLD2
using DataFrames
using Measures

gr()

results = jldopen("experiments/relaxed-iteration4.jld2")["result"]
anim = @animate for s in results.solver
    heatmap(s.phase)
    end
gif(anim , "images/relaxed-anim.gif", fps=10)
#+end_src

#+RESULTS: fig:relaxed-anim
[[file:images/relaxed-anim.gif]]

** SMOOTH operator
The relaxed solver uses the same approach as the original solver, where we solve \( L_r(\phi^{n+1,m,\alpha}_{ij}, \mu^{n+\frac{1}{2},m,\alpha}_{ij}) = (\zeta_{ij}^n , \psi_{ij}^n)^T \) for each grid-point \( \phi_{ij}^{n+1,m,\alpha} \). Notably \((\zeta_{ij}^n , \psi_{ij}^n)^T  \) is the same as in the original part. As in the original smoothing, evalations of \( \mu^{n+\frac{1}{2},m,\alpha}_{kl} \) for \( k,l > i,j \) are replaced with their values from the previous SMOOTH iteration.

Correspondingly the SMOOTH operation expands to:
#+name: eq:discrete-relaxed-smooth
\begin{equation}
\begin{aligned}
  -\frac{\Sigma_{Gij}}{h^2}\overline{\mu^{n + \frac{1}{2},m,\alpha}_{ji}} &= \frac{\phi ^{n+1,m,\alpha}_{ij}}{\Delta t} - \zeta^{n,\alpha}_{ij} - \frac{\Sigma_G\mu_{ij}}{h^2} \\
 \varepsilon ^2 \alpha \overline{\phi ^{n+1,m,\alpha}_{ij}} + 2 \phi ^{n+1,m,\alpha}_{ij} &= \varepsilon ^2 \alpha c^{n,\alpha}_{ij}  -\overline{\mu^{n + \frac{1}{2},m,\alpha}_{ji}}  - \psi_{ij}^{n,\alpha}
\end{aligned}
\end{equation}
where
- \(  \Sigma_G \mu_{ij} = G_{i+\frac{1}{2}j} \mu^{n + \frac{1}{2},m}_{i+1j} +  G_{i-\frac{1}{2}j} \mu^{n + \frac{1}{2},m}_{i-1j} + G_{ij+\frac{1}{2}}  \mu^{n + \frac{1}{2},m}_{ij+1} + G_{ij-\frac{1}{2}} \mu^{n + \frac{1}{2},m}_{ij-1}  \),
We then solve directly for the smoothed variables, \( \overline{\mu_{ij}^{n+1,m,\alpha}} \) and \( \overline{\phi_{ij}^{n+1,m,\alpha}} \). This was not done in the original paper [cite:@SHIN20117441] because the required system of linear equations in the paper [cite:@SHIN20117441]  was solved numerically.
\begin{align*}
\varepsilon^2 \alpha(\phi_{ij}^{n+1,m,\alpha}) + 2\phi_{ij}^{n+1,m,\alpha} &= \varepsilon^2 \alpha c^\alpha - \frac{h^2}{\Sigma_G} (\frac{\phi_{ij}^{n+1,m,\alpha}}{\Delta t} - \zeta^n_{ij} - \frac{1}{h^2} \Sigma_G \mu_{ij}) - \psi_{ij}
\end{align*}
\( \implies \)
\begin{align*}
\varepsilon^2\alpha (\phi_{ij}^{n+1,m,\alpha}) + 2\phi_{ij}^{n+1,m,\alpha} + \frac{h^2}{\Sigma_{Gij}}\frac{\phi_{ij}^{n+1,m,\alpha}}{\Delta t} &= \varepsilon^2 \alpha c^\alpha - \frac{h^2}{\Sigma_G} (- \zeta^n_{ij} - \frac{1}{h^2} \Sigma_G \mu_{ij}) - \psi_{ij}
\end{align*}
\( \implies \)
\begin{align*}
(\varepsilon^2 \alpha + 2 + \frac{h^2}{\Sigma_G \Delta t}) \phi_{ij}^{n+1,m,\alpha} &= \varepsilon^2 \alpha c^\alpha - \frac{h^2}{\Sigma_G}(- \zeta^n_{ij} - \frac{\Sigma_G \mu_{ij}}{h^2} ) -\psi_{ij}
\end{align*}
\( \implies \)
\begin{align*}
 \phi_{ij}^{n+1,m,\alpha} &= \left(\varepsilon^2 \alpha c^\alpha - \frac{h^2}{\Sigma_G}(- \zeta^n_{ij} - \frac{\Sigma_G \mu_{ij}}{h^2} ) -\psi_{ij}\right)\left(\varepsilon^2 \alpha + 2 + \frac{h^2}{\Sigma_G \Delta t}\right)^{-1}
\end{align*}
#+name: solve-for-phi
#+begin_src julia :eval never :exports none
bordernumber = neighbours_in_domain(i, j, G, solver.len, solver.width)

solver.phase[I] = (solver.epsilon^2 * solver.alpha * solver.c[I] - solver.h^2 / bordernumber * ( -solver.xi[I]  - discrete_G_weigted_neigbour_sum(i,j,solver.potential , G , solver.len , solver.width) / solver.h^2 ) - solver.psi[I]) / (solver.epsilon^2 * solver.alpha  + 2 + solver.h^2 / (bordernumber*solver.dt))
#+end_src
#+name: update-the-potential
#+begin_src julia :eval never :exports none
            solver.potential[I] = (solver.phase[I]/solver.dt - solver.xi[I] - discrete_G_weigted_neigbour_sum(i,j, solver.potential , G , solver.len , solver.width)/solver.h^2) * (-solver.h^2/bordernumber)
#+end_src
#+name: SMOOTH_relaxed
#+begin_src julia :eval never :tangle src/multi_relaxed.jl :noweb no-export
function SMOOTH!(
    solver::T,
    iterations,
    adaptive
) where T <: Union{relaxed_multi_solver , adapted_relaxed_multi_solver}
    for k = 1:iterations
        old_phase = copy(solver.phase)
        for I in CartesianIndices(solver.phase)[2:end-1, 2:end-1]
            i, j = I.I
            <<solve-for-phi>>
            <<update-potential>>
        end

        #if adaptive && LinearAlgebra.norm(old_phase - solver.phase) < 1e-10
            ##println("SMOOTH terminated at $(k) succesfully")
            #break
        #end
    end
end
#+end_src

#+name: fig:relaxed-smooth-eval
#+begin_src julia-vterm :results file graphics :file smooth_relaxed.svg
<<init>>
plots = []
eps = 0.13
#M = testdata(64, div(64,3), 64/5 , 2)
for alpha in [1e3 , 1e4 , 1e5 , 1e6 , 32500]
local testgrd = testgrid(relaxed_multi_solver,M, 2 ; alpha=alpha , epsilon=eps)
set_xi_and_psi!(testgrd[1])
elyps_solver!(testgrd[1] , 2000)
SMOOTH!(testgrd[1], 1000, false);
push!(plots , heatmap(testgrd[1].phase, aspect_ratio=:equal, title=L"$\alpha = %$alpha$" , xlim=(2,testgrd[1].len) , ylim=(2,testgrd[1].width) , showaxis=false , legend=false));
    end

original = testgrid(multi_solver,M, 2)
set_xi_and_psi!(original[1])
SMOOTH!(original[1], 1000, false);
push!(plots , heatmap(original[1].phase, aspect_ratio=:equal, title="original" , xlim=(2,original[1].len) , ylim=(2,original[1].width) , showaxis=false , legend=false));
p = plot(plots...)
savefig(p,"images/smooth_relaxed.svg")
#+end_src

#+caption: effect of the relaxed SMOOTH operator, and additional solving of the elliptical problem, for different values of alpha
#+RESULTS: fig:relaxed-smooth-eval
[[file:images/smooth_relaxed.svg]]

Furthermore, experimentation shows that alpha alone is insufficient to get a relaxed method consistent with the original solver, since alpha had an effect similar to epsilon, where it changed the boundary thickness in the phase-field \( \phi \). Therefore epsilon and alpha cannot be chosen independently. Hence we use a simple MCMC optimizer for \( \alpha,\varepsilon \) in order to give the relaxed solver the best chance we can.
Monte Carlo Optimizer For \( \varepsilon , \alpha \).
#+begin_src julia :tangle src/optim.jl :noweb yes
using Distributions
using DataFrames
using JLD2
<<init>>

function test_values(alpha_distribution::Distribution , epsilon_distribution::Distribution , M)
    alpha = rand(alpha_distribution)
    eps = max(rand(epsilon_distribution)  ,1e-10)
    relaxed_solver = testgrid(relaxed_multi_solver, M, 2; alpha=alpha, epsilon=eps)
    set_xi_and_psi!(relaxed_solver[1])
    #SMOOTH!(relaxed_solver[1], 100, false)
    for j=1:64
    elyps_solver!(relaxed_solver[1], 2000)
    v_cycle!(relaxed_solver , 1)
    end
    error = norm(relaxed_solver[1].phase .- original_solver[1].phase) / *(size(relaxed_solver[1].phase)...)
    return (;alpha=alpha , epsilon=eps , error=error)
end

original_solver = testgrid(multi_solver, M, 2)
set_xi_and_psi!(original_solver[1])
for j=1:64
v_cycle!(original_solver , 1)
end
#SMOOTH!(original_solver[1], 100, false);
eps = 3e-3
#M = testdata(64, div(64,3), 64/5 , 2)
alpha0 = 10000
epsilon0 = 1e-2
best_alpha = alpha0 / 10
best_epsilon = epsilon0 / 10
best_error  = Inf
results = DataFrame()
for n=1:1000
    searchradius = 1
    alpha_distribution = Normal(best_alpha , searchradius * alpha0)
    epsilon_distribution = Normal(best_epsilon , searchradius * epsilon0)
    result = test_values(alpha_distribution , epsilon_distribution , M)
    if result.error < best_error
        global best_error = result.error
        global best_alpha = result.alpha
        global best_epsilon = result.epsilon
        println(result)
    end
push!(results , result)
end
jldsave("experiments/alpha-epsilon.jld2"; result=results)
println("Best alpha: $best_alpha , Best epsilon: $best_epsilon")
#+end_src
sadly the MCMC didn't yield results consistent with the original solver after a few Iterations
* rate of stability
** massbal
#+name: fig:relaxed-mass-balance
#+begin_src julia-vterm :results file graphics :file relaxed-mass-balance.svg
<<init>>
using JLD2
using DataFrames
using Measures
i0 = 64 * 3+1
results = jldopen("experiments/relaxed-iteration.jld2")["result"]
energy = [ massbal(s.phase) .- massbal(results.solver[i0].phase) for s in results[i0:i0+63,:].solver]
p1 = plot(1:64 , energy, xlabel= "time-steps" , ylabel = "error"  , label =false)
p2 = heatmap(results.solver[i0].phase , title="initial condition" , legend=:none , aspectratio=:equal , grid=false , showaxis=false)
p3 = heatmap(results.solver[i0+63].phase , title="after 64 time-steps" , legend=:none , aspectratio=:equal , grid=false , showaxis=false)
p = plot(p2,p3 , p1 , layout=layout3x1 , size=(1600 ,1600))
savefig(p , "images/relaxed-mass-balance.svg")
#+end_src

#+RESULTS: fig:relaxed-mass-balance
[[file:images/relaxed-mass-balance.svg]]

** energy

#+name: fig:relaxed-energy-balance
#+begin_src julia-vterm :results file graphics :file relaxed-energy-balance.svg
<<init>>
using JLD2
using DataFrames
i0 = 1*64 +1
original_results = jldopen("experiments/iteration.jld2")["result"]
relaxed_results = jldopen("experiments/relaxed-iteration.jld2")["result"]
original_energy = bulk_energy.(original_results[i0:i0+63,:].solver)
relaxed_energy = bulk_energy.(relaxed_results[i0:i0+63,:].solver)
p1 = plot(1:64 , original_energy , title=L"Discrete Helmholtz Energy $E_d^{bulk}$", xlabel="timesteps" , ylabel="energy"  , label="original")
p1 = plot!(p1,1:64 , relaxed_energy , title=L"Discrete Helmholtz Energy $E_d^{bulk}$", xlabel="timesteps" , ylabel="energy"  , label="relaxed")
p2 = heatmap(relaxed_results.solver[i0].phase , title="initial condition" , legend=:none , aspectratio=:equal , showaxis=false , grid=false)
p3 = heatmap(relaxed_results.solver[i0+63].phase , title="after 64 time-steps" , aspectratio=:equal , legend=:none , showaxis=false , grid=false)
p = plot(p2,p3,p1 , layout=layout3x1 , size=(1600 ,1600))
savefig(p , "images/relaxed-energy-balance.svg")
#+end_src

#+caption: energy decay of the relaxed solver compared to the original solver.
#+RESULTS[06f7ce276ee26e0f3adfda9d2fb591ad7786b44f]: fig:relaxed-energy-balance
[[file:images/relaxed-energy-balance.svg]]


We observe the discrete Helmoltz energy decrease is the same manner as with the original solver.
** convergence of a sub iteration v-cycle

#+name: fig:relaxed-convergence
#+begin_src julia-vterm :results file graphics :file relaxed-convergence.svg
<<init>>
using DataFrames
using JLD2
using LaTeXStrings
n=1024

i0 = 1
df = jldopen("experiments/subiteration.jld2")["result"]
df = groupby(df , :experiment)[i0]
gd = groupby(df , :iteration)
original_res = combine(gd  , :cycle => ((x)-> [norm(x[i].phase - x[i-1].phase) for i in 2:size(x,1)]))

original_res =  groupby(original_res , :iteration)[1].cycle_function


df = jldopen("experiments/relaxed-subiteration.jld2")["result"]
df = groupby(df , :experiment)[i0]
gd = groupby(df , :iteration)
relaxed_res = combine(gd  , :cycle => ((x)-> [norm(x[i].phase - x[i-1].phase) for i in 2:size(x,1)]))

relaxed_res =  groupby(relaxed_res , :iteration)[1].cycle_function
p=plot([original_res, relaxed_res],label= ["original"  "relaxed"])
savefig(p , "images/relaxed-convergence.svg")
#+end_src

#+RESULTS: fig:relaxed-convergence
[[file:images/relaxed-convergence.svg]]

** convergence unter refinment in time
we test the bahaviour unter refinement in time by succesivly subdeviding the original time interval \( [0,T] \) in finer parts


#+name: fig:relaxed-stability-in-time
#+begin_src julia-vterm :results file graphics :file relaxed-time-stability.svg
<<init>>
using DataFrames
using JLD2
using LaTeXStrings
df = jldopen("experiments/relaxed-time.jld2")["result"]
dfo = jldopen("experiments/time.jld2")["result"]
gdo = groupby(dfo,:iteration)
dfo = DataFrame([ last(x) for x in gdo])
change = [norm(df[!, "phase"][i] .- df[! , "phase"][i-1]) for i=2:size(df , 1)]
change0 = [norm(dfo[!, "phase"][i] .- dfo[! , "phase"][i-1]) for i=2:size(dfo , 1)]
p = plot(change , ylabel = "difference" , xlabel = "number of timesteps" , label="relaxed" )
p = plot(p , change0 , ylabel = "difference" , xlabel = "number of timesteps" , label="original")
savefig(p , "images/relaxed-time-stability.svg")
#+end_src

#+Caption: behavior of both  solvers while solving the time interval \( T = \left[ 0 , 10^{-2} \right] \) with increasing number of timesteps
#+RESULTS: fig:relaxed-stability-in-time
[[file:images/relaxed-time-stability.svg]]

** convergence under refinement in space
we test convergence in space by succesivly subdividing our grid into finer meshes


#+name: fig:relaxed-stability-in-space
#+begin_src julia-vterm :results file graphics :file relaxed-space-stability.svg
<<init>>
using DataFrames
using JLD2
using LaTeXStrings
df = jldopen("experiments/relaxed_space_refinement.jld2")["result"]
change = [norm(df[!, "phase"][i] .- restrict(df[! , "phase"][i-16] , G))/*(size(df[!,"phase"][i])...) for i=17:16:size(df , 1)]
p = plot([L"1024^2 \to 512^2" , L"512^2 \to 256^2" , L"256^2\to128^2" , L"128^2\to64^2" , L"64^2 \to32^2"],change , ylabel = "difference" , yscale=:log10, xlabel = "change in number of gridpoints" , label=L"\Delta \phi" , xscale=:log2 , seriestype=:scatter , xaxis=:flip , legend=:topright)
savefig(p , "images/relaxed-space-stability.svg")
#+end_src

#+RESULTS: fig:relaxed-stability-in-space
[[file:images/relaxed-space-stability.svg]]

* Comparison
Furthermore we expect the approximation for \( \phi_{ij}^{n+1} \) to converge.
\begin{equation}
||\phi_{ij}^{n+1} - \phi_{ij}^{n+1,\alpha}|| \to 0
\end{equation}
In practice we observe the following behaviour:
#+begin_src julia :noweb no-export :eval never :tangle experiments/src/alpha.jl
<<init>>
using JLD2
using Distributed
using ProgressBars
using DataFrames

original_grid = testgrid(multi_solver, M, 2)
alphas = 0:1e4:2e6

function alpha_error(alpha::Number , solution::Array )
    test_solver  = testgrid(relaxed_multi_solver, M, 2, alpha=alpha)
    set_xi_and_psi!(test_solver[1])
    for j in 1:64
        elyps_solver!(test_solver[1], 1000)
        v_cycle!(test_solver , 1)
    end
return [(;alpha=alpha , error=norm(test_solver[1].phase - solution))]
end
set_xi_and_psi!(original_grid[1])
for j in 1:64
    v_cycle!(original_grid, 1)
end
print("finished original v_cycle")
tasks = []
for alpha in alphas
    t = Threads.@spawn alpha_error(alpha , original_grid[1].phase)
    push!(tasks , (alpha=alpha , task = t))
end
result = DataFrame()
for task in ProgressBar(tasks)
    append!(result , fetch(task.task) )
    end
jldsave("experiments/alpha.jld2"; result)
#+end_src


#+begin_src julia-vterm :results graphics file :file alpha-error.svg
<<init>>
using JLD2
using DataFrames
using Measures
results = jldopen("experiments/alpha.jld2")["result"]
p=plot(results.alpha  , results.error ./64^2, label=false)
savefig(p, "images/alpha-error.svg")
#+end_src

#+RESULTS[c9011a75a329dfad869e8e100b7934bea5836b44]:
[[file:images/alpha-error.svg]]

in all cases the difference to the original solver is apparent. Furthermore we observe a optimal value of \( \alpha \) at approximately \( 7.5 * 10^5 \) we explain this with our observations done for the Smoothing operator, where for small and large values of \( \alpha \) the relaxed approach ironically results in restricted behaviour. Empirical this is to be expected as. for large values of alpha the elliptical equation approaches \( \phi \)  and for small values the elliptical solver does not converge.

#+begin_src julia-vterm :results file graphics :file relaxed-comp.gif
<<init>>
using JLD2
using DataFrames
using Measures
using LaTeXStrings

gr()

results = jldopen("experiments/iteration.jld2")["result"]
results1 = jldopen("experiments/relaxed-iteration.jld2")["result"]
results2 = jldopen("experiments/relaxed-iteration-nophi.jld2")["result"]
results3 = jldopen("experiments/relaxed-iteration-nosubiter.jld2")["result"]
titles =  ["original" , "subiter elliptical" , L"without $2\phi$" , L"without $2\phi$ and subiter"]

anim = @animate for iter in zip(results.solver,results1.solver ,results2.solver , results3.solver)
    plots = []
    for (phase , title) in zip(iter ,titles)
        push!(plots , heatmap(phase.phase , title=title , legend=:none , aspectratio=:equal , grid=false , showaxis=false))
        plot(plots...)
        end
    end
gif(anim , "images/relaxed-comp.gif", fps=10)
#+end_src

although we can observe slight diffrences between the original solver and the relaxed approach they are barely noticalble by eye. Therefore we also show the numerical difference between both.
#+begin_src julia-vterm :results file graphics :file relaxed-comparison.gif
<<init>>
using JLD2
using DataFrames
using Measures
using LaTeXStrings

i = 1*64 +1
gr()

original_results = jldopen("experiments/iteration.jld2")["result"]
relaxed_results = jldopen("experiments/relaxed-iteration.jld2")["result"]

difference = [norm(original.phase./2 .- relaxed.phase./2) /64^2 for (original, relaxed) in zip(original_results.solver[i:i+63],relaxed_results.solver[i:i+63])
]
anim = @animate for (original, relaxed) in zip(original_results.solver[i:i+63],relaxed_results.solver[i:i+63])
        p1 = plot(1:size(difference,1) , difference , xlabel= "time-steps" , ylabel = "error"  , title="diffrence" , label=false)
        p2 = heatmap(original.phase , title="original" , legend=:none , aspectratio=:equal , grid=false , showaxis=false)
        p3 = heatmap(relaxed.phase , title="relaxed" , aspectratio=:equal , grid=false , showaxis=false , legend=:none)
        plot(p1,p2,p3 , layout=(1,3) , size=(2000 ,700) , bottom_margin=20Plots.mm , left_margin=20Plots.mm)
        end
gif(anim , "images/relaxed-comparison.gif", fps=10)
#+end_src

#+RESULTS:
[[file:images/relaxed-comparison.gif]]



#+name: fig:relaxed-original-comparison
#+begin_src julia-vterm :results file graphics :file relaxed-comparison.svg
<<init>>
using JLD2
using DataFrames
using Measures
using LaTeXStrings

i = 0*64 +1
gr()

original_results = jldopen("experiments/iteration.jld2")["result"]
relaxed_results = jldopen("experiments/relaxed-iteration.jld2")["result"]

difference = [norm(original.phase .- relaxed.phase) /64^2 for (original, relaxed) in zip(original_results.solver[i:i+63],relaxed_results.solver[i:i+63])
]
original, relaxed =   original_results.solver[i+63],relaxed_results.solver[i+63]
p1 = plot(1:size(difference,1) , difference , xlabel= "time-steps" , ylabel = "error"  , title="diffrence" , label=false)
p2 = heatmap(original.phase , title=L"original at $n=64$" , legend=:none , aspectratio=:equal , grid=false , showaxis=false)
p3 = heatmap(relaxed.phase , title=L"relaxed at $n=64$" , aspectratio=:equal , grid=false , showaxis=false , legend=:none)
p=plot(p1,p2,p3 , layout=(1,3) , size=(2000 ,700) , bottom_margin=20Plots.mm , left_margin=20Plots.mm)
savefig(p , "images/relaxed-comparison.svg")
#+end_src

#+caption: comparison between the original and the relaxed CH solvers.
#+RESULTS: fig:relaxed-original-comparison
[[file:images/relaxed-comparison.svg]]

Comparing both solvers visually yields little to no difference. Numerically we observe small discrepancies. However with values around \( 10^{-3} \) after 64 time-steps we are still far from the maximum error of 4, which would correspond to the inverse of the original phase.

* Apendix
** Operator implementation
#+begin_src julia :tangle src/utils.jl :eval never
function set_xi_and_psi!(solver::T) where T <: Union{multi_solver , relaxed_multi_solver}
    xi_init(x) = x / solver.dt
    psi_init(x) = solver.W_prime(x) - 2 * x
    solver.xi[2:end-1, 2:end-1] = xi_init.(solver.phase[2:end-1,2:end-1])
    solver.psi[2:end-1, 2:end-1] = psi_init.(solver.phase[2:end-1,2:end-1])
    return nothing
end
#+end_src
*** baseline
#+begin_src julia :tangle src/multisolver.jl :eval never
function L(solver::multi_solver,i,j , phi , mu)
    xi = solver.phase[i, j] / solver.dt -
         (discrete_G_weigted_neigbour_sum(i, j, solver.potential, G, solver.len, solver.width)
          -
          neighbours_in_domain(i, j, G, solver.len, solver.width) * mu )/solver.h^2
    psi = solver.epsilon^2/solver.h^2 *
          (discrete_G_weigted_neigbour_sum(i, j, solver.phase, G, solver.len, solver.width)
           -
           neighbours_in_domain(i, j, G, solver.len, solver.width) * phi) - 2 * phi + mu
    return [xi, psi]
end
#+end_src
#+begin_src julia :tangle src/multisolver.jl :eval never
function dL(solver::multi_solver , i , j)
    return [ (1/solver.dt) (1/solver.h^2*neighbours_in_domain(i,j,G,solver.len , solver.width));
             (-1*solver.epsilon^2/solver.h^2 * neighbours_in_domain(i,j,G,solver.len , solver.width) - 2) 1]
    end
#+end_src
*** relaxed
#+begin_src julia :tangle src/multi_relaxed.jl :eval never
function L(solver::relaxed_multi_solver,i,j , phi , mu)
    xi = solver.phase[i, j] / solver.dt -
         (discrete_G_weigted_neigbour_sum(i, j, solver.potential, G, solver.len, solver.width)
          -
          neighbours_in_domain(i, j, G, solver.len, solver.width) * mu )/solver.h^2
    psi = solver.epsilon^2 * solver.alpha*(solver.c[i,j] - phi) - solver.potential[i,j] - 2 * solver.phase[i,j]
    return [xi, psi]
end
#+end_src
#+begin_src julia :tangle src/multi_relaxed.jl :eval never
function dL(solver::relaxed_multi_solver , i , j)
    return [ (1/solver.dt) (1/solver.h^2*neighbours_in_domain(i,j,G,solver.len , solver.width));
             (-1*solver.epsilon^2 * solver.alpha  - 2) 1]
    end
#+end_src
** rng generation
for random point generation we use the folowing Function and seed.
#+begin_src julia-vterm :session jl :results table :exports both
using Random
rng = MersenneTwister(42)
gridsize = 64
radius = gridsize /5
blobs = gridsize ÷ 5
rngpoints = rand(rng,1:gridsize, 2, blobs)
#+end_src

#+RESULTS:
: 2×12 Matrix{Int64}:
:  48  40  20   1  63  49   8  60  26  58  26  11
:  17  13  56  52  15   9  30  14  40   9  40  25


the random testdata is then generated as follows
#+name: testdata
#+begin_src julia :eval never :tangle src/utils.jl :exports none
using Random
function testdata(gridsize , blobs , radius ,norm;rng=MersenneTwister(42))
rngpoints = rand(rng,1:gridsize, 2, blobs)
M = zeros(gridsize,gridsize) .- 1
for p in axes(rngpoints , 2)
    point = rngpoints[:, p]
    for I in CartesianIndices(M)
        if (LinearAlgebra.norm(point .- I.I  , norm) < radius)
            M[I] = 1
        end
    end
end
M
end
#+end_src
** Experiments :noexport:
*** iteration
#+begin_src julia :results output  :noweb yes :eval never :tangle experiments/src/iteration.jl
using JLD2
using DataFrames
using Random
<<init>>
<<setup-diverse-testgrids>>
function iter(g::Vector{T} , n) where T<: solver
    out = []
    for j in 1:64
    set_xi_and_psi!(g[1])
    for i = 1:64
        v_cycle!(g, 1)
    end
    push!(out, (solver=deepcopy(g[1]), iteration=j , experiment=n))
    end
    return out
end


tasks = []
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i], i)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/iteration.jld2"; result)
#+end_src

#+RESULTS:

#+name: fig:behaviour
#+begin_src julia-vterm :results graphics file :file behaviour.gif :chache :session jl :noweb no-export :output-dir images :exports none :noweb no-export
<<init>>
using JLD2
using DataFrames
results = jldopen("experiments/iteration.jld2")["result"]
n  = size(results.solver , 1)
pbar = ProgressBar(total = 10 * n)
energy = zeros(0)
massbalance = zeros(0)

anim = @animate for res in eachrow(results)
    push!(energy , bulk_energy(res.solver))
    push!(massbalance , massbal(res.solver.phase))

    p0 = heatmap(res.solver.phase , clim =(-1,1) , framestyle=:none , legend=true, lims=(1, size(res.solver.phase , 1)) , aspect_ratio=:equal, title  = "phasefield" )
   p1 = heatmap(res.solver.potential , framestyle=:none , legend=true, lims=(1,size(res.solver.phase , 1)), aspect_ratio=:equal, title  = "potential" )

    current_range = (res.experiment -1)*64 +1

    p3 = plot( 1:res.iteration, (massbalance .-massbalance[current_range])[current_range:current_range+res.iteration-1] , xlim=(1,64),  title = "Mass change")
    p2 = plot(1:res.iteration , energy[current_range:current_range+res.iteration-1], xlim=(1,64),  title = "Bulk energy")
    plot(p0,p1,p2,p3)
end
gif(anim , "images/behaviour.gif" , fps = 10)
#+end_src

#+caption: behaviour of bulk energy \( E_{bulk} \) and amount of fluid changing phase, for different initial conditions
#+RESULTS: fig:behaviour
[[file:images/behaviour.gif]]

*** subiteration
#+begin_src julia :results output :noweb yes :tangle experiments/src/subiteration.jl
using DataFrames
using JLD2
using ProgressMeter
<<init>>
<<setup-diverse-testgrids>>
n = 4
m = 64

function iter(g::Vector{T} , n , k , prg::Progress) where T<: solver
    out = []
    for j in 1:n
    set_xi_and_psi!(g[1])
    for i = 1:m
        v_cycle!(g, 1)
        push!(out, (cycle=deepcopy(g[1]), iteration=j , subiteration=i , experiment=k))
        next!(prg)
    end
    end
    return out
end


tasks = []
prg=Progress(size(tests ,1)*n*m , showspeed=true , )
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i] , n , i , prg)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/subiteration.jld2"; result)
#+end_src
*** time
#+begin_src julia :results output :noweb yes :exports none :tangle experiments/src/time.jl
using DataFrames
using JLD2
<<init>>
SIZE  =64
M = testdata(SIZE, SIZE ÷ 5, SIZE /5 , 2)
tests = [testgrid(multi_solver , M , 2 , dt = t ) for t in 1e-2./(1:64)]

function iter(g::Vector{T} , n) where T<: solver
    out = []
    for i = 1:n
    set_xi_and_psi!(g[1])
    for i = 1:64
        v_cycle!(g, 1)
    end
    push!(out, (phase=copy(g[1].phase), iteration=n))
    end
    return out
end


tasks = []
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i], i)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/time.jld2"; result)
#+end_src
*** space
#+begin_src julia :results output :noweb yes :exports none :tangle experiments/src/space.jl
using DataFrames
using JLD2
<<init>>

M = testdata(2^10 , 2^5 , 2^7 , 2 )
grids = testgrid(multi_solver  , M , 7)
# inits
for i=2:size(grids,1)
    restrict_solver!(grids[i-1] , grids[i])
end
tests = [[grids[i-1] , grids[i]] for i=2:size(grids,1)]


function iter(g::Vector{T} , n) where T<: solver
    out = []
    for j in 1:n
    set_xi_and_psi!(g[1])
    for i = 1:64
        v_cycle!(g, 1)
    end
    push!(out, (phase=copy(g[1].phase), iteration=j))
    end
    return out
end


tasks = []
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i], 16)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/space_refinement.jld2"; result)
#+end_src
** Relaxed experiments :noexport:
*** Iteration
#+begin_src julia    :noweb no-export :tangle experiments/src/relaxed-iteration.jl :async
using JLD2
using DataFrames
using ProgressMeter
using Random
<<init>>
<<setup-diverse-testgrids>>

#tests = [testgrid(relaxed_multi_solver, M , 2;alpha=82000 , epsilon=0.009) for M in initial_data]
tests = [testgrid(relaxed_multi_solver, M , 2) for M in initial_data]

n = 64
m = 64


function iter(g::Vector{relaxed_multi_solver} , n , prg::Progress)
    out = []
    for j in 1:n
    set_xi_and_psi!(g[1])
    for i = 1:m
        elyps_solver!(g[1] , 1000)
        v_cycle!(g, 1)
        next!(prg)
    end
    push!(out, (solver=deepcopy(g[1]), iteration=j , experiment=n))
    end
    return out
end

prg=Progress(size(tests ,1)*n*m , showspeed=true , )
tasks = []
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i], i , prg)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/relaxed-iteration.jld2"; result)
#+end_src

*** Subiteration
#+begin_src julia :tangle experiments/src/relaxed-subiteration.jl :noweb yes
using DataFrames
using JLD2
using ProgressMeter
<<init>>
<<setup-diverse-testgrids>>
#tests = [testgrid(relaxed_multi_solver, M , 2;alpha=32428.2 , epsilon=0.163398) for M in initial_data]
tests = [testgrid(relaxed_multi_solver, M , 2) for M in initial_data]
n = 4
m = 1024

function iter(g::Vector{T} , n ,k , prg::Progress) where T<: solver
    out = []
    for j in 1:n
    set_xi_and_psi!(g[1])
    for i = 1:m
        elyps_solver!(g[1] , 1000)
        v_cycle!(g, 1)
        push!(out, (cycle=deepcopy(g[1]), iteration=j , subiteration=i , experiment=k))
        next!(prg)
    end
    end
    return out
end


tasks = []
prg=Progress(size(tests ,1)*n*m , showspeed=true , )
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i] , n , i , prg)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/relaxed-subiteration.jld2"; result)
#+end_src

*** Time
#+begin_src julia :results output :noweb yes :exports none :tangle experiments/src/relaxed-tiem.jl
using DataFrames
using JLD2
<<init>>
tests = [testgrid(relaxed_multi_solver , M , 2 , dt = t ) for t in 1e-2./(1:64)]

function iter(g::Vector{T} , n) where T<: solver
    out = []
    for j in 1:n
    set_xi_and_psi!(g[1])
    for i = 1:64
        elyps_solver!(g[1] , 1000)
        v_cycle!(g, 1)
    end
    end
    push!(out, (phase=copy(g[1].phase), iteration=n))
    return out
end


tasks = []
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i], i)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/relaxed-time.jld2"; result)
#+end_src
*** Space
#+begin_src julia :results output :noweb yes :exports none :tangle experiments/src/space.jl
using DataFrames
using JLD2
<<init>>

M = testdata(2^10 , 2^5 , 2^7 , 2 )
grids = testgrid(relaxed_multi_solver  , M , 7)
# inits
for i=2:size(grids,1)
    restrict_solver!(grids[i-1] , grids[i])
end
tests = [[grids[i-1] , grids[i]] for i=2:size(grids,1)]


function iter(g::Vector{T} , n) where T<: solver
    out = []
    for j in 1:n
    set_xi_and_psi!(g[1])
    elyps_solver!(solver , 1000)
    for i = 1:64
        v_cycle!(g, 1)
    end
    push!(out, (phase=copy(g[1].phase), iteration=j))
    end
    return out
end


tasks = []
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i], 16)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/relaxed_space_refinement.jld2"; result)
#+end_src
* Utility functions :noexport:
#+name: imports
#+begin_src julia :session jl :results silent :exports none
using Plots
using LinearAlgebra
#+end_src


#+begin_src julia :tangle src/utils.jl :eval never
###############################################################################
#                  Common Utility Functions For Multi Solvers                 #
###############################################################################
"""
restricts an array on the small grid to an array in the large grid asserts size arr=2^n + 2 and returns ret=2^(n-1) + 2

Returns
---------------------------
large grid array + padding
"""
function restrict(arr, G)
    shape = (size(arr) .- 2) .÷ 2
    ret = zeros(shape .+ 2)
    for I in CartesianIndices(ret)[2:end-1, 2:end-1]
        i, j = I.I
        g = [
            G(2 * i - 1, 2 * j - 1, (size(arr) .- 2)...),
            G(2 * i - 1, 2 * j, (size(arr) .- 2)...),
            G(2 * i, 2 * j - 1, (size(arr) .- 2)...),
            G(2 * i, 2 * j, (size(arr) .- 2)...)
        ]
        if sum(g) == 0
            ret[I] = 0
        else
            ret[I] = (
                1 / sum(g)
                ,*
                dot(g,
                    [
                        arr[2*i-1, 2*j-1],
                        arr[2*i-1, 2*j],
                        arr[2*i, 2*j-1],
                        arr[2*i, 2*j]
                    ]
                )
            )
        end
    end
    return ret
end

"""
    prolong(arr , G)

interpolates int a smaller grid by a factor of 2

"""
function prolong(arr, G)
    inner_shape = (size(arr) .- 2) .* 2
    ret = zeros(inner_shape .+ 2)
    ONE = oneunit(CartesianIndices(arr)[1])
    for I in CartesianIndices(arr)[2:end-1, 2:end-1]
        Ind = 2 * (I - ONE) + ONE
        for J in (Ind-ONE):Ind
            ret[J] = G(J.I..., inner_shape...) * arr[I]
        end
    end
    return ret
end
"""
    restrict!(smallgrid_solver::multi_solver , largegrid_solver::multi_solver)::multi_solver

------------
Requires
----------
smallgrid solver and largegid solvers to be multiple of 2 from each other bar padding eg. (66x66)->(34x34)

------------
Returns
------------
    nothing. mutatest largegid in place to represent the smallgrid

"""
function restrict_solver!(smallgrid_solver::T, largegrid_solver::T) where {T<:solver}
    copy!(largegrid_solver.phase, restrict(smallgrid_solver.phase, G))
    copy!(largegrid_solver.potential, restrict(smallgrid_solver.potential, G))
    return nothing
end
#+end_src
#+begin_src julia :tangle src/solvers.jl :eval never
abstract type solver end
struct multi_solver <: solver
    phase::Matrix{Float64}
    potential::Matrix{Float64}
    xi::Matrix{Float64}
    psi::Matrix{Float64}
    epsilon::Float64
    h::Float64
    dt::Float64
    W_prime::Function
    len::Int
    width::Int

end
struct relaxed_multi_solver <: solver
    phase::Matrix{Float64}
    potential::Matrix{Float64}
    xi::Matrix{Float64}
    psi::Matrix{Float64}
    c::Matrix{Float64}
    epsilon::Float64
    h::Float64
    dt::Float64
    W_prime::Function
    len::Int
    width::Int
    alpha::Float64

end
#+end_src
#+begin_src julia :tangle src/testgrids.jl :eval never
function W_prime(x)
    return -x * (1 - x^2)
end
function testgrid(::Type{multi_solver},M, len; dt = 1e-3 ,  epsilon=8e-3 , h0=3e-3)
    grid = Array{multi_solver}(undef, len)
    phase = zeros(size(M) .+ 2)
    phase[2:end-1, 2:end-1] = M


    for i = 1:len
        dims = size(M) .÷ 2^(i-1) .+ 2
        grid[i] = multi_solver(zeros(dims),
            zeros(dims),
            zeros(dims),
            zeros(dims),
            epsilon, h0 * 2^i, dt,
            W_prime,
            (dims .- 2)...)

    end
    copyto!(grid[1].phase, phase)
    return grid

end

function testgrid(::Type{relaxed_multi_solver},M, len ; alpha=1e6 , dt=1e-3, epsilon=8e-3 , h0=3e-3)
    grid = Array{relaxed_multi_solver}(undef, len)
    phase = zeros(size(M) .+ 2)
    phase[2:end-1, 2:end-1] = M

    for i = 1:len
        dims = size(M) .÷ 2^(i-1) .+ 2
        grid[i] = relaxed_multi_solver(zeros(dims),
            zeros(dims),
            zeros(dims),
            zeros(dims),
            zeros(dims),
            epsilon, h0 * 2^i, dt,
            W_prime,
            (dims .- 2)... ,
            alpha)

    end
    copyto!(grid[1].phase, phase)
    return grid
end


#+end_src

#+name: init
#+begin_src julia :eval never
include(pwd() * "/src/solvers.jl")
include(pwd() * "/src/adapted_solvers.jl")
include(pwd() * "/src/utils.jl")
include(pwd() * "/src/multisolver.jl")
include(pwd() * "/src/multi_relaxed.jl")
include(pwd() * "/src/testgrids.jl")
include(pwd() * "/src/elypssolver.jl")
using Plots
using LaTeXStrings
using LinearAlgebra
using Printf
using ProgressBars
default(fontfamily="computer modern" , titlefontsize=32 , guidefontsize=32 , tickfontsize = 22 )
pgfplotsx()
layout2x2 = grid(2,2)
layout3x1 = @layout [ b  c ; a]
size3x1 = (1600,1600)
SIZE = 64
M = testdata(SIZE, SIZE ÷ 5, SIZE /5 , 2)

#+end_src
#+name: setup-grid
#+begin_src julia :eval never :noweb yes
<<init>>
testgrd = testgrid(multi_solver,M, 2)
test_solver = testgrd[1]
#+end_src

#+name: setup-relaxed-grid
#+begin_src julia :eval never :noweb yes
<<init>>
testgrd = testgrid(relaxed_multi_solver,M, 2)
println("Hi")
solver = testgrd[1]
#+end_src

#+name: setup-comparison
#+begin_src julia :noweb yes
<<init>>
using Plots
using LinearAlgebra
using ProgressBars
using JLD2
M = jldopen("data/test-phasefield.jld2")["M"]

relaxed_grid1 = testgrid(relaxed_multi_solver, M, 2 ,alpha=1e3)
relaxed_grid2 = testgrid(relaxed_multi_solver, M, 2 , alpha=1e4)
relaxed_grid3 = testgrid(relaxed_multi_solver, M, 2 , alpha=1e5)
original_grid = testgrid(multi_solver, M, 2)

#+end_src

#+name: setup-diverse-testgrids
#+begin_src julia :noweb yes
incirc(M) = filter(x -> norm(x.I .- (size(M, 1) / 2, size(M, 2) / 2)) < min(size(M)...) / 3, CartesianIndices(M))
insquare(M) = filter(x -> norm(x.I .- (size(M, 1) / 2, size(M, 2) / 2), Inf) < min(size(M)...) / 4, CartesianIndices(M))
side(M) = filter(x -> x.I[2] < size(M, 2) ÷ 2, CartesianIndices(M))
halfcirc(M) = filter(x -> norm(x.I .- (1, size(M, 2) / 2), 2) < min(size(M)...) / 3, CartesianIndices(M))

function get_special_input(fn, size)
    M = fill(-1, size , size )
    M[fn(M)] .= 1
    return M
end
SIZE  =64
t1= [testdata(SIZE, SIZE ÷ 5, SIZE /5 , j) for j in [1,2, Inf]]
t2 = [get_special_input(fn,SIZE) for  fn in [halfcirc , incirc, side , insquare]]
initial_data = [t1 ; t2]
tests = [testgrid(multi_solver, M , 2) for M in initial_data]

#+end_src











* References :ignore:
#+PRINT_BIBLIOGRAPHY:
#  LocalWords:  Discretization
# Local Variables:
# mode: org
# org-export-allow-bind-keywords: t
# End:
