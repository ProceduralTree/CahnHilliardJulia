#+title: A Multi-grid method
#+subtitle: on the Cahn-Hilliard equation  and its relaxed variation.
#+BIBLIOGRAPHY: ~/org/resources/bibliography/refs.bib
#+options: toc:nil
#+BIND: org-latex-title-command ""
#+BIND: org-latex-default-figure-position "H"
#+latex_class: mimosis
  #+latex_header: \include{~/.doom.d/OrgConfig/noteHeader.tex}
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="https://gongzhitaao.org/orgcss/org.css"/>
#+PROPERTY: header-args:julia :output-dir images :eval never :noweb no-export
#+PROPERTY: header-args:julia-vterm :output-dir images :exports results :noweb no-export :eval yes :session jl :cache yes
# #+INFOJS_OPT: view:info toc:nil
#+latex_header: \renewcommand{\floatpagefraction}{.9}%
#+latex_header: \usepackage[level]{datetime}
* Title-page :ignore:
#+begin_export latex
\frontmatter
\makeatletter
\begin{titlepage}
    \centering
\includegraphics[width=1\textwidth]{logo/logo.png}
\par
	\vspace{1.5cm}
	{\scshape\huge Bachelor's Thesis \par}
	\vspace{1.5cm}
	{\Huge\bfseries  \@title \par}
	\vspace{2cm}
	{\LARGE \@author \par}
	{\Large Matriculation Number: 3545737 \par}
	\vspace{1.5cm}
	{\large Examiner: Prof Rohde I believe \par}
	{\large Advisor: Hasel \par}
	\vspace{1.5cm}
	{\large Institute of Applied Analysis and Numerical Simulation\par}



	\vfill

% Bottom of the page
	{\large Completed 01.01.2022 \par}
\end{titlepage}
\makeatother

#+end_export



#+begin_abstract
This Thesis gives a short overview and derivation for the Cahn-Hilliard Equation. It uses a discretization by the authors [cite:@SHIN20117441] as baseline, and expands upon this dicretisation with an elliptical relaxation approach. It introduces evaluation metrics regarding stability in time, space and during sub-iteration. And compares the elliptical approach against the baseline. Furthermore, it shows a qualitative success of the elliptical solver, however it also highlights challenges in numerical stability.
#+end_abstract
#+TOC: headlines 3
#+begin_export latex
\mainmatter
#+end_export
* Introduction
The Cahn-Hilliard (CH) equation is a well known fourth order PDE used in multi-phase flow. It is used to couple different phases with a diffuse-interface, as compared to a sharp interface, approach. Therefore, it has a smooth transition between phases.
The CH equation serves the same purpose, as the second order Allen-Cahn equation. However, the Allen-Cahn equation is not mass conservative. Hence, the Cahn-Hilliard equation is used if mass conservation  is required.
In this thesis we implement numerical solvers for the Cahn-Hilliard equation in the Julia programming language.
We begin by giving an overview and a derivation for the analytical CH equation in Chapter [[The Cahn-Hilliard equation]]. We then show mass conservation and a decrease of total energy in time.
The Chapter [[Multigrid method]] introduces our discretization and a finite difference based two grid method. We explain the necessary functions, describe the relevant steps of our numerical implementation, and give their implementation. Additionally we introduce the initial conditions we used in this thesis.
In Chapter [[Numerical experiments]] we evaluate this method's stability,discrete mass conservation and discrete energy decrease that we have shown continuously for the analytical CH equation.
Our thesis introduces a analytical relaxation approach to the classical CH equation, where instead of solving a fourth order PDE [fn:1], we solver a second order relaxed PDE and an additional elliptical PDE. In the chapter [[Relaxed problem]] we introduce this approach, and then derive a numerical solver using the method described in chapter [[Multi-grid method]]. Hereupon we derive and implement the necessary functions for the discretized relaxed equation, and  we introduce a simple solver for the elliptical PDE.
Subsequently, in chapter [[Relaxed experiments]], we evaluate our relaxed method against the baseline with the same measures, as introduced in chapter [[Numerical experiments]].

We began writing this thesis with a reproducible research philosophy in mind. Hence, we provide the explanation you  are reading, and the implementation in the same file. The original aim was to have the mathematical formulas and their implementation interleaved in a way, that leaves no room for interpretation. While we fall short of this goal, we still provide all relevant code in the relevant sections and the appendix. All shown code is therefore the code that is run on our machine. Since not all parts of the code are relevant for understanding, unimportant sections are implemented elsewhere. Didacticly they aer replaced with a comment of form =<<unumportant-code-section>>=. Their implementation can be found in ~Thesis_jl.org~ in a code block of the same name.
We did experiment with additional tools such as [[https:orgmode.org][org-mode]] that allow for scientific note-taking and literate programming.
This file is available on our github repository at [[https://github.com/ProceduralTree/CahnHilliardJulia.git]]
as ~Thesis_jl.org~.
* The Cahn-Hilliard equation
The Cahn-Hilliard(CH) equation is a partial differential equation (PDE) that governs the dynamics of a two-phase fluid [cite:@Wu_2022]. The form of the CH equation used in this thesis in the domain \( \Omega \times (0, T) \,, \Omega \subset \mathbb{R}^d \,, d \in \mathbb{N}  \,, T>0 \),
#+name: eq:CH
\begin{equation}
\begin{aligned}
\partial_{t}\phi(x,t) &=  \nabla \cdot(M(\phi)\nabla\mu), \\
\mu &= - \varepsilon^2 \Delta\phi  + W'(\phi),
\end{aligned}
\end{equation}
where the variables \( \phi , \mu : \Omega \times (0,T) \to \mathbb{R}^d \) are phase-field variable and chemical potential,
\(\varepsilon\) is a positive constant correlated with interface thickness, \( W(\phi) \) is a double well potential and \(M(\phi) > 0\) is a mobility coefficient [cite:@Wu_2022].
 \( \phi\) is defined in an interval \(I=[-1,1] \) and  represent the different phases.
\begin{align*}
\phi &=
\begin{cases}
1 &\,, \phi \in \text{phase 1} \\
-1 &\,, \phi \in\text{phase 2}
\end{cases}
\end{align*}

 In this thesis we assume \(M(\phi) \equiv 1 \), simplifying the CH equation.

The advantages of the CH approach, as compared to traditional boundary coupling, are for example: "explicit tracking of the interface" [cite:@Wu_2022], as well as "evolution of complex geometries and topological changes [...] in a natural way" [cite:@Wu_2022].
In practice, it enables linear interpolation between different formulas on different phases.
** Physical derivation of the CH equation [[eqref:eq:CH]]
*** The free energy
The authors in [cite:@Wu_2022] define the CH equation using the *Ginzburg-Landau* free energy equation:
#+name: eq:energy
\begin{align}
E^{\text{bulk}}[\phi] &= \int_{\Omega} \frac{\varepsilon^2}{2} |\nabla \phi |^2 + W(\phi) \, dx ,
\end{align}
where \(W(\phi) \) denotes the Helmholtz free energy density of mixing [cite:@Wu_2022] that we approximate it in further calculations with \(W(\phi) = \frac{(1-\phi ^2)^2}{4}\) as in [cite:@SHIN20117441] shown in Fig. [[fig:double-well]].
#+name: fig:double-well
#+begin_src julia-vterm :results file graphics :file double-well.svg
using Plots
using LaTeXStrings
W(x) = 1/4 * (1- x^ 2)^2
p = plot(W , xlims=(-2,2) , label=:none)
savefig(p, "images/double-well.svg")
#+end_src

#+caption: Double well potential \( W(\phi) \)
#+RESULTS[990bafb41c1855db23a8eb8b6bc4129e91d73342]: fig:double-well
[[file:images/double-well.svg]]




The chemical potential, \( \mu \), then follows as the variational derivation of the free energy in Eq.[[eqref:eq:energy]].
#+name: eq:chemical-potential
\begin{align}
 \mu &= \frac{\delta E_{bulk}(\phi)}{\delta \phi} = -\varepsilon^2 \Delta \phi + W'(\phi)
\end{align}

*** Derivation of the CH equation from mass balance
The paper [cite:@Wu_2022] states that the observable phase separation is driven by a diffusion resulting from the gradient in chemical potential \( \mu \). The emergent conservative dynamics motivate the following diffusion equation
#+name: eq:massbal
\begin{equation}
    \partial_t \phi + \nabla \cdot \mathbf{J} = 0,
\end{equation}
where \( \mathbf{J} = -\nabla \mu \) represents mass-flux.
We follow the authors [cite:@Wu_2022] in deriving the CH equation by combining Eq.eqref:eq:chemical-potential and Eq.[[eqref:eq:massbal]].
\begin{equation}
\begin{aligned}
\implies \partial_t \phi   &=- \nabla \cdot \mathbf{J} = \Delta\mu , \\
\mu &=  -\varepsilon^2 \Delta \phi + W'(\phi) \,,
\end{aligned}
\end{equation}
Furthermore the CH equation is mass conservative under homogeneous Neumann boundary conditions, defined as:
#+name: eq:boundary-conditions
\begin{equation}
\begin{aligned}
\mathbf{J} \cdot \mathbf{n} &= 0 & \text{on} \, \partial\Omega &\times (0,T),\\
\partial_n\phi &= 0 & \text{on} \, \partial\Omega &\times (0,T),
\end{aligned}
\end{equation}
where \( \mathbf{n}  \) is the outward normal on \( \partial \Omega \).
To show the conservation of mass we analyze the change in total mass in the domain \( \Omega \) over time.
#+name: eq:mass-conservation
\begin{equation}
\begin{aligned}
\frac{d}{dt}\int_{\Omega}\phi \ d \mathbf{x} &=\int_{\Omega}\frac{\partial \phi}{\partial t} \ d\mathbf{x} \\
&= - \int_{\Omega} \nabla \cdot \mathbf{J} \ d\mathbf{x}\\
&=  \int_{\partial\Omega}  \mathbf{J} \cdot \mathbf{n}  \ d\mathbf{s} \\
&= 0 & \forall t\in(0,T)\,,
\end{aligned}
\end{equation}

In order to show thermodynamic consistency of the CH equation, we take the time derivation of the free energy functional Eq.[[eqref:eq:energy]].
\begin{align*}
\frac{d}{dt}E^{bulk}[\phi(t)] &= \int_{\Omega} ( \varepsilon^2 \nabla \phi \cdot \nabla \partial_t \phi + W'(\phi) \partial_t \phi) \ d \mathbf{x} \\
&=\int_{\Omega} (\varepsilon^2\nabla\phi + W'(\phi))\partial_t\phi \ d\mathbf{x}\\
&=\int_{\Omega} \mu \partial_t \phi \ d\mathbf{x}\\
&= \int_{\Omega} \mu \cdot \Delta\mu \ d\mathbf{x} \\
&= -\int_{\Omega} \nabla\mu \cdot \nabla\mu \ dx + \int_{\partial\Omega} \mu \nabla\phi_t \cdot \mathbf{n} \ dS \\
&\stackrel{\partial_n\phi = 0}{=} - \int_{ \Omega } |\nabla \mu|^2 \ d \mathbf{x}, & \forall t \in (0,T)
\end{align*}

* Discretization into a LES
** The discretization of functions and derrivative operators
As baseline for numerical experiments we use a two-grid method based on the finite difference method defined in [cite:@SHIN20117441].
Our discretization follows the one taken by the authors in [cite:@SHIN20117441].
We discretize our domain \( \Omega \) to be a Cartesian-grid \( \Omega_d \) on a square with side-length \( N\cdot h \), where N is the number of grid-points in one direction, and \( h \) is the distance between grid-points. In all our initial data \( h \) is \( 3\cdot10^{-3}\) and \( N=64 \). However, for stability tests we change \( h \) and \( N \).
\begin{equation}
\Omega_d = \left\{ i,j \mid i,j \in \mathbb{N} \,, i,j \in [2,N+1] \right\}
\end{equation}
where \( \Omega_{d} \) is the discrete version or our domain as shown in [[fig:discrete-domain]].
#+name: fig:discrete-domain
#+begin_src julia-vterm :results file graphics :file domain.svg
using Plots
using LaTeXStrings
pgfplotsx()
Idx = CartesianIndex(1,1)
M = zeros(66,66)
M[2:end-1 , 2:end-1] = ones(64,64)
p= heatmap(M, title=L"\Omega_d" , clim=(-1,1),
            gridlinewidth=2 , axis_equal_image=true , extra_kwargs=:subplot , xlims=(1 ,66) , ylims=(1,66))

savefig(p,"images/domain.svg")
#+end_src

#+caption: Discrete Domain used for most of the experiments in this Thesis
#+RESULTS[46038739234db0a64b145e68000e9b1ea9d30425]: fig:discrete-domain
[[file:images/domain.svg]]


We discretize the phase-field ,\( \phi \), and chemical potential ,\( \mu \), into grid-wise functions \(\phi_{ij}, \mu_{ij} \)
\begin{equation}
\begin{aligned}
\phi_{ij}^n: \Omega_d \times \left\{ 0, \dots  \right\} &\to \mathbb{R}\\
\mu_{ij}^n: \Omega_d \times \left\{ 0, \dots \right\} &\to \mathbb{R}
\end{aligned}
\end{equation}
Here \( n \) denotes the nth time-step, and \( (i,j) \) are Cartesian indices on the discrete domain \( \Omega_d \).
The authors in [cite:@SHIN20117441] then use the characteristic function \( G \) of the  domain \( \Omega \) to enforce no-flux boundary conditions [[eqref:eq:boundary-conditions]].

\begin{align*}
G(x,y) &=
\begin{cases}
1, & (x,y) \in  \Omega \\
0, & (x,y) \not\in  \Omega
\end{cases}
\end{align*}
We implement the discrete version of \( G \) on \( \Omega_d \) as follows:
\begin{align*}
G_{ij} &=
\begin{cases}
1, & i,j \in [2,N+1]  \\
0, & \text{else}
\end{cases}
\end{align*}
The definition of \( G_{ij} \) with \( i,j \in [2,N+1] \) enables us to evaluate \( G_{ij} \) of-grid.
#+begin_src julia :tangle src/utils.jl :eval never :exports none
"""
Boundry indicator function

Returns
---------------
1 if index i,j is in bounds(without padding) and 0 else
"""
#+end_src
#+begin_src julia :tangle src/utils.jl :eval never
function G(i, j, len, width)
    if 2 <= i <= len + 1 && 2 <= j <= width + 1
        return 1.0
    else
        return 0.0
    end
end
#+end_src

We then define the discrete derivatives \( D_x\phi_{ij}, \ D_y\phi_{ij} \) using centered differences:
\begin{align}
D_x\phi^{n+1,m}_{i+\frac{1}{2} j} &= \frac{\phi^{n+1,m}_{i+1j} - \phi^{n+1,m}_{ij}}{h} & D_y\phi^{n+1,m}_{ij+\frac{1}{2}} &= \frac{\phi^{n+1,m}_{ij+1} - \phi^{n+1,m}_{ij}}{h}
\end{align}
We define \( D_x\mu_{ij}^{n+\frac{1}{2},m} , D_y\mu_{ij}^{n+\frac{1}{2},m} \) in the same way.
Next we define the discrete gradient \( \nabla_d \phi^{n+1,m}_{ij}\), as well as a modified Laplacian \( \nabla_d \cdot (G_{ij} \nabla_d \phi^{n+1,m}_{ij} )\):



#+name: eq:discretization
\begin{equation}
\begin{aligned}
\nabla_d \phi^{n+1,m}_{ij} &= \left(D_x \phi^{n+1,m}_{i+1j} , \ D_y \phi^{n+1,m}_{ij+1}\right) \,,\\
 \nabla_d \cdot (G_{ij} \nabla_d \phi^{n+1,m}_{ij}) &= \frac{G_{i+\frac{1}{2}j}D_x \phi^{n+1,m}_{i+\frac{1}{2}j} -  G_{i-\frac{1}{2}}D_x \phi^{n+1,m}_{i-\frac{1}{2}j} + D_y \phi^{n+1,m}_{ij+\frac{1}{2}} - D_y \phi^{n+1,m}_{ij-\frac{1}{2}}}{h} \\
  &= \frac{ G_{i+\frac{1}{2}j} \phi^{n + 1,m}_{i+1j} +  G_{i-\frac{1}{2}j} \phi^{n +,m}_{i-1j} + G_{ij+\frac{1}{2}}  \phi^{n +,m}_{ij+1} + G_{ij-\frac{1}{2}} \phi^{n +,m}_{ij-1}    }{h^2}\\
& \, - \frac{\left(   G_{i+\frac{1}{2}j} + G_{i-\frac{1}{2}j} + G_{ij+\frac{1}{2}} + G_{ij-\frac{1}{2}}  \cdot \phi_{ij} \right)}{h^2} \,,
\end{aligned}
\end{equation}
The discretization for \(  \nabla_d\mu_{ij}^{n+\frac{1}{2},m} ,  \nabla_d \cdot (G_{ij} \nabla_d \mu^{n+\frac{1}{2},m}_{ij}) \) are done the same as for \( \phi_{ij}^{n+1} \)
 We define \(   \nabla_d \cdot (G_{ij} \nabla_d \phi_{ij} )\) instead of a discrete Laplacian \( \Delta_d \) to ensure a discrete version of boundary conditions [[eqref:eq:boundary-conditions]].
 The authors in [cite:@SHIN20117441] show this to be the case by expanding \( \nabla_d \cdot (G_{ij} \nabla_d\phi_{ij}) \).
Notably, when one point lies outside the domain, e.g. \( G_{i + \frac{1}{2}} = 0 \)  then the corresponding discrete gradient \( \frac{\phi_{i+1}^{n+1} - \phi_i}{h}  \) is weighted by 0. This corresponds the discrete version of \( \partial_n\phi = 0 \).
The authors in [cite:@SHIN20117441]

To simplify the notation for discretized derivatives we use the following abbreviations:
- \(  \Sigma_G \phi_{ij} = G_{i+\frac{1}{2}j} \phi^{n + 1,m}_{i+1j} +  G_{i-\frac{1}{2}j} \phi^{n +1,m}_{i-1j} + G_{ij+\frac{1}{2}}  \phi^{n +1,m}_{ij+1} + G_{ij-\frac{1}{2}} \phi^{n +1,m}_{ij-1}  \)
- \(  \Sigma_{Gij} = G_{i+\frac{1}{2}j} + G_{i-\frac{1}{2}j} + G_{ij+\frac{1}{2}} + G_{ij-\frac{1}{2}}  \)
Code:
#+begin_src julia :tangle src/utils.jl :eval never
function neighbours_in_domain(i, j, G, len, width)
    (
        G(i + 0.5, j, len, width)
        + G(i - 0.5, j, len, width)
        + G(i, j + 0.5, len, width)
        + G(i, j - 0.5, len, width)
    )

end
function discrete_G_weigted_neigbour_sum(i, j, arr, G, len, width)
    (
        G(i + 0.5, j, len, width) * arr[i+1, j]
        + G(i - 0.5, j, len, width) * arr[i-1, j]
        + G(i, j + 0.5, len, width) * arr[i, j+1]
        + G(i, j - 0.5, len, width) * arr[i, j-1]
    )
end
#+end_src

We can then write the modified Laplacian \( \nabla_d (G \nabla_d\phi_{ij}^{n+1}) \) as:
\begin{align*}
\nabla_{d} \cdot(G \nabla_d\phi_{ij}^{n+1}) &= \frac{\Sigma_G\phi_{ij}^{n+1} - \Sigma_{Gij}\cdot \phi_{ij}^{n+1}}{h^2}
\end{align*}
We use this modified Laplacian to deal with boundary conditions. Our abbreviations simplify separating implicit and explicit terms in the discretization.
** Initial data
For testing we use initial phase-fields defined by the following equations:

\begin{equation}
\begin{aligned}
\phi_{ij} &=
\begin{cases}
1 &\,, \|(i,j) - (\frac{N}{2} , \frac{N}{2})\|_p < \frac{N}{3}\\
-1 &\,,else
\end{cases}
&
\text{where    }  p \in \{2,\infty\}
\\
\phi_{ij} &=
\begin{cases}
1 &\,,  i < \frac{N}{2} \\
-1 &\,,else
\end{cases}
\\
\phi_{ij} &=
\begin{cases}
1 &\,, \|(i,j) - (\frac{N}{2} , 2)\|_2 < \frac{N}{3} \\
-1 &\,,else
\end{cases}
\\
\phi_{ij} &=
\begin{cases}
1 &\,, \| (i,j) - q_k \|_p < \frac{N}{5}  \\
-1 &\,,else
\end{cases}
& p \in \{1,2, \infty\} , q_k \in Q
\end{aligned}
\end{equation}
where \( q_k \) are random points inside my domain. Those we generate those using the following RNG setup in Julia
#+begin_src julia-vterm :session jl :results table :exports both
using Random
rng = MersenneTwister(42)
gridsize = 64
radius = gridsize /5
blobs = gridsize ÷ 5
rngpoints = rand(rng,1:gridsize, 2, blobs)
#+end_src

#+RESULTS[3552e4337f2c07fbcf995633085c942ca4f20731]:
| Executing... 384b64d3 |

#+name: fig:testinput
#+begin_src julia-vterm :results file graphics  :file testdata.svg
<<init>>
<<setup-diverse-testgrids>>
plots =[  heatmap(t[1].phase ,  legend=:none , aspectratio=:equal , grid=false , showaxis=false , size=(600,600))
for t in tests[1:2:end]]
#plots = [heatmap(t[1].phase , size=(600,600), axis=:none , aspect_ratio=:equal) for t in tests]
p = plot(plots... , layout=(1,4) , size=(2400,600))

savefig(p,"images/testdata.svg")
#+end_src

#+caption: Examples of different phase-fields used as the initial condition in this work.
#+RESULTS[65140252e24fc779f0c2def8eb2fbefa4748bece]: fig:testinput
[[file:images/testdata.svg]]

** Numerical ansatz
The authors in [cite:@SHIN20117441] then define the discrete CH equation adapted for the domain as:
#+name: eq:discrete-cahn-hilliard
\begin{equation}
\begin{aligned}
\frac{\phi_{ij}^{n+1} - \phi_{ij}^n}{\Delta t}  &=  \nabla _d \cdot (G_{ij} \nabla_d \mu_{ij}^{n+\frac{1}{2}} )  \,, \\
 \mu_{ij}^{n+\frac{1}{2}} &= 2\phi_{ij}^{n+1} - \varepsilon^2  \nabla_d \cdot  (G_{ij} \nabla _d \phi_{ij}^{n+1} ) + W'(\phi_{ij}^n) - 2\phi _{ij}^n \,,
\end{aligned}
\end{equation}
and derive a numerical scheme from this implicit equation.
** The discrete system
The authors in [cite:@SHIN20117441] derive their method by separating [[eqref:eq:discrete-cahn-hilliard]] into implicit and linear terms, and explicit non-linear terms. We write the implicit terms in form of a function \( L: \RR^2 \to \RR^2  \) and the explicit terms in \( (\zeta^n_{ij} , \psi^n_{ij})^T \). We define \( L \) as:
\begin{align*}
L
\begin{pmatrix}
\phi^{n+1}_{ij} \\
\mu^{n+\frac{1}{2}}_{ij}
\end{pmatrix}
&=
\begin{pmatrix}
\frac{\phi^{n+1}_{ij}}{\Delta t} - \nabla _d \cdot  ( G_{ij} \nabla _d \mu^{n+\frac{1}{2}}_{ij} ) \\
\varepsilon^2 \nabla _d \cdot  (G \nabla_d \phi_{ij}^{n+1}) - 2\phi_{ij}^{n+1} + \mu_{ij}^{n+\frac{1}{2}}
\end{pmatrix}
.
\end{align*}
#+begin_src julia :tangle src/multisolver.jl :eval never
function L(solver::multi_solver,i,j , phi , mu)
    xi = solver.phase[i, j] / solver.dt -
         (discrete_G_weigted_neigbour_sum(i, j, solver.potential, G, solver.len, solver.width)
          -
          neighbours_in_domain(i, j, G, solver.len, solver.width) * mu )/solver.h^2
    psi = solver.epsilon^2/solver.h^2 *
          (discrete_G_weigted_neigbour_sum(i, j, solver.phase, G, solver.len, solver.width)
           -
           neighbours_in_domain(i, j, G, solver.len, solver.width) * phi) - 2 * phi + mu
    return [xi, psi]
end
#+end_src
This function follows from [[eqref:eq:discrete-cahn-hilliard]] and is linear in the unknowns \( \left(\phi^{n+1}_{ij} , \mu^{n+\frac{1}{2}}_{ij} \right) \). The non-linear terms of eqref:eq:discrete-cahn-hilliard are collected in \( \left(\zeta^n_{ij}, \psi^n_{ij} \right) \). Which we define as
\begin{align*}
\begin{pmatrix}
\zeta^n_{ij}
 \\
\psi^n_{ij}
\end{pmatrix}
&=
\begin{pmatrix}
\frac{\phi_{ij}^{n}}{\Delta t}\\
W'(\phi_{ij}^n) - 2\phi_{ij}^n
\end{pmatrix}
.
\end{align*}
#+begin_src julia :tangle src/utils.jl :eval never
function set_xi_and_psi!(solver::T) where T <: Union{multi_solver , relaxed_multi_solver}
    xi_init(x) = x / solver.dt
    psi_init(x) = solver.W_prime(x) - 2 * x
    solver.xi[2:end-1, 2:end-1] = xi_init.(solver.phase[2:end-1,2:end-1])
    solver.psi[2:end-1, 2:end-1] = psi_init.(solver.phase[2:end-1,2:end-1])
    return nothing
end
#+end_src
The authors [cite:@SHIN20117441] defined a numerical method where all non linear terms are evaluated explicitly. Therefore , we know everything needed to calculate \( (\zeta^n_{ij} , \psi^n_{ij})^T \) at the beginning of each time step. We compute those values once and store them in the solver.
Using \(  \left(\zeta^n_{ij}, \psi^n_{ij} \right)  \) and  \(   L\left(\phi^{n+1}_{ij} , \mu^{n+\frac{1}{2}}_{ij} \right) \) , we can rewrite eqref:eq:discrete-cahn-hilliard as
#+name: eq:LES
\begin{equation}
L
\begin{pmatrix}
\phi^{n+1}_{ij} \\
\mu^{n+\frac{1}{2}}_{ij}
\end{pmatrix}
=
\begin{pmatrix}
\zeta^n_{ij} \\
\psi^n_{ij}
\end{pmatrix}
.
\end{equation}

This Linear system consists of NxN, 2 dimensional linear equations. I.e. a LES with NxNx2 equations
Furthermore, as it is needed later on, we derive its Jacobian with respect to the current grid point \( (\phi^{n+1}_{ij} , \mu^{n+\frac{1}{2}}_{ij})^{T} \):

\begin{align*}
DL\begin{pmatrix}
\phi_{ij} \\
\mu_{ij}
\end{pmatrix} &= \begin{pmatrix}
\frac{1}{\Delta t} & \frac{1}{h^2}\Sigma_{Gij}  \\
-\frac{\varepsilon^2}{h^2}\Sigma_{Gij} - 2 & 1
\end{pmatrix}
= \mathbf{DL}
\end{align*}
#+begin_src julia :tangle src/multisolver.jl :eval never
function dL(solver::multi_solver , i , j)
    return [ (1/solver.dt) (1/solver.h^2*neighbours_in_domain(i,j,G,solver.len , solver.width));
             (-1*solver.epsilon^2/solver.h^2 * neighbours_in_domain(i,j,G,solver.len , solver.width) - 2) 1]
    end
#+end_src
Since \( L \) is linear, \( DL \) is constant. Using The abbreviation for \( \nabla_d(G_{ij}\nabla_d \mu_{ij}^{n+\frac{1}{2}}) \) introduced in [[The discretization of functions and derrivative operators]], we rewrite eqref:eq:LES in terms of \( DL \)
 #+name: eq:explicit-smooth
 \begin{equation}
\begin{aligned}
\begin{pmatrix}
  \zeta_{ij}^n\\
\psi_{ij}^n
\end{pmatrix}
&=
DL\begin{pmatrix}
\phi_{ij}^{n+1} \\
\mu_{ij}^{n+\frac{1}{2}}
\end{pmatrix}
\cdot
\begin{pmatrix}
\phi^{n+1}_{ij} \\
\mu^{n+\frac{1}{2}}_{ij}
\end{pmatrix}
+
\begin{pmatrix}
 - \frac{1}{h^2} \Sigma_{Gij}\mu_{ij}^{n+\frac{1}{2}} \\
+ \frac{\varepsilon^2}{h^2} \Sigma_{Gij}\phi_{ij}^{n+1} \\
\end{pmatrix}
,\\
\begin{pmatrix}
  \zeta_{ij}^n\\
\psi_{ij}^n
\end{pmatrix}
-
\begin{pmatrix}
 - \frac{1}{h^2} \Sigma_{Gij}\mu_{ij}^{n+\frac{1}{2}} \\
+ \frac{\varepsilon^2}{h^2} \Sigma_{Gij}\phi_{ij}^{n+1} \\
\end{pmatrix}
&=
DL\begin{pmatrix}
\phi_{ij}^{n+1} \\
\mu_{ij}^{n+\frac{1}{2}}
\end{pmatrix}
\cdot
\begin{pmatrix}
\phi^{n+1}_{ij} \\
\mu^{n+\frac{1}{2}}_{ij}
\end{pmatrix}
\,,
\end{aligned}
\end{equation}
where
- \(  \Sigma_G \phi_{ij}^{n+1} = G_{i+\frac{1}{2}j} \phi^{n + 1,m}_{i+1j} +  G_{i-\frac{1}{2}j} \phi^{n + 1,m}_{i-1j} + G_{ij+\frac{1}{2}}  \phi^{n + 1,m}_{ij+1} + G_{ij-\frac{1}{2}} \phi^{n + 1,m}_{ij-1}  \),
- \(  \Sigma_G \mu_{ij} = G_{i+\frac{1}{2}j} \mu^{n + \frac{1}{2},m}_{i+1j} +  G_{i-\frac{1}{2}j} \mu^{n + \frac{1}{2},m}_{i-1j} + G_{ij+\frac{1}{2}}  \mu^{n + \frac{1}{2},m}_{ij+1} + G_{ij-\frac{1}{2}} \mu^{n + \frac{1}{2},m}_{ij-1}  \),

* Multi-grid Method
The multigrid method consists of a linear Gauss-Seidel solver, restriction and prolongation methods, to move between different grid sizes.
** Gauss-Seidel  smoothing
The authors [cite:@SHIN20117441]derived Gauss-Seidel Smoothing from eqref:eq:LES :
 Smoothing denoted as a SMOOTH operator consists of a Gauss-Seidel method, by solving Eq.[[eqref:eq:smooth]] for all \( i,j \) with the initial guess for \( \zeta^n_{ij} , \psi^n_{ij} \).
In order to compute \( \left(   \phi_{ij}^{n+1} , \mu^{n+\frac{1}{2}}_{ij}  \right) \) we have to evaluate those grid-wise functions on at neighboring indices \( k,l \) e.g. \( k=i+1 , l=j-1 \).
Since values for \( \phi_{kl}^{n+1,m} , \mu_{kl}^{n+\frac{1}{2},m} \) are unknown, if \( k > i , l > j \), the authors in [cite:@SHIN20117441] and we use initial approximations, and the values of the current smooth iteration else. As initial approximation we use the values of \(  \phi_{kl}^{n+1,m} , \mu_{kl}^{n+\frac{1}{2},m}  \) from the last smoothing iteration.
We define an iterative Gaus Seidel method.
\begin{equation}
\begin{pmatrix}
  \zeta_{ij}^n\\
\psi_{ij}^n
\end{pmatrix}
-
\begin{pmatrix}
 - \frac{1}{h^2} \Sigma_{Gij}\mu_{ij}^{n+\frac{1}{2} , s + \frac{1}{2}} \\
+ \frac{\varepsilon^2}{h^2} \Sigma_{Gij}\phi_{ij}^{n+1 , s+\frac{1}{2}} \\
\end{pmatrix}
=
\mathbf{DL} \cdot
\begin{pmatrix}
\phi^{n+1 , s+1}_{ij} \\
\mu^{n+\frac{1}{2} , s+1}_{ij}
\end{pmatrix}
\,,
\end{equation}
where
- \(  \Sigma_G \phi_{ij}^{n+1  , s+\frac{1}{2}} = G_{i+\frac{1}{2}j} \phi^{n + 1,s}_{i+1j} +  G_{i-\frac{1}{2}j} \phi^{n + 1,s+1}_{i-1j} + G_{ij+\frac{1}{2}}  \phi^{n + 1,s}_{ij+1} + G_{ij-\frac{1}{2}} \phi^{n + 1,s+1}_{ij-1}  \),
- \(  \Sigma_G \mu_{ij}^{n+\frac{1}{2},s+\frac{1}{2}} = G_{i+\frac{1}{2}j} \mu^{n + \frac{1}{2},s}_{i+1j} +  G_{i-\frac{1}{2}j} \mu^{n + \frac{1}{2},s+1}_{i-1j} + G_{ij+\frac{1}{2}}  \mu^{n + \frac{1}{2},s}_{ij+1} + G_{ij-\frac{1}{2}} \mu^{n + \frac{1}{2},s+1}_{ij-1}  \),
This constitutes a Gaus-Seidel method in its element based formula.
#+name: calculate-left-hand-side
#+begin_src julia :eval never :exports none
bordernumber = neighbours_in_domain(i, j, G, solver.len, solver.width)

b = [(
            solver.xi[i, j]
            +
            discrete_G_weigted_neigbour_sum(
                i, j, solver.potential, G, solver.len, solver.width
            ) / solver.h^2
        ), (
            solver.psi[i, j]
            -
            (solver.epsilon^2 / solver.h^2) * discrete_G_weigted_neigbour_sum(
                i, j, solver.phase, G, solver.len, solver.width
            ))]


#+end_src
#+name:SMOOTH
#+begin_src julia :tangle src/multisolver.jl :eval never :noweb no-export
function SMOOTH!(
    solver::T,
    iterations,
    adaptive
) where T <: Union{multi_solver, adapted_multi_solver , gradient_boundary_solver}
    for s = 1:iterations
        # old_phase = copy(solver.phase)
        for I in CartesianIndices(solver.phase)[2:end-1, 2:end-1]
            i, j = I.I

            <<calculate-left-hand-side>>

            res = dL(solver, i,j ) \ b
            solver.phase[i, j] = res[1]
            solver.potential[i, j] = res[2]
        end
    end
end
#+end_src
We denote the approximations for \( \left( \phi_{ij}^{n+1} , \mu^{n+\frac{1}{2}}_{ij}  \right)  \) after smoothing, as  \( \left( \bar{\phi}_{ij}^{n+1} , \bar{\mu}^{n+\frac{1}{2}}_{ij}  \right)  \).
In Fig.[[fig:smoothing-examples]] we show 4 of the 7 initial data after one 200 iterations of smoothing. It is apparent that the sharp interface from the initial Data has diffused.
#+name: fig:smoothing-examples
#+begin_src julia-vterm :results file graphics  :file smooth.svg
<<input>>
<<setup-diverse-testgrids>>
plots= []
for t in tests
set_xi_and_psi!(t[1])
SMOOTH!(t[1], 200, true);
end
plots =[  heatmap(t[1].phase ,  legend=:none , aspectratio=:equal , grid=false , showaxis=false , size=(600,600))
          for t in tests[1:2:end]]
p = plot(plots... , layout=(1,4) , size=(2400,600))
savefig(p,"images/smooth.svg")

#+end_src

#+caption: Inputs from [[Initial data]] after SMOOTH.
#+RESULTS[fdb9207550b6615253fa672f5417f153b861be3b]: fig:smoothing-examples
[[file:images/smooth.svg]]

** Multi-grid method
The numerical method proposed in [cite:@SHIN20117441] consists of repeated sub-iterations of a multi-grid V-cycle.  Specifically we use a two-grid implementation with a fixed number of sub-iterations. Defined as:
#+begin_src julia :eval never :exports code
for j in 1:timesteps

    set_xi_and_psi!(solvers[1])

    for i = 1:subiterations

        v_cycle!(solvers, 1)
    end
end
#+end_src
where the V-cycle consists of the following steps
1. a Gauss-Seidel relaxation for smoothing on the fine grid \( h \), as described in Chapter [[Gauss-Seidel smoothing]].
2. calculate the residual error  \( \left(d_{ij,H}^{n+1,m} , r_{ij,H}^{n+1,m} \right) =: L\left( \phi_{ij}^{n+1} , \mu^{n+\frac{1}{2}}_{ij}  \right) - (\zeta^n_{ij} , \psi^n_{ij}  )  \). for the course grid \( H \) correction.
3. restriction from the fine grid to the course grid \(  h \to H  \).
4. a Gauss-Seidel SMOOTH to solve \( L(\hat{\phi}_{ij,H}^{n+1,m}, \hat{\mu}_{ij,H}^{n+\frac{1}{2},m})_H = L(\bar{\phi}_{ij,H}^{n+1,m} , \bar{\mu}_{ij,H}^{n+\frac{1}{2},m}) + (d_{ij,H}^{n+1,m} , r_{ij,H}^{n+1,m}) \).
    We solve for \( \left( \hat{\phi}_{ij,H}^{n+1,m}, \hat{\mu}_{ij,H}^{n+\frac{1}{2},m} \right) \) using the same iteration as in Chapter [[Gauss-Seidel smoothing]] however we replace \( (\zeta_{ij}^{n} , \psi_{ij}^n) \) with  \(  L(\bar{\phi}_{ij,H}^{n+1,m} , \bar{\mu}_{ij,H}^{n+\frac{1}{2},m}) + (d_{ij,H}^{n+1,m} , r_{ij,H}^{n+1,m}) \).  In the iteration, where \( \bar{\phi}_{ij,H}^{n+1,m} , \bar{\mu}_{ij,H}^{n+\frac{1}{2},m} \) are the values after the smooth restricted to the coarser grid and \( d_{ij,H}^{n+1,m} , r_{ij,H}^{n+1,m} \) is the residual from the smooth  iteration on the fine grid restricted onto the coarse grid.
5. prolongation from the course grid to the fine grid \( H\to h \)
6. post smoothing on the fine grid
We Do Gauss-Seidel smoothing with fixed iterations.
#+name: restrict-to-coarse-grid
#+begin_src julia :eval never :exports none

    restrict_solver!(grid[level], grid[level+1])
    coursegrid_solver = grid[level+1]
    solution = deepcopy(coursegrid_solver)

    d_large = restrict(d, G)
    r_large = restrict(r, G)


    u_large = zeros(size(d_large))
    v_large = zeros(size(d_large))
#+end_src
#+name: prolong-to-fine-grid
#+begin_src julia :eval never :exports none
u_large = solver.phase .- solution.phase
v_large = solver.potential .- solution.potential

solver = grid[level]

solver.phase .+= prolong(u_large , G)
solver.potential .+= prolong(v_large, G)

#+end_src
The V-cycle of a two-grid method using pre- and post-smoothing is then stated by:
#+begin_src julia :eval never :tangle src/mulisolver.jl
function alt_v_cycle!(grid::Array{T}, level) where T <: solver
    finegrid_solver = grid[level]
    #pre SMOOTHing
    SMOOTH!(solver, 40, false)

    d = zeros(size(finegrid_solver.phase))
    r = zeros(size(finegrid_solver.phase))

    # calculate error between L and expected values
    for I in CartesianIndices(finegrid_solver.phase)[2:end-1, 2:end-1]
        d[I], r[I] = [finegrid_solver.xi[I], finegrid_solver.psi[I]]
        .- L(finegrid_solver, I.I..., finegrid_solver.phase[I], finegrid_solver.potential[I])
    end

    restrict_solver!(grid[level], grid[level+1])
    coursegrid_solver = grid[level+1]
    solution = deepcopy(coursegrid_solver)

    d_large = restrict(d, G)
    r_large = restrict(r, G)


    u_large = zeros(size(d_large))
    v_large = zeros(size(d_large))

    for I in CartesianIndices(coursegrid_solver.phase)[2:end-1, 2:end-1]
        coursegrid_solver.xi[I]  , coursegrid_solver.psi[I] = L(coursegrid_solver , I.I... , coursegrid_solver.phase[I] , coursegrid_solver.potential[I] ) .+ [d_large[I],r_large[I]]
    end

    SMOOTH!(coursegrid_solver, 40 , false)

    u_large = coursegrid_solver.phase .- solution.phase
    v_large = coursegrid_solver.potential .- solution.potential

    finegrid_solver = grid[level]
    finegrid_solver.phase .+= prolong(u_large , G)
    finegrid_solver.potential .+= prolong(v_large, G)


    SMOOTH!(finegrid_solver, 80, false)
end
#+end_src

#+begin_src julia :tangle src/multisolver.jl :eval never :noweb no-export
function v_cycle!(grid::Array{T}, level) where T <: solver
    solver = grid[level]
    #pre SMOOTHing:
    SMOOTH!(solver, 400, false)

    d = zeros(size(solver.phase))
    r = zeros(size(solver.phase))

    # calculate error between L and expected values
    for I in CartesianIndices(solver.phase)[2:end-1, 2:end-1]
        d[I], r[I] = [solver.xi[I], solver.psi[I]] .- L(solver, I.I..., solver.phase[I], solver.potential[I])
    end

    <<restrict-to-coarse-grid>>

    #Newton Iteration for solving smallgrid
    for i = 1:300
        for I in CartesianIndices(solver.phase)[2:end-1, 2:end-1]

            diffrence = L(solution, I.I..., solution.phase[I], solution.potential[I])
                        .- [d_large[I], r_large[I]]
                        .- L(solver, I.I..., solver.phase[I], solver.potential[I])

            local ret = dL(solution, I.I...) \ diffrence

            u_large[I] = ret[1]
            v_large[I] = ret[2]
        end
        solution.phase .-= u_large
        solution.potential .-= v_large
    end

    <<prolong-to-fine-grid>>

    SMOOTH!(solver, 800, false)
end
#+end_src


After a few iterations, V-cycle exhibits the following behavior:

#+name: fig:solver-iteration
#+begin_src julia-vterm :results file graphics html :file iteration.gif :noweb no-export :async t :exports results html :output-dir images  :tangle src/plot.jl :session jl :eval never-export
<<init>>
using JLD2
using DataFrames
results = jldopen("experiments/iteration.jld2")["result"]
anim = @animate for res in eachrow(results)
    heatmap(res.solver.phase , title="phase field" , legend=:none , aspectratio=:equal , showaxis=false , grid=false , size=(400 ,400))
end
gif(anim , "images/iteration.gif" , fps = 10)
#+end_src

#+caption: A few time steps of the solver for different initial conditions as shown in [[Initial data]]
#+RESULTS: fig:solver-iteration
[[file:images/iteration.gif]]

* Numerical experiments
In the previous Chapter we discretized the CH equation based on the multigrid method described by the authors in [cite:@SHIN20117441] and we obtained a numerical scheme for \( \phi , \mu \). In this chapter we analyse the change in mass, change in total energy \( E^{bulk} \), stability in time , space and during sub-iterations.

** Energy evaluations
As discrete energy measure we use:
#+name: eq:discrete-energy
\begin{equation}
\begin{aligned}
E^{\text{bulk}}_d(\phi_{ij}) &= \sum_{i,j \in \Omega} \frac{\varepsilon^2}{2} |G\nabla_d \phi_{ij} |^2 + W\left(\phi_{ij}\right)  \\
&= \sum_{i,j \in \Omega} \frac{\varepsilon^2}{2} G_{i+\frac{1}{2}j}(D_x\phi_{i+\frac{1}{2}j}) ^2 + G_{ij+\frac{1}{2}}(D_y\phi_{ij+\frac{1}{2}})^2  + W\left(\phi_{ij}\right)  .\\
\end{aligned}
\end{equation}
Since the continous total energy Eq.[[eqref:eq:energy]] decreases over time, we expect it's discrete couterpart to exhibit the same behaviour. Them numerical implementation for the bulk energy can be found in the Appendix [[bulk energy and mass balance]].
In Fig.[[fig:energy-balance]] we observe the discrete total energy going down with increasing number of time-steps, as we expect from a  CH based solver. Visually we observe the energy decrease as reduced surface curvature.
#+name: fig:energy-balance
#+begin_src julia-vterm :results file graphics :file energy_balance.svg
<<init>>
using JLD2
using DataFrames
i0 = 1*64 +1
results = jldopen("experiments/iteration.jld2")["result"]
energy = bulk_energy.(results[i0:i0+63,:].solver)

p1 = plot(1:64 ,
          energy ,
          title=L"Discrete Energy $E_d^{bulk}$",
          xlabel="timesteps" ,
          ylabel="energy"  ,
          label=false)
p2 = heatmap(results.solver[i0].phase ,
             title="initial condition" ,
             legend=:none ,
             aspectratio=:equal ,
             showaxis=false ,
             grid=false)
p3 = heatmap(results.solver[i0+63].phase ,
             title="after 64 time-steps" ,
             aspectratio=:equal ,
             legend=:none ,
             showaxis=false ,
             grid=false)
p = plot(p2,p3,p1 , layout=layout3x1 , size=size3x1  )

savefig(p , "images/energy_balance.svg")
#+end_src

#+caption: Behaviour of energy \( E_{bulk} \) over time for one initial condition \( \phi_0 \).
#+RESULTS: fig:energy-balance
[[file:images/energy_balance.svg]]

** Numerical mass conservation
The analytical CH equation in Eq.[[eqref:eq:CH]]  is mass conservative as shown in Eq.[[eqref:eq:mass-conservation]].
Instead of a physical mass we use the average of \(\phi\) over the domain \(\Omega\).
This yields a balance between both phases.  Since our implementation uses no-flow boundary conditions the balance between /phase 1/ and /phase 2/ stays the same. We therefore calculate a balanace
\begin{align*}
b &= \frac{\sum_{i,j \in \Omega} \phi_{ij}}{N^2}
\end{align*}
such that \( b = 1 \) means there is only phase 1, \( \phi \equiv 1 \), and \( b = -1 \) means there is only phase 2, \( \phi \equiv -1 \).
Ideally this value stays constant over time for numerical mass conservation.
In practice we observe slight fluctuations in Figure [[fig:mass-balance]]. Those however are close to machine precision and can therefore be ignored. The numerical impolementation is  in appendix [[bulk energy and mass balance]].

#+name: fig:mass-balance
#+begin_src julia-vterm :results file graphics :file mass_balance.svg :output-dir images :noweb no-export :session jl
<<init>>
using JLD2
using DataFrames
using Measures
pgfplotsx()
i0 = 64 * 1 + 1
results = jldopen("experiments/iteration.jld2")["result"]
energy = [ massbal(s.phase) for s in results[i0:i0+63,:].solver]
p1 = plot(1:64 ,
          energy .- energy[1],
          xlabel= "time-steps" ,
          ylabel = "error" ,
          title = "phase change",
          label=false)
p2 = heatmap(results.solver[i0].phase ,
             title="initial condition" ,
             legend=:none ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false)
p3 = heatmap(results.solver[i0+63].phase ,
             title="after 64 time-steps" ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false ,
             legend=:none)

p = plot(p2,
         p3 ,
         p1 ,
         layout= layout3x1 ,
         size=size3x1)

savefig(p , "images/mass_balance.svg")
#+end_src

        #+caption: Behaviour of phase change over time for one initial condition \( \phi_0 \).
#+RESULTS: fig:mass-balance
[[file:images/mass_balance.svg]]

** Stability of a multi-grid sub-iteration
We expect our solver to stay stable when increasing the number of multigrid sub-iterations. To validate this assumption we compare the phase-field of the current sub-iteration \( \phi^{n+1,m}_{ij} \) with the phse-field of the previous sub-iteration \( \phi_{ij}^{n+1,m-1} \).
\begin{equation}
\| \phi^{n+1,m-1} - \phi^{n+1,m} \|_{Fr}= \sqrt{ \sum_{i,j \in \Omega_d} \left|   \phi^{n+1,m-1}_{ij} - \phi^{n+1,m}_{ij} \right|^2 }
\end{equation}
 As sub-iterations increase , \( m\to\infty \),  we expect the difference between both phase-fields to go to zero \( \|\phi^{n+1,m} - \phi^{n+1,m-1}\|_{Fr} \to 0 \). We observe this behaviour in Figure [[fig:convergence]]
#+name: fig:convergence
#+begin_src julia-vterm :results file graphics :file convergence.svg
<<init>>
<<setup-diverse-testgrids>>
using DataFrames
using JLD2
using LaTeXStrings
i0 = 4
df = jldopen("experiments/subiteration.jld2")["result"]
gd = groupby(df , :iteration)
res = combine(gd  , :cycle => ((x)-> [norm(x[i].phase - x[i-1].phase) for i in 2:size(x,1)]))

gres =  groupby(res , :iteration)[1]

p1= res.cycle_function[i0*64:(i0+1)*64-2] |>
    (x)-> plot(x ,
               yscale=:log10 ,
               title="Behaviour" ,
               xlabel="sub-iterations" ,
               ylabel= L" \|\phi^{n+1,m} - \phi^{n+1,m-1}\|_{Fr} " ,
               label= false)
p2 = heatmap(df.cycle[i0].phase ,
             title="initial condition" ,
             legend=:none ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false)
p3 = heatmap(df.cycle[i0].phase .-df.cycle[i0+62].phase ,
             title=L"\phi^{n+1,0} - \phi^{n+1,64}" ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false )

p = plot(p2,
         p3 ,
         p1 ,
         layout= layout3x1 ,
         size=(1600 , 1600))
savefig(p , "images/convergence.svg")
#+end_src

#+caption: Stability of the original CH solver for increasing sub-iterations
#+RESULTS[352350d7cb19f6fa37525bfb4950c4aba4eb9a6e]: fig:convergence
[[file:images/convergence.svg]]

in practise we observe the behaviour we expect, where an increasing number of sub-iterations leads to decreasing change compared to the previous sub-iteration.

#+begin_src julia-vterm :results file graphics html :file subiteration.svg :output-dir images :noweb no-export :session jl :exports none
<<init>>
using DataFrames
using JLD2
using LaTeXStrings
df = jldopen("experiments/subiteration.jld2")["result"]
gd = groupby(df , :iteration)
p1 = heatmap(gd[1].cycle[1].phase , aspectratio=:equal , title= "one subiteration" , showaxis=false  )
p2 = heatmap(gd[1].cycle[64].phase , aspectratio=:equal , title = "64 sub-iterations" , showaxis=false)
p = plot(p1,p2)
savefig(p , "images/subiteration.svg")
#+end_src

#+RESULTS[17fc4df2e4d089d1d12fd7209b2b8dc7cb027c15]:
#+begin_export html
[[file:images/subiteration.svg]]
#+end_export

** Stability in time
We expect our numerical error to decrease when calculating with smaller time steps. To test this, we  successively subdivide the original time interval \( [0,T] \) in finer parts. We fix \( \Delta t \cdot n = T \) for \( T=10^{-2} \) and test different values of \( n \). In Figure [[fig:stability-in-time]] we compare the phase-field \( \phi^{n}_{ij} \) and \( \phi^{n-1}_{ij}  \) at \( T=10^{-2} \). and observe the decrease we expect.
#+name: fig:stability-in-time
#+begin_src julia-vterm :results file graphics :file time-stability.svg
<<init>>
using DataFrames
using JLD2
using LaTeXStrings

df = jldopen("experiments/time.jld2")["result"]
gd = groupby(df , :iteration)

sd =  combine(x->(;phase=x[end,:].phase) , gd)
change = [norm(sd[!, "phase"][i] .- sd[! , "phase"][i-1]) for i=2:size(sd , 1)]

p1 = plot(change ,
         xlabel = L"number of time-steps to $t = 10^{-2}s$" ,
         ylabel=L"\|\phi_{ij}^{n+1} - \phi_{ij}^n \|_{Fr}" ,
          label = false,
         title= L"behavior of the original CH solver at $t=10^{-2}s$")
p2 = heatmap(gd[10].phase[end],
             title=L"$t=10^{-2} \,, n=10$" ,
             legend=:none ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false)
p3 = heatmap(gd[end].phase[end],
             title=L"$t=10^{-2} \,, n=64$" ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false ,
             legend=:none)

p = plot(p2,
         p3 ,
         p1 ,
         layout= layout3x1 ,
         size=size3x1)
savefig(p , "images/time-stability.svg")
#+end_src

#+Caption: Behavior of the baseline solver while solving the time interval \( T = \left[ 0 , 10^{-2} \right] \) with increasing number of time-steps.
#+RESULTS[0f922b31e3f46dde2af9273d00fa27b1317be553]: fig:stability-in-time
[[file:images/time-stability.svg]]

** Stability in space
We expect our methods to be stable under different grid-sizes \( h \) and grid-points \( N \). Therefore we expect the difference after one time-step between eg. a \( 512 \times 512 \) grid and a \( 1024 \times 1024 \) grid to be smaller than the difference between a \( 64 \times 64 \) grid and a \( 128 \times 128 \) grid. In order to keep the problem the same , we fix \( Nh = 10^{-3} \cdot 1024 \) and test for \( N \in \left\{ 1024 , 512 , 256 , 128 , 64 , 32 \right\} \)
In Fig.[[fig:stability-in-space]] we observe the differences to fluctuate between \(10^{-3}\) and \(10^{-4}\). Indicating that the solver is somewhat stable.
#+name: fig:stability-in-space
#+begin_src julia-vterm :results file graphics :file space-stability.svg
<<init>>
using DataFrames
using JLD2
using LaTeXStrings
gr()
df = jldopen("experiments/space_refinement.jld2")["result"]
gd = groupby(df , :iteration)
n = 4
change = [norm(gd[n].phase[i] - restrict(gd[n].phase[i-1] , G))/ *(size(gd[n].phase[i])...) for i= 2:size(gd[n].phase , 1) ]


p1 = plot([L"1024^2 \to 512^2" , L"512^2 \to 256^2" , L"256^2\to128^2" , L"128^2\to64^2" , L"64^2 \to32^2"],
         change ,
         ylabel = "difference" ,
         yscale=:log10,
         xlabel = "change in number of gridpoints" ,
         label=L"\Delta \phi" ,
         xscale=:log2 ,
         seriestype=:scatter ,
         xaxis=:flip ,
         legend=:topright)

p2 = heatmap(gd[4].phase[1],
             title=L"1024 \times 1024" ,
             legend=:none ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false)
p3 = heatmap(gd[4].phase[4],
             title=L"128 \times 128" ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false ,
             legend=:none)

p = plot(p2,
         p3 ,
         p1 ,
         layout= layout3x1 ,
         size=size3x1)
savefig(p , "images/space-stability.svg")
#+end_src

#+Caption: Behavior of the baseline solver while solving on successively finer grids
#+RESULTS[86f3e5e3d57f940d637b74a1a467c1862bbcb3aa]: fig:stability-in-space
[[file:images/space-stability.svg]]

* Relaxed problem
In effort to decrease the order of complexity, from fourth order derivative to second order, we propose an elliptical relaxation approach, where the relaxation variable \( c \) is the solution of the following elliptical PDE:
#+name: eq:elliptical-equation
\begin{align}
- \Delta c^\alpha  + \alpha c^a &= \alpha \phi ^\alpha,
\end{align}
where \( \alpha \) is a relaxation parameter. We expect to approach the original solution of the CH equation Eq.[[eqref:eq:CH]] as  \( \alpha \to \infty \).
This results in the following relaxation for the classical CH equation Eq.[[eqref:eq:CH]]:
#+name: eq:relaxed-cahn-hilliard
\begin{equation}
\begin{aligned}
\partial_t \phi^\alpha  &= \Delta \mu \,,\\
\mu &= \varepsilon ^2 \alpha(c^\alpha - \phi^\alpha) + W'(\phi) .
\end{aligned}
\end{equation}
It requires solving the elliptical PDE each time-step to calculate \(c\).

As ansatz for the numerical solver we propose:
#+name: eq:discrete-relaxed-cahn-hilliard
\begin{equation}
\begin{aligned}
\frac{\phi_{ij}^{n+1,\alpha} - \phi_{ij}^{n,\alpha}}{\Delta t}  &=  \nabla _d \cdot (G_{ij} \nabla_d \mu_{ij}^{n+\frac{1}{2},\alpha} )  \,,\\
 \mu_{ij}^{n+\frac{1}{2},\alpha} &= 2\phi_{ij}^{n+1,\alpha} - \varepsilon^2 a(c_{ij}^{n+1,\alpha} - \phi_{ij}^{n+1,\alpha})  + W'(\phi_{ij}^{n,\alpha}) - 2\phi _{ij}^{n,\alpha} \,.
\end{aligned}
\end{equation}
This approach is inspired by Eq.[[eqref:eq:discrete-cahn-hilliard]] and adapted to the relaxed CH equation in Eq.[[eqref:eq:discrete-relaxed-cahn-hilliard]].
We then apply the multi-grid method proposed in [[Multi-grid method]] to the relaxed problem by replacing the differential operators with their discrete counterparts, as defined in Eq.[[eqref:eq:discretization]],
and expand them.
** Elliptical PDE
In order to solve the relaxed CH equation we solve the following PDE in each  time step:
\begin{align*}
- \nabla \cdot  (G \nabla c^\alpha) + \alpha c^\alpha  = \alpha \phi ^\alpha \,.
\end{align*}
Similarly to the first solver we solve this PDE  with a finite difference scheme using the same discretization as before.
*** Discretization
To solve the additional elliptical system, we propose a simple implicit scheme similiar to the one used in Eq.[[eqref:eq:elliptical-equation]].:
\begin{align*}
- \nabla_d \cdot  (G_{ij} \nabla_d c_{ij}^{n+1,\alpha}) + \alpha  c_{ij}^{n+1,\alpha} &= \alpha \phi_{ij}^{n+1,\alpha}
\end{align*}
We then use the finite differences defined in Eq.eqref:eq:discretization to derrive the corresponding linear system.
\begin{align*}
- \frac{1}{h^2} ( G_{i+\frac{1}{2}j}(c_{i+1j}^{n+1,\alpha} - c_{ij}^{n+1,\alpha}) & \\
+G_{ij+\frac{1}{2}}(c_{ij+1}^{n+1,\alpha} - c_{ij}^{n+1,\alpha}) & \\
+G_{i-\frac{1}{2}j}(c_{i-1j}^{n+1,\alpha} - c_{ij}^{n+1,\alpha})& \\
+G_{ij-\frac{1}{2}}(c_{ij-1}^{n+1,\alpha} - c_{ij}^{n+1,\alpha})) + \alpha  c_{ij}^{n+1\alpha} &=\alpha  \phi_{ij}^{n+1,\alpha}
\end{align*}

We abbreviate \(  \Sigma_G c^{n+1,\alpha}_{ij} = G_{i+\frac{1}{2}j} c^{n+1,\alpha}_{i+1j} +  G_{i-\frac{1}{2}j} c^{n+1,\alpha}_{i-1j} + G_{ij+\frac{1}{2}}  c^{n+1,\alpha}_{ij+1} + G_{ij-\frac{1}{2}} c^{n+1,\alpha}_{ij-1}  \) and \(  \Sigma_{Gij} = G_{i+\frac{1}{2}j} + G_{i-\frac{1}{2}j} + G_{ij+\frac{1}{2}} + G_{ij-\frac{1}{2}}  \). Then the discrete elliptical PDE can be stated as:
#+name: eq:discrete_elyps
\begin{align}
-\frac{ \Sigma_G c^{n+1,\alpha}_{ij}}{h^2} + \frac{\Sigma_G}{h^2} c^{n+1,\alpha}_{ij} + \alpha c^{n+1,\alpha}_{ij} &= \alpha\phi^{n+1,\alpha}_{ij} \,.
\end{align}
this constituted a linear system with \( N\times N \) equations
*** Gauss Seidel solver for the elliptical system
To solve the elliptical system we introduce a Gauss-Seidel solver similar to the Gauss-Seidel Solver used for the smoothing step in the multi-grid method.
We define this iteration in terms of \( s \),
For the Gauss-Seidel Iterative solver, we define the abbreviations
 \[  \Sigma_G c^{n+1,\alpha , s+\frac{1}{2}}_{ij} = G_{i+\frac{1}{2}j} c^{n+1,\alpha,s}_{i+1j} +  G_{i-\frac{1}{2}j} c^{n+1,\alpha,s+1}_{i-1j} + G_{ij+\frac{1}{2}}  c^{n+1,\alpha, s}_{ij+1} + G_{ij-\frac{1}{2}} c^{n+1,\alpha ,s+1}_{ij-1}  \]
We then define the gaus seidel iteration by the following, and solve algebraicly for \( c_{ij}^{n+1,\alpha,s+1} \)
\begin{align*}
\left( \frac{\Sigma_{Gij}}{h^2} + \alpha \right)c_{ij}^{n+1,\alpha,s+1} = \alpha\phi^{n+1,\alpha}_{ij} + \frac{\Sigma_G c_{ij}^{n+1,\alpha,s+\frac{1}{2}}}{h^2}\\
c_{ij}^{n+1,\alpha,s+1} = \frac{\alpha\phi^{n+1,\alpha}_{ij} + \frac{\Sigma_G c_{ij}^{n+1,\alpha, s+\frac{1}{2}}}{h^2}}{\frac{\Sigma_{G}}{h^2} + \alpha}\\
c_{ij}^{n+1,\alpha, s+1} = \frac{\alpha h^2 \phi^{n+1,\alpha}_{ij}}{\Sigma_{Gij} + \alpha h^2} + \frac{\Sigma_G c_{ij}^{n+1,\alpha , s+\frac{1}{2}}}{\Sigma_{Gij} + \alpha h^{2}}
\end{align*}
We run the elliptical solver for a fixed number of iterations. Furthermore we denote the solution of the iterative solver with \( c_{ij}^{n+1,\alpha} \). We implement the corresponding iteration as follows:
#+begin_src julia :eval never :tangle src/elypssolver.jl :exports none
using ProgressBars

"""
    elyps_solver(c,
    phase,
    len,
        width,
    alpha,
    h,
    n
)

TBW
"""
#+end_src
#+name: elyps_solver
#+begin_src julia :eval never :tangle src/elypssolver.jl
function elyps_solver!(solver::T, n) where T  <: Union{relaxed_multi_solver , adapted_relaxed_multi_solver}
    for k in 1:n
        for i = 2:(solver.len+1)
            for j = 2:(solver.width+1)
                bordernumber = neighbours_in_domain(i, j,G, solver.len, solver.width)
                solver.c[i, j] =
                    (
                        solver.alpha * solver.phase[i, j] +
                        discrete_G_weigted_neigbour_sum(i, j, solver.c, G, solver.len, solver.width) / solver.h^2
                    ) / (bordernumber / solver.h^2 + solver.alpha)

            end
        end
    end
end
#+end_src
** Relaxed system
We use the same discetization approach, as for the baseline system.
We reformulate the discretization in Eq.[[eqref:eq:discrete-relaxed-cahn-hilliard]] in terms of the relaxed function \(L\) as follows:
\begin{align*}
L_r
\begin{pmatrix}
\phi ^{n+1,\alpha}_{ij} \\
\mu^{n+\frac{1}{2},\alpha}_{ij}
\end{pmatrix}
&=
\begin{pmatrix}
\frac{\phi^{n+1,m,\alpha}_{ij}}{\Delta t} - \nabla _d \cdot (G_{ji} \nabla _d \mu^{n + \frac{1}{2},m,\alpha}_{ji}) \\
\varepsilon ^2 \alpha (c^\alpha_{ij} - \phi^{n+1,m,\alpha}_{ij}) - 2\phi ^{n+1,m,\alpha}_{ij} -\mu^{n + \frac{1}{2},m,\alpha}_{ji}
\end{pmatrix}
\end{align*}

and its Jacobian:
\begin{align*}
DL_r\begin{pmatrix}
\phi^{n+1,\alpha, m}_{ij} \\
\mu^{n+\frac{1}{2},m,\alpha}_{ij}
\end{pmatrix} &= \begin{pmatrix}
\frac{1}{\Delta t} & \frac{1}{h^2}\Sigma_{G}  \\
- \varepsilon^2 \alpha  - 2 & 1
\end{pmatrix}
\end{align*}
Much like the original solver, where in Eq.eqref:eq:explicit-smooth we wrote the initial approach as as LES, we write the LES for the relaxed system as
\begin{equation}
L_r
\begin{pmatrix}
\phi ^{n+1,\alpha}_{ij} \\
\mu^{n+\frac{1}{2},\alpha}_{ij}
\end{pmatrix}
=
\begin{pmatrix}
\zeta^n_{ij}
 \\
\psi^n_{ij}
\end{pmatrix},
\end{equation}
where \( \left( \zeta_{ij}^n  , \psi_{ij}^n \right) \) are the same in the original and relaxed solvers.
Since the relaxed CH equation is no longer second order in both directions the resulting LES is simpler. To take advantage of this, we resolve the system algebraically for each grid-point \( \left( i.j \right) \).
#+name: eq:discrete-relaxed-smooth
\begin{align}
  -\frac{\Sigma_{Gij}}{h^2}\mu^{n + \frac{1}{2},m,\alpha}_{ji} &= \frac{\phi ^{n+1,m,\alpha}_{ij}}{\Delta t} - \zeta^{n,\alpha}_{ij} - \frac{\Sigma_G\mu_{ij}}{h^2} \,,\\
\label{discrete-relaxed-smooth2}
 \varepsilon ^2 \alpha \phi ^{n+1,m,\alpha}_{ij} + 2 \phi ^{n+1,m,\alpha}_{ij} &= \varepsilon ^2 \alpha c^{n,\alpha}_{ij}  -\mu^{n + \frac{1}{2},m,\alpha}_{ji}  - \psi_{ij}^{n,\alpha} \,,
\end{align}
where
- \(  \Sigma_G \mu_{ij} = G_{i+\frac{1}{2}j} \mu^{n + \frac{1}{2},m}_{i+1j} +  G_{i-\frac{1}{2}j} \mu^{n + \frac{1}{2},m}_{i-1j} + G_{ij+\frac{1}{2}}  \mu^{n + \frac{1}{2},m}_{ij+1} + G_{ij-\frac{1}{2}} \mu^{n + \frac{1}{2},m}_{ij-1}  \),
The second dimension of eqref:eq:discrete-relaxed-smooth is solvable algebraically for \( \mu_{ij}^{n+\frac{1}{2} , m , \alpha} \) and subsitute it in eqref:discrete-relaxed-smooth2.
\begin{align*}
\varepsilon^2 \alpha(\phi_{ij}^{n+1,m,\alpha}) + 2\phi_{ij}^{n+1,m,\alpha} &= \varepsilon^2 \alpha c^\alpha - \frac{h^2}{\Sigma_G} (\frac{\phi_{ij}^{n+1,m,\alpha}}{\Delta t} - \zeta^n_{ij} - \frac{1}{h^2} \Sigma_G \mu_{ij}) - \psi_{ij}
\end{align*}
We solve this system for \( \phi_{ij}^{n+1,m,\alpha} \). This results in the following system
#+name: eq:relaxed-les
\begin{equation}
\begin{aligned}
 \phi_{ij}^{n+1,m,\alpha} &= \left(\varepsilon^2 \alpha c^\alpha - \frac{h^2}{\Sigma_G}(- \zeta^n_{ij} - \frac{\Sigma_G \mu_{ij}}{h^2} ) -\psi_{ij}\right)\left(\varepsilon^2 \alpha + 2 + \frac{h^2}{\Sigma_G \Delta t}\right)^{-1} \\
\mu_{ij}^{n+\frac{1}{2} ,m , \alpha} &= \frac{h^2}{\Sigma_G} (\frac{\phi_{ij}^{n+1,m,\alpha}}{\Delta t} - \zeta^n_{ij} - \frac{1}{h^2} \Sigma_G \mu_{ij})
\end{aligned}
\end{equation}
this system does no longer require solving a 2D LES in the gaus seidel implementation of the following chapter.
** Relaxed Gauss-Seidel iteration
We derrive a gaus seidel iteration from Eq.eqref:eq:relaxed-les. As before we state the iteration as.
\begin{equation}
\begin{aligned}
 \phi_{ij}^{n+1,m,\alpha,s+1} &= \left(\varepsilon^2 \alpha c^\alpha - \frac{h^2}{\Sigma_G}(- \zeta^n_{ij} - \frac{\Sigma_G \mu_{ij}^{n+\frac{1}{2},\alpha,m,s+\frac{1}{2}}}{h^2} ) -\psi_{ij}^n\right)\left(\varepsilon^2 \alpha + 2 + \frac{h^2}{\Sigma_G \Delta t}\right)^{-1} \\
\mu_{ij}^{n+\frac{1}{2} ,m , \alpha , s+1} &= \frac{h^2}{\Sigma_G} (\frac{\phi_{ij}^{n+1,m,\alpha , s+1}}{\Delta t} - \zeta^n_{ij} - \frac{1}{h^2} \Sigma_G \mu_{ij}^{n+\frac{1}{2},\alpha,m,s+\frac{1}{2}})
\end{aligned}
\end{equation}
where
- \(  \Sigma_G \mu_{ij}^{n+\frac{1}{2},\alpha,m,s+\frac{1}{2}} = G_{i+\frac{1}{2}j} \mu^{n + \frac{1}{2},m,s}_{i+1j} +  G_{i-\frac{1}{2}j} \mu^{n + \frac{1}{2},m,s+1}_{i-1j} + G_{ij+\frac{1}{2}}  \mu^{n + \frac{1}{2},m,s}_{ij+1} + G_{ij-\frac{1}{2}} \mu^{n + \frac{1}{2},m,s+1}_{ij-1}  \),
Contrary to the Gauss Seidel iteration in the baseline solver, this iteration is a lot cheaper to calculate, since it no longer requires solving a 2x2 LES per grid-point.
#+name: solve-for-phi
#+begin_src julia :eval never :exports none
bordernumber = neighbours_in_domain(i, j, G, solver.len, solver.width)

solver.phase[I] = (solver.epsilon^2 * solver.alpha * solver.c[I] - solver.h^2 / bordernumber * ( -solver.xi[I]  - discrete_G_weigted_neigbour_sum(i,j,solver.potential , G , solver.len , solver.width) / solver.h^2 ) - solver.psi[I]) / (solver.epsilon^2 * solver.alpha  + 2 + solver.h^2 / (bordernumber*solver.dt))
#+end_src
#+name: update-the-potential
#+begin_src julia :eval never :exports none
            solver.potential[I] = (solver.phase[I]/solver.dt - solver.xi[I] - discrete_G_weigted_neigbour_sum(i,j, solver.potential , G , solver.len , solver.width)/solver.h^2) * (-solver.h^2/bordernumber)
#+end_src
#+name: SMOOTH_relaxed
#+begin_src julia :eval never :tangle src/multi_relaxed.jl :noweb no-export
function SMOOTH!(
    solver::T,
    iterations,
    adaptive
) where T <: Union{relaxed_multi_solver , adapted_relaxed_multi_solver}
    for k = 1:iterations
        # old_phase = copy(solver.phase)
        for I in CartesianIndices(solver.phase)[2:end-1, 2:end-1]
            i, j = I.I
            <<solve-for-phi>>
            <<update-potential>>
        end

        #if adaptive && LinearAlgebra.norm(old_phase - solver.phase) < 1e-10
            ##println("SMOOTH terminated at $(k) succesfully")
            #break
        #end
    end
end
#+end_src
#+caption: Effect of the relaxed SMOOTH operator, and additional solving of the elliptical problem, for different values of alpha
#+RESULTS: fig:relaxed-smooth-eval
[[file:images/smooth_relaxed.svg]]

Furthermore, experimentation shows that alpha alone is insufficient to get a relaxed method consistent with the original solver, since \( \alpha \) had an effect similar to \( \varepsilon \), where it changed the boundary thickness in the phase-field \( \phi \). Therefore \( \varepsilon \) and \( \alpha \) cannot be chosen independently. Hence we use a simple Monte Carlo optimizer for \( \alpha,\varepsilon \) in order to give the relaxed solver the best chance we can. The implementation thereof is given in Appendix [[Monte Carlo optimizer]].
** The relaxed multigrid method
As the difference between both methods is abstracted away in the operators, the relaxed V-cycle the replaces the original operators with their relaxed counterparts. Due to julias multiple dispatch features this changes nothing in the implementation Therefore we reuse the original V-cycle in the [[Multi-grid method]].
In the executions for each time step, we add the elliptic solver in the subiteration. The iterative solver is then defined as:
#+begin_src julia :eval never :exports code
for j in 1:timesteps

    set_xi_and_psi!(solvers[1])

    for i = 1:subiterations

        elyps_solver!(solvers[1] , 1000)
        v_cycle!(solvers, 1)
    end
end
#+end_src

#+name: fig:relaxed-anim
#+begin_src julia-vterm :results file graphics html :file relaxed-anim.gif
<<init>>
using JLD2
using DataFrames
using Measures

gr()

results = jldopen("experiments/relaxed-iteration4.jld2")["result"]
anim = @animate for s in results.solver
    heatmap(s.phase)
    end
gif(anim , "images/relaxed-anim.gif", fps=10)
#+end_src

#+RESULTS: fig:relaxed-anim
[[file:images/relaxed-anim.gif]]
* Relaxed experiments
We expect the relaxed solver to behave the same as the baseline method for all test cases that we have introduced in Chapter [[Numerical experiments]]. Therefore we run the same experiments for our relaxed solver.
** Relaxed energy evaluations
we do evaluate our relaxed method using the discrete energy defined in Eq.[[eqref:eq:discrete-energy]]. On the same initial data, and with the same values for \( \varepsilon , h , dt \) as in the Chapter.[[Energy evaluations]]. In Figure.[[fig:relaxed-energy-balance]] we then observe the energy decay we expected. Our relaxed approach closely follows the baseline, although it consistently decayed slightly faster. This is within our expectations.
#+name: fig:relaxed-energy-balance
#+begin_src julia-vterm :results file graphics :file relaxed-energy-balance.svg
<<init>>
using JLD2
using DataFrames
i0 = 1*64 +1
original_results = jldopen("experiments/alt-iteration.jld2")["result"]
relaxed_results = jldopen("experiments/alt-relaxed-iteration.jld2")["result"]
original_energy = bulk_energy.(original_results[i0:i0+63,:].solver)
relaxed_energy = bulk_energy.(relaxed_results[i0:i0+63,:].solver)
p1 = plot(1:64 ,
          original_energy ,
          title=L"Discrete Energy $E_d^{bulk}$",
          xlabel="timesteps" ,
          ylabel="energy"  ,
          label="original")
p1 = plot!(p1,
           1:64 ,
           relaxed_energy ,
           title=L"Discrete Energy $E_d^{bulk}$",
           xlabel="timesteps" ,
           ylabel="energy"  ,
           label="relaxed")
p2 = heatmap(relaxed_results.solver[i0].phase ,
             title="initial condition" ,
             legend=:none ,
             aspectratio=:equal ,
             showaxis=false ,
             grid=false)
p3 = heatmap(relaxed_results.solver[i0+63].phase ,
             title="after 64 time-steps" ,
             aspectratio=:equal ,
             legend=:none ,
             showaxis=false ,
             grid=false)

p = plot(p2,p3,p1 , layout=layout3x1 , size=(1600 ,1600))
savefig(p , "images/relaxed-energy-balance.svg")
#+end_src

#+caption: Energy decay of the relaxed solver compared to the original solver.
#+RESULTS[ddc6809b1b7f3918596757e2d1ab6e0f9ac4c92f]: fig:relaxed-energy-balance
[[file:images/relaxed-energy-balance.svg]]


We observe the discrete energy decrease is the same manner as with the original solver.
** Relaxed numerical mass balance
since both the CH equation Eq.[[eqref:eq:CH]] and the baseline solver from Fig.[[fig:mass-balance]] are mass conservative, the relaxed solver should be as well, to be competitive with the baseline approach. Our relaxed solver shows  mass loss around 5% as seen in Fig.[[fig:relaxed-mass-balance]]. This is nowhere near the machine precision, we reached in Fig.[[fig:mass-balance]]. The relaxed solver is therefore not mass conservative.
#+name: fig:relaxed-mass-balance
#+begin_src julia-vterm :results file graphics :file relaxed-mass-balance.svg
<<init>>
using JLD2
using DataFrames
using Measures
i0 = 64 * 1+1
results = jldopen("experiments/alt-relaxed-iteration.jld2")["result"]
energy = [ massbal(s.phase) .- massbal(results.solver[i0].phase) for s in results[i0:i0+63,:].solver]
p1 = plot(1:64 , energy, xlabel= "time-steps" , ylabel = "error"  , label =false)
p2 = heatmap(results.solver[i0].phase , title="initial condition" , legend=:none , aspectratio=:equal , grid=false , showaxis=false)
p3 = heatmap(results.solver[i0+63].phase , title="after 64 time-steps" , legend=:none , aspectratio=:equal , grid=false , showaxis=false)
p = plot(p2,p3 , p1 , layout=layout3x1 , size=(1600 ,1600))
savefig(p , "images/relaxed-mass-balance.svg")
#+end_src

#+caption: Mass los in the relaxed solver


** Stability of a relaxed multigrid sub-iteration
We also compare the subiteration behaviour of the relaxed solver to the original we therefore plot \( \|\phi_{ij}^{n+1,m} - \phi_{ij}^{n+2,m-1} \|_{Fr} \) against \( \| \phi_{ij}^{n+1,m,\alpha} - \phi_{ij}^{n+1,m-1,\alpha} \| \) for \( m \in \{2, \dots , 64\} \). After some implementation mistakes the  sub-iterations in Fig.[[fig:relaxed-convergence]] are stable. The relaxed solver has significantly slower convergence compared to the baseline solver. During testing the relaxed solverg converged at around 1024 sub-iterations and the baseline solver at around 16.
#+name: fig:relaxed-convergence
#+begin_src julia-vterm :results file graphics :file relaxed-convergence.svg
<<init>>
using DataFrames
using JLD2
using LaTeXStrings
n=1024

i0 = 1
df = jldopen("experiments/subiteration.jld2")["result"]
df = groupby(df , :experiment)[i0]
gd = groupby(df , :iteration)
original_res = combine(gd  , :cycle => ((x)-> [norm(x[i].phase - x[i-1].phase) for i in 2:size(x,1)]))

original_res =  groupby(original_res , :iteration)[1].cycle_function

df = jldopen("experiments/alt-relaxed-subiteration.jld2")["result"]
df = groupby(df , :experiment)[i0]
gd = groupby(df , :iteration)
relaxed_res = combine(gd  , :cycle => ((x)-> [norm(x[i].phase - x[i-1].phase) for i in 2:size(x,1)]))

relaxed_res =  groupby(relaxed_res , :iteration)[1].cycle_function
p=plot([original_res, relaxed_res[1:128]],label= ["original"  "relaxed"] , ylabel="difference" , xlabel="sub-iteration" , yaxis=:log10 )
savefig(p , "images/relaxed-convergence.svg")
#+end_src

#+RESULTS[14ad9189aff29255900fc51825317bae4f13be6e]: fig:relaxed-convergence
[[file:images/relaxed-convergence.svg]]

** Relaxed stability in time
we test the behaviour under refinement in time by succesivly subdividing the original time interval \( [0,T] \) in finer parts. We use the same meassure as in Chaper.[[Stability in time]] and directly compare. We observe simmilar behaviour to the original solver in Fig.[[fig:relaxed-stability-in-time]]. The relaxed solver has consisten lower difference than the original solver. This might suggest a more consistent method over time.
#+name: fig:relaxed-stability-in-time
#+begin_src julia-vterm :results file graphics :file relaxed-time-stability.svg
<<init>>
using DataFrames
using JLD2
using LaTeXStrings
df = jldopen("experiments/relaxed-time.jld2")["result"]
dfo = jldopen("experiments/time.jld2")["result"]
gdo = groupby(dfo,:iteration)
dfo = DataFrame([ last(x) for x in gdo])
change = [norm(df[!, "phase"][i] .- df[! , "phase"][i-1]) for i=2:size(df , 1)]
change0 = [norm(dfo[!, "phase"][i] .- dfo[! , "phase"][i-1]) for i=2:size(dfo , 1)]
p = plot(change , ylabel = "difference" , xlabel = "number of timesteps" , label="relaxed" )
p = plot(p , change0 , ylabel = "difference" , xlabel = "number of timesteps" , label="original")
savefig(p , "images/relaxed-time-stability.svg")
#+end_src

#+Caption: Behavior of the relaxed and baseline solvers while solving the time interval \( t \in \left[ 0 , 10^{-2} \right] \) with increasing number of time-steps.
#+RESULTS[ef38636e23fc3d9303364c9203744561c2ff36bd]: fig:relaxed-stability-in-time
[[file:images/relaxed-time-stability.svg]]

** Relaxed stability in space
For the relaxed solver we do the same evaluation for space, that we did for the baseline solver. We \(\Delta\phi\) going down exponentially with increasing grid sizes. This behaviour is as expected. However the jump from    \(128^2 \to 64^2\) to \(256^2 \to 128^2\)leads us to believe, that the solver is not yet stable for courser grids.

#+name: fig:relaxed-stability-in-space
#+begin_src julia-vterm :results file graphics :file relaxed-space-stability.svg :exports none
<<init>>
using DataFrames
using JLD2
using LaTeXStrings
default(fontfamily="computer modern" , titlefontsize=22 , guidefontsize=18 , tickfontsize = 12 , legendfontsize=12)
gr()
odf = jldopen("experiments/space_refinement.jld2")["result"]
df = jldopen("experiments/relaxed_space_refinement.jld2")["result"]
gd = groupby(df , :iteration)
ogd = groupby(odf , :iteration)
n = 4
change = [norm(gd[n].phase[i] - restrict(gd[n].phase[i-1] , G))/ *(size(gd[n].phase[i])...) for i= 2:size(gd[n].phase , 1) ]
ochange = [norm(ogd[n].phase[i] - restrict(ogd[n].phase[i-1] , G))/ *(size(ogd[n].phase[i])...) for i= 2:size(ogd[n].phase , 1) ]
p = plot([L"1024^2 \to 512^2" , L"512^2 \to 256^2" , L"256^2\to128^2" , L"128^2\to64^2" , L"64^2 \to32^2"],
[ochange ,change] ,
ylabel = "difference" ,
yaxis = :log10,
xlabel = "change in number of gridpoints" ,
labels=[L"original $\Delta \phi$"  L"relaxed $\Delta\phi$"  ],
seriestype=:scatter ,
xaxis=:flip ,
legend=:topright,
right_margin = 10 * Plots.mm,
left_margin = 2 * Plots.mm,
bottom_margin = 2* Plots.mm)

savefig(p , "images/relaxed-space-stability.svg")
#+end_src

#+RESULTS[ac21efe8cb7262c2f4dc5fe974e6ca94c77da05b]: fig:relaxed-stability-in-space
[[file:images/relaxed-space-stability.svg]]

* Comparison
In the previous chapter we have shown the stability for both solver. In this chapter we show a direct comparison between both methods.
** effect of alpha
To see the impact of \( \alpha \) on our solver, we evaluate both solvers after one time-step , and then calculate the difference between \( \phi_{ij}^{n+1} \) and \( \phi_{ij}^{n+1,\alpha} \), for various values of \( \alpha \).
Since the solution of the relaxed solver should approach the original solver, we expect
\begin{equation}
||\phi_{ij}^{n+1} - \phi_{ij}^{n+1,\alpha}||_{Fr} \to 0.
\end{equation}
In Fig.[[fig:alpha-error]] we observe the following behaviour where in all cases the difference between the relaxed solver and the original solver is apparent. Furthermore we observe a optimal value of \( \alpha \) at approximately \( 7.5 * 10^5 \). We explain this with our observations done for the Smoothing operator, where for small and large values of \( \alpha \) the relaxed solver results in restricted behaviour, which we also expect. On the other hand, for large values of \( \alpha \) the elliptical equation approaches \( \phi \), however it does not converge to \( \phi \) for small values of \( \alpha \).
#+name: fig:alpha-error
#+begin_src julia-vterm :results graphics file :file alpha-error.svg
using JLD2
using DataFrames
using Measures
<<init>>

pgfplotsx()
results = jldopen("experiments/alpha.jld2")["result"]
p=plot(results.alpha , results.error ./64^2, label=false , xlabel=L"\alpha" , ylabel="difference" )

savefig(p, "images/alpha-error.svg")
#+end_src

#+caption: Difference between the original solver \( \phi^1_{ij} \) and the relaxed solver \( \phi^{1,\alpha}_{ij} \) for different values of  \( \alpha \)
#+RESULTS[f474fd86cf30b6b4f9d6b13a527d99b42b609d04]: fig:alpha-error
[[file:images/alpha-error.svg]]

** Direct comparison
We then show a coparison of both solvers we plot the phase-fields after 64 time-steps, and the difference \(\|\phi^{n+1}_{ij} - \phi^{n+1,\alpha}_{ij}\|_{Fr}\) over the time-steps \( n \in \{0 , \dots , 63 \}\).
#+begin_src julia-vterm :results file graphics html :file relaxed-comp.gif
<<init>>
using JLD2
using DataFrames
using Measures
using LaTeXStrings

gr()

results = jldopen("experiments/iteration.jld2")["result"]
results1 = jldopen("experiments/relaxed-iteration.jld2")["result"]
results2 = jldopen("experiments/relaxed-iteration-nophi.jld2")["result"]
results3 = jldopen("experiments/relaxed-iteration-nosubiter.jld2")["result"]
titles =  ["original" , "subiter elliptical" , L"without $2\phi$" , L"without $2\phi$ and subiter"]

anim = @animate for iter in zip(results.solver,results1.solver ,results2.solver , results3.solver)
    plots = []
    for (phase , title) in zip(iter ,titles)
        push!(plots , heatmap(phase.phase , title=title , legend=:none , aspectratio=:equal , grid=false , showaxis=false))
        plot(plots...)
        end
    end
gif(anim , "images/relaxed-comp.gif", fps=10)
#+end_src
We can observe slight differences between the original solver and the relaxed solver. To quantify those, we run the relaxed solver for a fixed value of \( \alpha=7700 \) , as it is in the intervall where \( \alpha \) is minimal in Fig.[[fig:alpha-error]]. We then  show the numerical difference between \( \phi_{ij}^n \) and \( \phi_{ij}^{n,\alpha} \) in Fig.[[fig:relaxed-original-comparison]]. The observed difference is mainly in areas with high curvature and inclusions of small segments of one phase in the other.
#+name: relaxed-comparison
#+begin_src julia-vterm :results file graphics html :file relaxed-comparison.gif
<<init>>
using JLD2
using DataFrames
using Measures
using LaTeXStrings

i = 0*64 +1
gr()

original_results = jldopen("experiments/alt-iteration.jld2")["result"]
relaxed_results = jldopen("experiments/alt-relaxed-iteration.jld2")["result"]

difference = [norm(original.phase./2 .- relaxed.phase./2) /64^2 for (original, relaxed) in zip(original_results.solver[i:i+63],relaxed_results.solver[i:i+63])
]
anim = @animate for (original, relaxed) in zip(original_results.solver[i:i+63],relaxed_results.solver[i:i+63])
        p1 = plot(1:size(difference,1) , difference , xlabel= "time-steps" , ylabel = "error"  , title="diffrence" , label=false)
        p2 = heatmap(original.phase , title="original" , legend=:none , aspectratio=:equal , grid=false , showaxis=false)
        p3 = heatmap(relaxed.phase , title="relaxed" , aspectratio=:equal , grid=false , showaxis=false , legend=:none)
        plot(p1,p2,p3 , layout=(1,3) , size=(2000 ,700) , bottom_margin=20Plots.mm , left_margin=20Plots.mm)
        end
gif(anim , "images/relaxed-comparison.gif", fps=10)
#+end_src

#+RESULTS[76efe71ab5265c6ad1da811a6f84242b09d84c91]: relaxed-comparison
#+begin_export html
[[file:images/relaxed-comparison.gif]]
#+end_export


#+name: fig:relaxed-original-comparison
#+begin_src julia-vterm :results file graphics :file relaxed-comparison.svg
<<init>>
using JLD2
using DataFrames
using Measures
using LaTeXStrings

i = 0*64 +1
pgfplotsx()
original_results = jldopen("experiments/alt-iteration.jld2")["result"]
relaxed_results = jldopen("experiments/alt-relaxed-iteration.jld2")["result"]

difference = [norm(original.phase .- relaxed.phase) /64^2 for (original, relaxed) in zip(original_results.solver[i:i+63],relaxed_results.solver[i:i+63])
]
original, relaxed =   original_results.solver[i+63],relaxed_results.solver[i+63]

p1 = plot(1:size(difference,
                 1) ,
          difference ,
          xlabel= "time-steps" ,
          ylabel = "error"  ,
          title="diffrence" ,
          label=false)

p2 = heatmap(original.phase ,
             title=L"original at $n=64$" ,
             legend=:none ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false)
p3 = heatmap(relaxed.phase ,
             title=L"relaxed at $n=64$" ,
             aspectratio=:equal ,
             grid=false ,
             showaxis=false ,
             legend=:none)
p=plot(p2,
       p3,
       p1 ,
       layout=layout3x1 ,
       size=size3x1 )
savefig(p , "images/relaxed-comparison.svg")
#+end_src

#+caption: Comparison between the original and the relaxed CH solvers.
#+RESULTS[cca6cd5858468e58cbdf037ea297f65a5a9bf61b]: fig:relaxed-original-comparison
[[file:images/relaxed-comparison.svg]]

** optimizer for alpha
In addition to the experiments in Fig.[[fig:alpha-error]] we have experimented with a Monte Carlo Optimizer to optimize \( \alpha \) in conjunction with \( \varepsilon \), to best approximate the baseline solver after one time-step. This resulted in a optimal \( \varepsilon \) found that was very close to the actual \( \varepsilon \) used. (9e-3 compared to 8e-3). This gives us confidence that the relaxed method solves the same problem, as the baseline. Optimal values for \( \alpha \) varied , however stayed fairly large around \( 10^5 \to 10^{6} \).

* Conclusion
In this thesis we have presented a simple introduction to the CH equation and have shown two numerical solvers for it.
We have presented a baseline method implemented from the authors [cite:@SHIN20117441], and have Shown how to derive it from their initial approach.
We have done the derivations in a way, that enables a simple adaptation to a modified version of the discrete CH equation Eq.[[eqref:eq:discrete-cahn-hilliard]], as introduced in [cite:@SHIN20117441].
We have introduced measures to evaluate both solvers in space , time and mass conservation as well as their sub-iteration behaviour.
We have shown the baseline to be mass conservative, in a numerical sense, and we have shown it to be stable in all tested measures.
We have shown our relaxed solver to approach the baseline, during sub-iterations it converges significantly slower than the baseline solver. Furthermore it is not mass conservative.
We intentionally didn't evaluate runtime since numerical experiments have shown both solvers to be dependant on the amount of sub-iterations, hyperparameters such as \( \varepsilon \) as well as the number off smoothing iterations.
It would therefore be unfair to evaluate one solver on a set of parameters tweaked for the other.
As example for this dilemma we recall runs where the relaxed solver was around 10x faster than the baseline with the same parameters.
The baseline solver was able to run with 10x less smoothing iterations than the relaxed one.
A fair comparison would hence require to find the optimal number of smoothing for each solver.


For the sake of completeness we include runtime benchmarks Of both methods. Those should be taken with a pinch of salt because of the reasons above. Both examples are run with the same parameters and  the results are in the Appendix.

** Outlook
This thesis leaves a lot of room for further research. We have already mentioned runtime evaluations, which require more optimizations, and additional experiments to test the number of smoothing iterations. Here it would be beneficial if both solvers are made adaptive, to ensure fair evaluations.
Furthermore, we initially considered a machine learning approach to replace the elliptical system. We didn't follow this idea mostly due to time constraints, as we had already collected trainings data during our numerical experiments. Our choice of programming language would have been of benefit here, as it would enable more advanced technices, such as integrating the numerical solver in the trainings loop since julia offers automatic diccerentiation of arbitrary functions, and therefore enables back-propagation (gradient descent) through the entire solver. Interessting would alo have been different discretizations of the relaxed CH equation, and different method for solving it, such as a finite volume or finite element method. Those bring the chalange of beeing harder to compare to our baseline.
* Appendix
** Operator implementation
*** relaxed
#+begin_src julia :tangle src/multi_relaxed.jl :eval never
function L(solver::relaxed_multi_solver,i,j , phi , mu)
    xi = solver.phase[i, j] / solver.dt -
         (discrete_G_weigted_neigbour_sum(i, j, solver.potential, G, solver.len, solver.width)
          -
          neighbours_in_domain(i, j, G, solver.len, solver.width) * mu )/solver.h^2
    psi = solver.epsilon^2 * solver.alpha*(solver.c[i,j] - phi) - solver.potential[i,j] - 2 * solver.phase[i,j]
    return [xi, psi]
end
#+end_src
#+begin_src julia :tangle src/multi_relaxed.jl :eval never
function dL(solver::relaxed_multi_solver , i , j)
    return [ (1/solver.dt) (1/solver.h^2*neighbours_in_domain(i,j,G,solver.len , solver.width));
             (-1*solver.epsilon^2 * solver.alpha  - 2) 1]
    end
#+end_src
** rng generation
for random point generation we use the folowing Function and seed.

#+RESULTS:
: 2×12 Matrix{Int64}:
:  48  40  20   1  63  49   8  60  26  58  26  11
:  17  13  56  52  15   9  30  14  40   9  40  25


the random testdata is then generated as follows
#+name: testdata
#+begin_src julia :eval never :tangle src/utils.jl :exports none
using Random
function testdata(gridsize , blobs , radius ,norm;rng=MersenneTwister(42))
rngpoints = rand(rng,1:gridsize, 2, blobs)
M = zeros(gridsize,gridsize) .- 1
for p in axes(rngpoints , 2)
    point = rngpoints[:, p]
    for I in CartesianIndices(M)
        if (LinearAlgebra.norm(point .- I.I  , norm) < radius)
            M[I] = 1
        end
    end
end
M
end
#+end_src
** Experiments :noexport:
*** iteration
#+begin_src julia :results output  :noweb yes :eval never :tangle experiments/src/iteration.jl
using JLD2
using DataFrames
using Random
<<init>>
<<setup-diverse-testgrids>>
function iter(g::Vector{T} , n) where T<: solver
    out = []
    for j in 1:64
    set_xi_and_psi!(g[1])
    for i = 1:64
        v_cycle!(g, 1)
    end
    push!(out, (solver=deepcopy(g[1]), iteration=j , experiment=n))
    end
    return out
end


tasks = []
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i], i)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/iteration.jld2"; result)
#+end_src

#+RESULTS:

#+name: fig:behaviour
#+begin_src julia-vterm :results graphics file html :file behaviour.gif :chache :session jl :noweb no-export :output-dir images :exports none :noweb no-export
<<init>>
using JLD2
using DataFrames
results = jldopen("experiments/iteration.jld2")["result"]
n  = size(results.solver , 1)
pbar = ProgressBar(total = 10 * n)
energy = zeros(0)
massbalance = zeros(0)

anim = @animate for res in eachrow(results)
    push!(energy , bulk_energy(res.solver))
    push!(massbalance , massbal(res.solver.phase))

    p0 = heatmap(res.solver.phase , clim =(-1,1) , framestyle=:none , legend=true, lims=(1, size(res.solver.phase , 1)) , aspect_ratio=:equal, title  = "phasefield" )
   p1 = heatmap(res.solver.potential , framestyle=:none , legend=true, lims=(1,size(res.solver.phase , 1)), aspect_ratio=:equal, title  = "potential" )

    current_range = (res.experiment -1)*64 +1

    p3 = plot( 1:res.iteration, (massbalance .-massbalance[current_range])[current_range:current_range+res.iteration-1] , xlim=(1,64),  title = "Mass change")
    p2 = plot(1:res.iteration , energy[current_range:current_range+res.iteration-1], xlim=(1,64),  title = "Bulk energy")
    plot(p0,p1,p2,p3)
end
gif(anim , "images/behaviour.gif" , fps = 10)
#+end_src

#+caption: Behaviour of bulk energy \( E_{bulk} \) and amount of fluid changing phase, for different initial conditions

*** subiteration
#+begin_src julia :results output :noweb yes :tangle experiments/src/subiteration.jl
using DataFrames
using JLD2
using ProgressMeter
<<init>>
<<setup-diverse-testgrids>>
n = 4
m = 64

function iter(g::Vector{T} , n , k , prg::Progress) where T<: solver
    out = []
    for j in 1:n
    set_xi_and_psi!(g[1])
    for i = 1:m
        alt_v_cycle!(g, 1)
        push!(out, (cycle=deepcopy(g[1]), iteration=j , subiteration=i , experiment=k))
        next!(prg)
    end
    end
    return out
end


tasks = []
prg=Progress(size(tests ,1)*n*m , showspeed=true , )
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i] , n , i , prg)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/subiteration.jld2"; result)
#+end_src
*** time
#+begin_src julia :results output :noweb yes :exports none :tangle experiments/src/time.jl
using DataFrames
using JLD2
<<init>>
SIZE  =64
M = testdata(SIZE, SIZE ÷ 5, SIZE /5 , 2)
tests = [testgrid(multi_solver , M , 2 , dt = t ) for t in 1e-2./(1:64)]

function iter(g::Vector{T} , n) where T<: solver
    out = []
    for i = 1:n
    set_xi_and_psi!(g[1])
    for i = 1:64
        v_cycle!(g, 1)
    end
    push!(out, (phase=copy(g[1].phase), iteration=n))
    end
    return out
end


tasks = []
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i], i)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/time.jld2"; result)
#+end_src
*** space
#+begin_src julia :results output :noweb yes :exports none :tangle experiments/src/space.jl
using DataFrames
using JLD2
using ProgressMeter
<<init>>

M = testdata(2^10 , 2^5 , 2^7 , 2 )
grids = testgrid(multi_solver  , M , 7 , h0 = 3e-3*64 / 1024)
# inits
for i=2:size(grids,1)
    restrict_solver!(grids[i-1] , grids[i])
end
tests = [[grids[i-1] , grids[i]] for i=2:size(grids,1)]
n = 4
m = 64

function iter(g::Vector{T} , n , prg::Progress) where T<: solver
    out = []
    for j in 1:n
    set_xi_and_psi!(g[1])
    for i = 1:m
        alt_v_cycle!(g, 1)
        next!(prg)
    end
    push!(out, (phase=copy(g[1].phase), iteration=j))
    end
    return out
end


tasks = []
prg=Progress(size(tests ,1)*n*m , showspeed=true , )
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i], n , prg)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/space_refinement.jld2"; result)
#+end_src
** Relaxed experiments :noexport:
*** Iteration
#+begin_src julia    :noweb no-export :tangle experiments/src/relaxed-iteration.jl :async
using JLD2
using DataFrames
using ProgressMeter
using Random
<<init>>
<<setup-diverse-testgrids>>

#tests = [testgrid(relaxed_multi_solver, M , 2;alpha=82000 , epsilon=0.009) for M in initial_data]
tests = [testgrid(relaxed_multi_solver, M , 2) for M in initial_data]

n = 64
m = 64


function iter(g::Vector{relaxed_multi_solver} , n , prg::Progress)
    out = []
    for j in 1:n
    set_xi_and_psi!(g[1])
    for i = 1:m
        elyps_solver!(g[1] , 1000)
        v_cycle!(g, 1)
        next!(prg)
    end
    push!(out, (solver=deepcopy(g[1]), iteration=j , experiment=n))
    end
    return out
end

prg=Progress(size(tests ,1)*n*m , showspeed=true , )
tasks = []
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i], i , prg)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/relaxed-iteration.jld2"; result)
#+end_src

*** Subiteration
#+begin_src julia :tangle experiments/src/relaxed-subiteration.jl :noweb yes
using DataFrames
using JLD2
using ProgressMeter
<<init>>
<<setup-diverse-testgrids>>
#tests = [testgrid(relaxed_multi_solver, M , 2;alpha=32428.2 , epsilon=0.163398) for M in initial_data]
tests = [testgrid(relaxed_multi_solver, M , 2) for M in initial_data]
n = 4
m = 1024

function iter(g::Vector{T} , n ,k , prg::Progress) where T<: solver
    out = []
    for j in 1:n
    set_xi_and_psi!(g[1])
    for i = 1:m
        elyps_solver!(g[1] , 1000)
        v_cycle!(g, 1)
        push!(out, (cycle=deepcopy(g[1]), iteration=j , subiteration=i , experiment=k))
        next!(prg)
    end
    end
    return out
end


tasks = []
prg=Progress(size(tests ,1)*n*m , showspeed=true , )
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i] , n , i , prg)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/relaxed-subiteration.jld2"; result)
#+end_src

*** Time
#+begin_src julia :results output :noweb yes :exports none :tangle experiments/src/relaxed-tiem.jl
using DataFrames
using JLD2
<<init>>
tests = [testgrid(relaxed_multi_solver , M , 2 , dt = t ) for t in 1e-2./(1:64)]

function iter(g::Vector{T} , n) where T<: solver
    out = []
    for j in 1:n
    set_xi_and_psi!(g[1])
    for i = 1:64
        elyps_solver!(g[1] , 1000)
        alt_v_cycle!(g, 1)
    end
    end
    push!(out, (phase=copy(g[1].phase), iteration=n))
    return out
end


tasks = []
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i], i)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/relaxed-time.jld2"; result)
#+end_src
*** Space
#+begin_src julia :results output :noweb yes :exports none :tangle experiments/src/relaxed-space.jl
using DataFrames
using JLD2
using ProgressMeter
<<init>>

M = testdata(2^10 , 2^5 , 2^7 , 2 )
grids = testgrid(relaxed_multi_solver  , M , 7 , h0=3e-3 * 64 /1024)
# inits
for i=2:size(grids,1)
    restrict_solver!(grids[i-1] , grids[i])
end
tests = [[grids[i-1] , grids[i]] for i=2:size(grids,1)]

n = 4
m = 1024

function iter(g::Vector{T} , n , prg::Progress) where T<: solver
    out = []
    for j in 1:n
    set_xi_and_psi!(g[1])
    elyps_solver!(g[1] , 1000)
    for i = 1:m
        alt_v_cycle!(g, 1)
        next!(prg)
    end
    push!(out, (phase=copy(g[1].phase), iteration=j))
    end
    return out
end


prg=Progress(size(tests ,1)*n*m , showspeed=true , )
tasks = []
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i], n , prg)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/relaxed_space_refinement.jld2"; result)
#+end_src
*** alpha

#+begin_src julia :noweb no-export :eval never :tangle experiments/src/alpha.jl :exports results
<<init>>
using JLD2
using Distributed
using ProgressBars
using DataFrames

original_grid = testgrid(multi_solver, M, 2)
alphas = 0:1e4:2e6

function alpha_error(alpha::Number , solution::Array )
    test_solver  = testgrid(relaxed_multi_solver, M, 2, alpha=alpha)
    set_xi_and_psi!(test_solver[1])
    for j in 1:64
        elyps_solver!(test_solver[1], 1000)
        alt_v_cycle!(test_solver , 1)
    end
return [(;alpha=alpha , error=norm(test_solver[1].phase - solution))]
end
set_xi_and_psi!(original_grid[1])
for j in 1:64
    alt_v_cycle!(original_grid, 1)
end
print("finished original v_cycle")
tasks = []
for alpha in alphas
    t = Threads.@spawn alpha_error(alpha , original_grid[1].phase)
    push!(tasks , (alpha=alpha , task = t))
end
result = DataFrame()
for task in ProgressBar(tasks)
    append!(result , fetch(task.task) )
    end
jldsave("experiments/alpha.jld2"; result)
#+end_src

** alternative experiments
*** iteration
#+begin_src julia :results output  :noweb yes :eval never :tangle experiments/src/alt-iteration.jl
using JLD2
using DataFrames
using Random
using ProgressMeter
<<init>>
<<setup-diverse-testgrids>>
n = 64
m = 16
function iter(g::Vector{T} , experiment , prg::Progress) where T<: solver
    out = []
    for j in 1:n
    set_xi_and_psi!(g[1])
    for i = 1:m
        alt_v_cycle!(g, 1)
        next!(prg)
    end
    push!(out, (solver=deepcopy(g[1]), iteration=j , experiment=experiment))
    end
    return out
end


prg=Progress(size(tests ,1)*n*m , showspeed=true , )
tasks = []
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i], i , prg)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/alt-iteration.jld2"; result)
#+end_src
#+begin_src julia    :noweb no-export :tangle experiments/src/alt-relaxed-iteration.jl :eval never
using JLD2
using DataFrames
using ProgressMeter
using Random
<<init>>
<<setup-diverse-testgrids>>

#tests = [testgrid(relaxed_multi_solver, M , 2;alpha=82000 , epsilon=0.009) for M in initial_data]
tests = [testgrid(relaxed_multi_solver, M , 2 , h0=1.5e-3) for M in initial_data]

n = 64
m = 512


function iter(g::Vector{relaxed_multi_solver} , experiment , prg::Progress)
    out = []
    for j in 1:n
    set_xi_and_psi!(g[1])
    for i = 1:m
        elyps_solver!(g[1] , 1000)
        alt_v_cycle!(g, 1)
        next!(prg)
    end
    push!(out, (solver=deepcopy(g[1]), iteration=j , experiment=experiment))
    end
    return out
end

prg=Progress(size(tests ,1)*n*m , showspeed=true , )
tasks = []
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i], i , prg)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/alt-h-relaxed-iteration.jld2"; result)
#+end_src

*** subiteration

#+begin_src julia :tangle experiments/src/alt-relaxed-subiteration.jl :noweb yes
using DataFrames
using JLD2
using ProgressMeter
<<init>>
<<setup-diverse-testgrids>>
#tests = [testgrid(relaxed_multi_solver, M , 2;alpha=32428.2 , epsilon=0.163398) for M in initial_data]
tests = [testgrid(relaxed_multi_solver, M , 2) for M in initial_data]
n = 4
m = 1024

function iter(g::Vector{T} , n ,experiment , prg::Progress) where T<: solver
    out = []
    for j in 1:n
    set_xi_and_psi!(g[1])
    for i = 1:m
        elyps_solver!(g[1] , 1000)
        alt_v_cycle!(g, 1)
        push!(out, (cycle=deepcopy(g[1]), iteration=j , subiteration=i , experiment=experiment))
        next!(prg)
    end
    end
    return out
end


tasks = []
prg=Progress(size(tests ,1)*n*m , showspeed=true , )
for i in eachindex(tests)
    t = Threads.@spawn iter(tests[i] , n , i , prg)
    push!(tasks , (iteration = 1 , task = t))
    end
result = DataFrame()
for task in tasks
    append!(result , fetch(task.task) )
    end
jldsave("experiments/alt-relaxed-subiteration.jld2"; result)
#+end_src
** alternative results
*** iteration
#+begin_src julia-vterm :results graphics file html :file alt-behaviour.gif :session jl :noweb no-export :output-dir images :exports none :noweb no-export :cache no
<<init>>
using JLD2
using DataFrames
gr()
results = jldopen("experiments/alt-iteration.jld2")["result"]
n  = size(results.solver , 1)
pbar = ProgressBar(total = 10 * n)
energy = zeros(0)
massbalance = zeros(0)

anim = @animate for res in eachrow(results)
    heatmap(res.solver.phase , clim =(-1,1) , framestyle=:none , legend=true, lims=(1, size(res.solver.phase , 1)) , aspect_ratio=:equal, title  = "phasefield" )

end

gif(anim , "images/alt-behaviour.gif" , fps = 10)
#+end_src

#+RESULTS[5be40c097a9ead7bf13cef459456889ddedb2fd2]:
#+begin_export html
[[file:images/alt-behaviour.gif]]
#+end_export


#+begin_src julia-vterm :results graphics file html :file alt-relaxed-behaviour.gif :session jl :noweb no-export :output-dir images :exports none :noweb no-export :cache no
<<init>>
using JLD2
using DataFrames
gr()
results = jldopen("experiments/alt-relaxed-iteration.jld2")["result"]
n  = size(results.solver , 1)
pbar = ProgressBar(total = 10 * n)
energy = zeros(0)
massbalance = zeros(0)

anim = @animate for res in eachrow(results)
    heatmap(res.solver.phase , clim =(-1,1) , framestyle=:none , legend=true, lims=(1, size(res.solver.phase , 1)) , aspect_ratio=:equal, title  = "phasefield" )

end

gif(anim , "images/alt-relaxed-behaviour.gif" , fps = 10)
#+end_src

#+RESULTS:
#+begin_export html
[[file:images/alt-relaxed-behaviour.gif]]
#+end_export

*** subiteration
#+begin_src julia-vterm :results file graphics :file alt-relaxed-convergence.svg
<<init>>
using DataFrames
using JLD2
using LaTeXStrings
gr()
n=1024

i0 = 1
df = jldopen("experiments/subiteration.jld2")["result"]
df = groupby(df , :experiment)[i0]
gd = groupby(df , :iteration)
original_res = combine(gd  , :cycle => ((x)-> [norm(x[i].phase - x[i-1].phase) for i in 2:size(x,1)]))

original_res =  groupby(original_res , :iteration)[1].cycle_function


df = jldopen("experiments/alt-relaxed-subiteration.jld2")["result"]
df = groupby(df , :experiment)[i0]
gd = groupby(df , :iteration)
relaxed_res = combine(gd  , :cycle => ((x)-> [norm(x[i].phase - x[i-1].phase) for i in 2:size(x,1)]))

relaxed_res =  groupby(relaxed_res , :iteration)[1].cycle_function
p=plot([original_res, relaxed_res],label= ["original"  "alternative relaxed"] , ylabel="difference" , xlabel="sub-iteration" )
savefig(p , "images/alt-relaxed-convergence.svg")
#+end_src

#+RESULTS[f6f4ee058d52005f0de0c501ab03bc21e22f21df]:
[[file:images/alt-relaxed-convergence.svg]]

*** mass
#+begin_src julia-vterm :results file graphics :file alt-h-relaxed-mass-balance.svg
<<init>>
using JLD2
using DataFrames
using Measures

i0 = 64 * 0+1
results = jldopen("experiments/alt-relaxed-iteration.jld2")["result"]
energy = [ massbal(s.phase) .- massbal(results.solver[i0].phase) for s in results[i0:i0+63,:].solver]
p1 = plot(1:64 , energy, xlabel= "time-steps" , ylabel = "error"  , label =false)
p2 = heatmap(results.solver[i0].phase , title="initial condition" , legend=:none , aspectratio=:equal , grid=false , showaxis=false)
p3 = heatmap(results.solver[i0+63].phase , title="after 64 time-steps" , legend=:none , aspectratio=:equal , grid=false , showaxis=false)
p = plot(p2,p3 , p1 , layout=layout3x1 , size=(1600 ,1600))
savefig(p , "images/alt-h-relaxed-mass-balance.svg")
#+end_src

#+RESULTS[2c49ac09d098e45116f2a65875ee0d0ff160a9ff]:
[[file:images/alt-h-relaxed-mass-balance.svg]]

#+begin_src julia-vterm :results file graphics :file alt-mass-balance.svg
<<init>>
using JLD2
using DataFrames
using Measures

i0 = 64 * 0+1
results = jldopen("experiments/alt-iteration.jld2")["result"]
energy = [ massbal(s.phase) .- massbal(results.solver[i0].phase) for s in results[i0:i0+63,:].solver]
p1 = plot(1:64 , energy, xlabel= "time-steps" , ylabel = "error"  , label =false)
p2 = heatmap(results.solver[i0].phase , title="initial condition" , legend=:none , aspectratio=:equal , grid=false , showaxis=false)
p3 = heatmap(results.solver[i0+63].phase , title="after 64 time-steps" , legend=:none , aspectratio=:equal , grid=false , showaxis=false)
p = plot(p2,p3 , p1 , layout=layout3x1 , size=(1600 ,1600))
savefig(p , "images/alt-mass-balance.svg")
#+end_src

#+RESULTS[ae674c0585cf06a81f1a5f3ff0f6f1881ee869ee]:
[[file:images/alt-mass-balance.svg]]

** Monte Carlo optimizer
#+begin_src julia :tangle src/optim.jl :noweb yes
using Distributions
using DataFrames
using JLD2
<<init>>

function test_values(alpha_distribution::Distribution , epsilon_distribution::Distribution , M)
    alpha = rand(alpha_distribution)
    eps = max(rand(epsilon_distribution)  ,1e-10)
    relaxed_solver = testgrid(relaxed_multi_solver, M, 2; alpha=alpha, epsilon=eps)
    set_xi_and_psi!(relaxed_solver[1])
    #SMOOTH!(relaxed_solver[1], 100, false)
    for j=1:64
    elyps_solver!(relaxed_solver[1], 2000)
    alt_v_cycle!(relaxed_solver , 1)
    end
    error = norm(relaxed_solver[1].phase .- original_solver[1].phase) / *(size(relaxed_solver[1].phase)...)
    return (;alpha=alpha , epsilon=eps , error=error)
end

original_solver = testgrid(multi_solver, M, 2)
set_xi_and_psi!(original_solver[1])
for j=1:64
alt_v_cycle!(original_solver , 1)
end
#SMOOTH!(original_solver[1], 100, false);
eps = 3e-3
#M = testdata(64, div(64,3), 64/5 , 2)
alpha0 = 10000
epsilon0 = 1e-2
best_alpha = alpha0 / 10
best_epsilon = epsilon0 / 10
best_error  = Inf
results = DataFrame()
for n=1:1000
    searchradius = 1
    alpha_distribution = Normal(best_alpha , searchradius * alpha0)
    epsilon_distribution = Normal(best_epsilon , searchradius * epsilon0)
    result = test_values(alpha_distribution , epsilon_distribution , M)
    if result.error < best_error
        global best_error = result.error
        global best_alpha = result.alpha
        global best_epsilon = result.epsilon
        println(result)
    end
push!(results , result)
end
jldsave("experiments/alpha-epsilon.jld2"; result=results)
println("Best alpha: $best_alpha , Best epsilon: $best_epsilon")
#+end_src
** bulk energy and mass balance
#+begin_src julia :tangle src/utils.jl :eval never
function bulk_energy(solver::T) where T <: Union{multi_solver , relaxed_multi_solver}
    energy = 0
    dx = CartesianIndex(1,0)
    dy = CartesianIndex(0,1)
    W(x) = 1/4 * (1-x^2)^2
    for I in CartesianIndices(solver.phase)[2:end-1,2:end-1]
        i,j = I.I
        energy += solver.epsilon^2 / 2 * G(i+ 0.5,j ,solver.len, solver.width) * (solver.phase[I+dx] - solver.phase[I])^2 + G(i,j+0.5,solver.len ,solver.width) * (solver.phase[I+dy] - solver.phase[I])^2 + W(solver.phase[I])
        end
   return energy
end
#+end_src

#+begin_src julia :tangle src/utils.jl
function massbal(arr)
    num_cells= *((size(arr).-2)...)
    return sum(arr[2:end-1, 2:end-1])/num_cells
    end
#+end_src

* Utility functions :noexport:
alternative V-cycle:
#+begin_src julia :eval never :tangle src/utils.jl
function alt_v_cycle!(grid::Array{T}, level) where T <: solver
    solver = grid[level]
    #pre SMOOTHingj
    SMOOTH!(solver, 40, false)

    d = zeros(size(solver.phase))
    r = zeros(size(solver.phase))

    # calculate error between L and expected values
    for I in CartesianIndices(solver.phase)[2:end-1, 2:end-1]
        d[I], r[I] = [solver.xi[I], solver.psi[I]] .- L(solver, I.I..., solver.phase[I], solver.potential[I])
    end

restrict_solver!(grid[level], grid[level+1])
solver = grid[level+1]
solution = deepcopy(solver)

d_large = restrict(d, G)
r_large = restrict(r, G)


u_large = zeros(size(d_large))
v_large = zeros(size(d_large))

    #Newton Iteration for solving smallgrid
    for I in CartesianIndices(solver.phase)[2:end-1, 2:end-1]
    solver.xi[I]  , solver.psi[I] = L(solver , I.I... , solver.phase[I] , solver.potential[I] ) .+ [d_large[I],r_large[I]]
    end

    SMOOTH!(solver, 40 , false)
    u_large = solver.phase .- solution.phase
    v_large = solver.potential .- solution.potential

    solver = grid[level]

    solver.phase .+= prolong(u_large , G)
    solver.potential .+= prolong(v_large, G)


    SMOOTH!(solver, 80, false)
end
#+end_src
#+name: imports
#+begin_src julia :session jl :results silent :exports none
using Plots
using LinearAlgebra
#+end_src


#+begin_src julia :tangle src/utils.jl :eval never
###############################################################################
#                  Common Utility Functions For Multi Solvers                 #
###############################################################################
"""
restricts an array on the small grid to an array in the large grid asserts size arr=2^n + 2 and returns ret=2^(n-1) + 2

Returns
---------------------------
large grid array + padding
"""
function restrict(arr, G)
    shape = (size(arr) .- 2) .÷ 2
    ret = zeros(shape .+ 2)
    for I in CartesianIndices(ret)[2:end-1, 2:end-1]
        i, j = I.I
        g = [
            G(2 * i - 1, 2 * j - 1, (size(arr) .- 2)...),
            G(2 * i - 1, 2 * j, (size(arr) .- 2)...),
            G(2 * i, 2 * j - 1, (size(arr) .- 2)...),
            G(2 * i, 2 * j, (size(arr) .- 2)...)
        ]
        if sum(g) == 0
            ret[I] = 0
        else
            ret[I] = (
                1 / sum(g)
                ,*
                dot(g,
                    [
                        arr[2*i-1, 2*j-1],
                        arr[2*i-1, 2*j],
                        arr[2*i, 2*j-1],
                        arr[2*i, 2*j]
                    ]
                )
            )
        end
    end
    return ret
end

"""
    prolong(arr , G)

interpolates int a smaller grid by a factor of 2

"""
function prolong(arr, G)
    inner_shape = (size(arr) .- 2) .* 2
    ret = zeros(inner_shape .+ 2)
    ONE = oneunit(CartesianIndices(arr)[1])
    for I in CartesianIndices(arr)[2:end-1, 2:end-1]
        Ind = 2 * (I - ONE) + ONE
        for J in (Ind-ONE):Ind
            ret[J] = G(J.I..., inner_shape...) * arr[I]
        end
    end
    return ret
end
"""
    restrict!(smallgrid_solver::multi_solver , largegrid_solver::multi_solver)::multi_solver

------------
Requires
----------
smallgrid solver and largegid solvers to be multiple of 2 from each other bar padding eg. (66x66)->(34x34)

------------
Returns
------------
    nothing. mutatest largegid in place to represent the smallgrid

"""
function restrict_solver!(smallgrid_solver::T, largegrid_solver::T) where {T<:solver}
    copy!(largegrid_solver.phase, restrict(smallgrid_solver.phase, G))
    copy!(largegrid_solver.potential, restrict(smallgrid_solver.potential, G))
    return nothing
end
#+end_src
#+begin_src julia :tangle src/solvers.jl :eval never
abstract type solver end
struct multi_solver <: solver
    phase::Matrix{Float64}
    potential::Matrix{Float64}
    xi::Matrix{Float64}
    psi::Matrix{Float64}
    epsilon::Float64
    h::Float64
    dt::Float64
    W_prime::Function
    len::Int
    width::Int

end
struct relaxed_multi_solver <: solver
    phase::Matrix{Float64}
    potential::Matrix{Float64}
    xi::Matrix{Float64}
    psi::Matrix{Float64}
    c::Matrix{Float64}
    epsilon::Float64
    h::Float64
    dt::Float64
    W_prime::Function
    len::Int
    width::Int
    alpha::Float64

end
#+end_src
#+begin_src julia :tangle src/testgrids.jl :eval never
function W_prime(x)
    return -x * (1 - x^2)
end
function testgrid(::Type{multi_solver},M, len; dt = 1e-3 ,  epsilon=8e-3 , h0=3e-3)
    grid = Array{multi_solver}(undef, len)
    phase = zeros(size(M) .+ 2)
    phase[2:end-1, 2:end-1] = M


    for i = 1:len
        dims = size(M) .÷ 2^(i-1) .+ 2
        grid[i] = multi_solver(zeros(dims),
            zeros(dims),
            zeros(dims),
            zeros(dims),
            epsilon, h0 * 2^i, dt,
            W_prime,
            (dims .- 2)...)

    end
    copyto!(grid[1].phase, phase)
    return grid

end

function testgrid(::Type{relaxed_multi_solver},M, len ; alpha=1.5e6 , dt=1e-3, epsilon=8e-3 , h0=3e-3)
    grid = Array{relaxed_multi_solver}(undef, len)
    phase = zeros(size(M) .+ 2)
    phase[2:end-1, 2:end-1] = M

    for i = 1:len
        dims = size(M) .÷ 2^(i-1) .+ 2
        grid[i] = relaxed_multi_solver(zeros(dims),
            zeros(dims),
            zeros(dims),
            zeros(dims),
            zeros(dims),
            epsilon, h0 * 2^i, dt,
            W_prime,
            (dims .- 2)... ,
            alpha)

    end
    copyto!(grid[1].phase, phase)
    return grid
end


#+end_src

#+name: init
#+begin_src julia :eval never
include(pwd() * "/src/solvers.jl")
include(pwd() * "/src/adapted_solvers.jl")
include(pwd() * "/src/utils.jl")
include(pwd() * "/src/multisolver.jl")
include(pwd() * "/src/multi_relaxed.jl")
include(pwd() * "/src/testgrids.jl")
include(pwd() * "/src/elypssolver.jl")
using Plots
using LaTeXStrings
using LinearAlgebra
using Printf
using ProgressBars
default(fontfamily="computer modern" , titlefontsize=32 , guidefontsize=22 , tickfontsize = 22 , legendfontsize=22)
pgfplotsx()
layout2x2 = grid(2,2)
layout3x1 = @layout [ b  c ; a]
size3x1 = (1600,1600)
SIZE = 64
M = testdata(SIZE, SIZE ÷ 5, SIZE /5 , 2)

#+end_src
#+name: setup-grid
#+begin_src julia :eval never :noweb yes
<<init>>
testgrd = testgrid(multi_solver,M, 2)
test_solver = testgrd[1]
#+end_src


#+name: setup-relaxed-grid
#+begin_src julia :eval never :noweb yes
<<init>>
testgrd = testgrid(relaxed_multi_solver,M, 2)
println("Hi")
solver = testgrd[1]
#+end_src

#+name: setup-comparison
#+begin_src julia :noweb yes
<<init>>
using Plots
using LinearAlgebra
using ProgressBars
using JLD2
M = jldopen("data/test-phasefield.jld2")["M"]

relaxed_grid1 = testgrid(relaxed_multi_solver, M, 2 ,alpha=1e3)
relaxed_grid2 = testgrid(relaxed_multi_solver, M, 2 , alpha=1e4)
relaxed_grid3 = testgrid(relaxed_multi_solver, M, 2 , alpha=1e5)
original_grid = testgrid(multi_solver, M, 2)

#+end_src

#+name: setup-diverse-testgrids
#+begin_src julia :noweb yes
incirc(M) = filter(x -> norm(x.I .- (size(M, 1) / 2, size(M, 2) / 2)) < min(size(M)...) / 3, CartesianIndices(M))
insquare(M) = filter(x -> norm(x.I .- (size(M, 1) / 2, size(M, 2) / 2), Inf) < min(size(M)...) / 4, CartesianIndices(M))
side(M) = filter(x -> x.I[2] < size(M, 2) ÷ 2, CartesianIndices(M))
halfcirc(M) = filter(x -> norm(x.I .- (1, size(M, 2) / 2), 2) < min(size(M)...) / 3, CartesianIndices(M))

function get_special_input(fn, size)
    M = fill(-1, size , size )
    M[fn(M)] .= 1
    return M
end
SIZE  =64
t1= [testdata(SIZE, SIZE ÷ 5, SIZE /5 , j) for j in [1,2, Inf]]
t2 = [get_special_input(fn,SIZE) for  fn in [halfcirc , incirc, side , insquare]]
initial_data = [t1 ; t2]
tests = [testgrid(multi_solver, M , 2) for M in initial_data]

#+end_src






* References :ignore:
#+PRINT_BIBLIOGRAPHY:
#  LocalWords:  Discretization

* Footnotes
[fn:1] This solver uses a two dimensional version with 2 second order terms instead of the full fourth order  equation.

[fn:2] Julia provides iteration utilities over n dimensional matricies. Therefore it would technically be possible to write dimension agnostic algorithms. While we used some of this functionality, we did not implement a full n-dimensional algorithm, and only provide a 2D implementation
# Local Variables:
# mode: org
# org-export-allow-bind-keywords: t
# End:
